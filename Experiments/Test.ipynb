{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Model Scripts folder to the path\n",
    "import sys\n",
    "sys.path.append(\"Model Scripts\")\n",
    "sys.path.append(\"Model Weights\")\n",
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to create the model\n",
    "from ArithmeticEncoder import create_arithmetic_transformer\n",
    "\n",
    "# Create a model with default parameters\n",
    "model = create_arithmetic_transformer()\n",
    "\n",
    "# Or create a model with custom parameters\n",
    "model = create_arithmetic_transformer(\n",
    "    vocab_size=14,\n",
    "    embed_size=128,\n",
    "    num_heads=4,\n",
    "    ff_dim=512,\n",
    "    num_layers=3,\n",
    "    max_length=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the complete saved state\n",
    "checkpoint = torch.load(r'./Model Weights/arithmetic_model_embedding.pth')\n",
    "\n",
    "# Extract the model configuration from the checkpoint\n",
    "config = checkpoint['model_config']\n",
    "\n",
    "# Create a new model with the saved configuration\n",
    "model = create_arithmetic_transformer(\n",
    "    vocab_size=config['vocab_size'],\n",
    "    embed_size=config['embed_size'],\n",
    "    num_heads=config['num_heads'],\n",
    "    ff_dim=config['ff_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    max_length=config['max_length'],\n",
    "    dropout=config['dropout']\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# If you need the vocabulary mappings that were used during training:\n",
    "vocab = checkpoint['vocab']  # for converting tokens to indices\n",
    "inv_vocab = checkpoint['inv_vocab']  # for converting indices back to tokens\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to use the model for inference, you'll want these helper functions:\n",
    "def preprocess_input(input_str, max_length, vocab):\n",
    "    # Reverse the input string\n",
    "    input_str = input_str[::-1]\n",
    "    # Tokenize\n",
    "    tokens = [vocab[c] for c in input_str if c in vocab]\n",
    "    # Pad\n",
    "    padded = tokens + [vocab['<PAD>']] * (max_length - len(tokens))\n",
    "    return torch.tensor(padded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def decode_output(output_tensor, inv_vocab):\n",
    "    _, predicted = output_tensor.max(2)\n",
    "    decoded = []\n",
    "    for token in predicted[0]:\n",
    "        token_val = token.item()\n",
    "        if token_val == vocab['<EOS>']:\n",
    "            break\n",
    "        if token_val != vocab['<PAD>']:\n",
    "            decoded.append(inv_vocab[token_val])\n",
    "    return ''.join(decoded)[::-1]  # Reverse at the end\n",
    "\n",
    "# Example usage:\n",
    "def test_addition(num1, num2, model, vocab, inv_vocab, max_length):\n",
    "    input_str = f\"{num1}+{num2}=\"\n",
    "    input_tensor = preprocess_input(input_str, max_length, vocab)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        result = decode_output(output, inv_vocab)\n",
    "    print(f\"{num1} + {num2} = {result}\")\n",
    "    print(f\"Correct result: {num1 + num2}\")\n",
    "    print(f\"Model's prediction is {'correct' if int(result) == num1 + num2 else 'incorrect'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 + 456 = 589\n",
      "Correct result: 579\n",
      "Model's prediction is incorrect\n",
      "5 + 7 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "42 + 58 = 60\n",
      "Correct result: 100\n",
      "Model's prediction is incorrect\n",
      "123 + 456 = 589\n",
      "Correct result: 579\n",
      "Model's prediction is incorrect\n",
      "1234 + 5678 = 6912\n",
      "Correct result: 6912\n",
      "Model's prediction is correct\n"
     ]
    }
   ],
   "source": [
    "# Test a simple addition\n",
    "test_addition(123, 456, model, vocab, inv_vocab, config['max_length'])\n",
    "\n",
    "# or test multiple additions in a loop\n",
    "test_cases = [\n",
    "    (5, 7),\n",
    "    (42, 58),\n",
    "    (123, 456),\n",
    "    (1234, 5678)\n",
    "]\n",
    "\n",
    "for num1, num2 in test_cases:\n",
    "    test_addition(num1, num2, model, vocab, inv_vocab, config['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
