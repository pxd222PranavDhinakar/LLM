{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Model Scripts folder to the path\n",
    "import sys\n",
    "sys.path.append(\"Model Scripts\")\n",
    "sys.path.append(\"Model Weights\")\n",
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to create the model\n",
    "from Model_Scripts.ArithmeticTransformer import create_arithmetic_transformer\n",
    "\n",
    "# Create a model with default parameters\n",
    "model = create_arithmetic_transformer()\n",
    "\n",
    "# Or create a model with custom parameters\n",
    "model = create_arithmetic_transformer(\n",
    "    vocab_size=14,\n",
    "    embed_size=128,\n",
    "    num_heads=4,\n",
    "    ff_dim=512,\n",
    "    num_layers=3,\n",
    "    max_length=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on cpu\n",
      "Model configuration: {'vocab_size': 14, 'embed_size': 256, 'num_heads': 4, 'ff_dim': 1024, 'num_layers': 4, 'max_length': 42, 'dropout': 0.1}\n",
      "Model loaded successfully! Best accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def load_model(model_path, device=None):\n",
    "    # Determine device\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load checkpoint\n",
    "    print(f\"Loading model on {device}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Extract config\n",
    "    config = checkpoint['model_config']\n",
    "    print(\"Model configuration:\", config)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_arithmetic_transformer(\n",
    "        vocab_size=config['vocab_size'],\n",
    "        embed_size=config['embed_size'],\n",
    "        num_heads=config['num_heads'],\n",
    "        ff_dim=config['ff_dim'],\n",
    "        num_layers=config['num_layers'],\n",
    "        max_length=config['max_length'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    \n",
    "    # Load state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Move model to device and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Get vocab if available\n",
    "    vocab = checkpoint.get('vocab')\n",
    "    inv_vocab = checkpoint.get('inv_vocab')\n",
    "    \n",
    "    print(f\"Model loaded successfully! Best accuracy: {checkpoint['accuracy']:.4f}\")\n",
    "    \n",
    "    return model, vocab, inv_vocab, device, config\n",
    "\n",
    "# Usage:\n",
    "model_path = './Model_Weights/medium_addition_model.pth'\n",
    "model, vocab, inv_vocab, device, config = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to use the model for inference, you'll want these helper functions:\n",
    "def preprocess_input(input_str, max_length, vocab):\n",
    "    # Reverse the input string\n",
    "    input_str = input_str[::-1]\n",
    "    # Tokenize\n",
    "    tokens = [vocab[c] for c in input_str if c in vocab]\n",
    "    # Pad\n",
    "    padded = tokens + [vocab['<PAD>']] * (max_length - len(tokens))\n",
    "    return torch.tensor(padded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def decode_output(output_tensor, inv_vocab):\n",
    "    _, predicted = output_tensor.max(2)\n",
    "    decoded = []\n",
    "    for token in predicted[0]:\n",
    "        token_val = token.item()\n",
    "        if token_val == vocab['<EOS>']:\n",
    "            break\n",
    "        if token_val != vocab['<PAD>']:\n",
    "            decoded.append(inv_vocab[token_val])\n",
    "    return ''.join(decoded)[::-1]  # Reverse at the end\n",
    "\n",
    "# Example usage:\n",
    "def test_addition(num1, num2, model, vocab, inv_vocab, max_length):\n",
    "    input_str = f\"{num1}+{num2}=\"\n",
    "    input_tensor = preprocess_input(input_str, max_length, vocab)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        result = decode_output(output, inv_vocab)\n",
    "    print(f\"{num1} + {num2} = {result}\")\n",
    "    print(f\"Correct result: {num1 + num2}\")\n",
    "    print(f\"Model's prediction is {'correct' if int(result) == num1 + num2 else 'incorrect'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 + 456 = 589\n",
      "Correct result: 579\n",
      "Model's prediction is incorrect\n",
      "5 + 7 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "42 + 58 = 00\n",
      "Correct result: 100\n",
      "Model's prediction is incorrect\n",
      "123 + 456 = 589\n",
      "Correct result: 579\n",
      "Model's prediction is incorrect\n",
      "1234 + 5678 = 7912\n",
      "Correct result: 6912\n",
      "Model's prediction is incorrect\n"
     ]
    }
   ],
   "source": [
    "# Test a simple addition\n",
    "test_addition(123, 456, model, vocab, inv_vocab, config['max_length'])\n",
    "\n",
    "# or test multiple additions in a loop\n",
    "test_cases = [\n",
    "    (5, 7),\n",
    "    (42, 58),\n",
    "    (123, 456),\n",
    "    (1234, 5678)\n",
    "]\n",
    "\n",
    "for num1, num2 in test_cases:\n",
    "    test_addition(num1, num2, model, vocab, inv_vocab, config['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 + 456 = 579\n",
      "Correct result: 579\n",
      "Model's prediction is correct\n",
      "5 + 7 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "42 + 58 = 100\n",
      "Correct result: 100\n",
      "Model's prediction is correct\n",
      "123 + 456 = 579\n",
      "Correct result: 579\n",
      "Model's prediction is correct\n",
      "1234 + 5678 = 6912\n",
      "Correct result: 6912\n",
      "Model's prediction is correct\n",
      "10304923 + 123123123 = 133428046\n",
      "Correct result: 133428046\n",
      "Model's prediction is correct\n",
      "123123123 + 10304923 = 133428046\n",
      "Correct result: 133428046\n",
      "Model's prediction is correct\n"
     ]
    }
   ],
   "source": [
    "  # Test a simple addition\n",
    "test_addition(123, 456, model, vocab, inv_vocab, config['max_length'])\n",
    "\n",
    "# or test multiple additions in a loop\n",
    "test_cases = [\n",
    "    (5, 7),\n",
    "    (42, 58),\n",
    "    (123, 456),\n",
    "    (1234, 5678),\n",
    "    (10304923, 123123123),\n",
    "    (123123123, 10304923)\n",
    "\n",
    "]\n",
    "\n",
    "for num1, num2 in test_cases:\n",
    "    test_addition(num1, num2, model, vocab, inv_vocab, config['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
