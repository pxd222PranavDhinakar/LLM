{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ArithmeticDataset(Dataset):\n",
    "    def __init__(self, max_length, num_samples):\n",
    "        self.max_length = max_length\n",
    "        self.num_samples = num_samples\n",
    "        self.data = self.generate_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def generate_number(self, length):\n",
    "        return random.randint(10**(length-1), 10**length - 1)\n",
    "\n",
    "    def generate_data(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionDataset(ArithmeticDataset):\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        samples_per_combination = self.num_samples // (self.max_length ** 2)\n",
    "        for i in range(1, self.max_length + 1):\n",
    "            for j in range(1, self.max_length + 1):\n",
    "                for _ in range(samples_per_combination):\n",
    "                    num1 = self.generate_number(i)\n",
    "                    num2 = self.generate_number(j)\n",
    "                    result = num1 + num2\n",
    "                    data.append((f\"{num1}+{num2}=\", str(result)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicationDataset(ArithmeticDataset):\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        samples_per_combination = self.num_samples // (self.max_length ** 2)\n",
    "        for i in range(1, self.max_length + 1):\n",
    "            for j in range(1, self.max_length + 1):\n",
    "                for _ in range(samples_per_combination):\n",
    "                    num1 = self.generate_number(i)\n",
    "                    num2 = self.generate_number(j)\n",
    "                    result = num1 * num2\n",
    "                    data.append((f\"{num1}*{num2}=\", str(result)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortingDataset(ArithmeticDataset):\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        samples_per_combination = self.num_samples // (self.max_length ** 2)\n",
    "        for i in range(1, self.max_length + 1):  # number of integers\n",
    "            for j in range(1, self.max_length + 1):  # max digit length\n",
    "                for _ in range(samples_per_combination):\n",
    "                    numbers = [self.generate_number(random.randint(1, j)) for _ in range(i)]\n",
    "                    indices = list('abcdefghijklmnopqrstuvwxyz'[:i])\n",
    "                    input_str = ','.join([f\"{idx}:{num}\" for idx, num in zip(indices, numbers)])\n",
    "                    sorted_indices = [idx for _, idx in sorted(zip(numbers, indices))]\n",
    "                    output_str = ''.join(sorted_indices)\n",
    "                    data.append((input_str, output_str))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset_class, max_length, train_samples, test_samples):\n",
    "    train_dataset = dataset_class(max_length, train_samples)\n",
    "    test_dataset = dataset_class(max_length, test_samples)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition sample: ('4+5=', '9')\n",
      "Multiplication sample: ('6*4=', '24')\n",
      "Sorting sample: ('a:3', 'a')\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "max_length = 20  # maximum length of operands\n",
    "train_samples = 200_000  # 20 million as mentioned in the paper\n",
    "test_samples = 1_000  # adjust as needed\n",
    "\n",
    "# Create datasets\n",
    "addition_train, addition_test = create_datasets(AdditionDataset, max_length, train_samples, test_samples)\n",
    "multiplication_train, multiplication_test = create_datasets(MultiplicationDataset, max_length, train_samples, test_samples)\n",
    "sorting_train, sorting_test = create_datasets(SortingDataset, max_length, train_samples, test_samples)\n",
    "\n",
    "# Print some samples\n",
    "print(\"Addition sample:\", addition_train[0])\n",
    "print(\"Multiplication sample:\", multiplication_train[0])\n",
    "print(\"Sorting sample:\", sorting_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addition Samples:\n",
      "Input: 135748326+108631275=, Output: 244379601\n",
      "Input: 1354172+336685848355199866=, Output: 336685848356554038\n",
      "Input: 44338320546283+972243690165=, Output: 45310564236448\n",
      "Input: 75040161704634192095+9527451304538227395=, Output: 84567613009172419490\n",
      "Input: 9318+84623911195379659736=, Output: 84623911195379669054\n",
      "Input: 58739854+8279644088=, Output: 8338383942\n",
      "Input: 9395564888+77629=, Output: 9395642517\n",
      "Input: 520+2371=, Output: 2891\n",
      "Input: 5623061952901691460+3=, Output: 5623061952901691463\n",
      "Input: 243+4925787039520747=, Output: 4925787039520990\n",
      "\n",
      "Multiplication Samples:\n",
      "Input: 1314*4727797=, Output: 6212325258\n",
      "Input: 3228169008960561*26=, Output: 83932394232974586\n",
      "Input: 7035962375386837078*20466463929=, Output: 144001270161655858478286759462\n",
      "Input: 4830844194151411*4972082029=, Output: 24019353602639217538092919\n",
      "Input: 68464*476769075851088=, Output: 32641518009068888832\n",
      "Input: 3517314548080498*75912257251479930246=, Output: 267007286808259638068510650232942508\n",
      "Input: 9157701523120469911*24=, Output: 219784836554891277864\n",
      "Input: 9815449*39=, Output: 382802511\n",
      "Input: 222564*1319102320=, Output: 293584688748480\n",
      "Input: 5103973233470414*7566984585775=, Output: 38621686783878808047507760850\n",
      "\n",
      "Sorting Samples:\n",
      "Input: a:89850,b:1,c:210273, Output: bac\n",
      "Input: a:92422980069,b:955,c:166596852822693,d:33168598266,e:9643845828,f:7128107932,g:240138997812,h:861004747392283,i:5,j:649348680291496,k:899641678955276,l:210912946985052,m:7,n:3946970,o:202021969566434, Output: imbnfedagcoljhk\n",
      "Input: a:4,b:56203099, Output: ab\n",
      "Input: a:11,b:88,c:2,d:87,e:3,f:4,g:805,h:844,i:31,j:121,k:91,l:819,m:8,n:4,o:75, Output: cefnmaiodbkjglh\n",
      "Input: a:11, Output: a\n",
      "Input: a:9,b:9, Output: ab\n",
      "Input: a:25,b:2,c:27492444666,d:553,e:74497453366,f:248566,g:1697,h:50303842,i:341,j:90,k:913039,l:64421985863,m:3262,n:7,o:26425471,p:75906992651,q:973,r:24251515,s:2172,t:25242, Output: bnajidqgsmtfkrohclep\n",
      "Input: a:5,b:4, Output: ba\n",
      "Input: a:9614,b:413619,c:2103866,d:525,e:35,f:497705,g:805690,h:34135,i:66437,j:5,k:56498,l:48097670,m:9982,n:626,o:15513,p:47, Output: jepdnamohkibfgcl\n",
      "Input: a:821,b:51872,c:9,d:72,e:10414,f:98082,g:41,h:984,i:30,j:2,k:9898,l:13, Output: jcligdahkebf\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def print_samples(dataset, name, num_samples=10):\n",
    "    print(f\"\\n{name} Samples:\")\n",
    "    for _ in range(num_samples):\n",
    "        idx = random.randint(0, len(dataset) - 1)\n",
    "        sample = dataset[idx]\n",
    "        print(f\"Input: {sample[0]}, Output: {sample[1]}\")\n",
    "\n",
    "# Sample from Addition dataset\n",
    "print_samples(addition_train, \"Addition\")\n",
    "\n",
    "# Sample from Multiplication dataset\n",
    "print_samples(multiplication_train, \"Multiplication\")\n",
    "\n",
    "# Sample from Sorting dataset\n",
    "print_samples(sorting_train, \"Sorting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Transformer for Arithmetic Tasks\n",
    "\n",
    "This code implements a small transformer model designed to learn basic arithmetic operations, inspired by the Abacus Embeddings paper. The model architecture is as follows:\n",
    "\n",
    "## Model Architecture\n",
    "- Embedding layer: Custom Abacus Embedding\n",
    "- Transformer layers: 2\n",
    "- Attention heads per layer: 2\n",
    "- Embedding dimension: 64\n",
    "- Feed-forward dimension: 128\n",
    "- Maximum sequence length: 20\n",
    "\n",
    "## Key Components\n",
    "1. **AbacusEmbedding**: A custom embedding layer that combines token embeddings with positional information.\n",
    "2. **SmallTransformer**: The main model class, incorporating the Abacus Embedding and transformer layers.\n",
    "3. **Training Loop**: Includes both training and evaluation phases, tracking loss and accuracy.\n",
    "\n",
    "## Training Details\n",
    "- Dataset: Addition task (can be extended to multiplication and sorting)\n",
    "- Batch size: 32\n",
    "- Number of epochs: 10\n",
    "- Optimizer: Adam\n",
    "- Learning rate: 0.001\n",
    "- Loss function: Cross Entropy Loss (ignoring padding tokens)\n",
    "\n",
    "This setup allows for quick experimentation and debugging on a CPU. Once the basic functionality is verified, the model size and dataset can be scaled up to match the specifications in the Abacus Embeddings paper.\n",
    "\n",
    "Let's calculate the number of parameters for this model configuration. We'll break it down by component:\n",
    "\n",
    "1. Embedding Layer:\n",
    "   - Token Embedding: vocab_size * embed_size = 14 * 64 = 896\n",
    "   - Positional Embedding: max_length * embed_size = 20 * 64 = 1,280\n",
    "\n",
    "2. Transformer Layers (for each layer):\n",
    "   - Self-Attention:\n",
    "     * Query, Key, Value matrices: 3 * (embed_size * embed_size) = 3 * (64 * 64) = 12,288\n",
    "     * Output projection: embed_size * embed_size = 64 * 64 = 4,096\n",
    "   - Feed-forward network:\n",
    "     * First linear layer: embed_size * ff_dim = 64 * 128 = 8,192\n",
    "     * Second linear layer: ff_dim * embed_size = 128 * 64 = 8,192\n",
    "   - Layer Norm (2 per layer): 2 * 2 * embed_size = 2 * 2 * 64 = 256\n",
    "\n",
    "   Total per layer: 12,288 + 4,096 + 8,192 + 8,192 + 256 = 33,024\n",
    "\n",
    "3. Output Layer:\n",
    "   - Linear projection: embed_size * vocab_size = 64 * 14 = 896\n",
    "\n",
    "Now, let's sum it up:\n",
    "- Embedding Layer: 896 + 1,280 = 2,176\n",
    "- Transformer Layers: 33,024 * 2 = 66,048\n",
    "- Output Layer: 896\n",
    "\n",
    "Total parameters: 2,176 + 66,048 + 896 = 69,120\n",
    "\n",
    "So, this small transformer model would have approximately 69,120 parameters.\n",
    "\n",
    "This is a very small model, which is perfect for initial experiments and debugging on a CPU. It's about 3 orders of magnitude smaller than the models described in the Abacus Embeddings paper (which mentions models with ~12 million parameters), allowing for quick iterations and tests of the basic architecture and training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, max_length, num_samples):\n",
    "        # Initialize the dataset with maximum length of numbers and total samples\n",
    "        self.max_length = max_length\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        # Define the vocabulary for tokenization\n",
    "        # 0-9 for digits, 10 for '+', 11 for '=', 12 for padding, 13 for end of sequence\n",
    "        self.vocab = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, \n",
    "                      '+': 10, '=': 11, '<PAD>': 12, '<EOS>': 13}\n",
    "        # Create an inverse vocabulary for decoding\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        # Generate the dataset\n",
    "        self.data = self.generate_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a specific item from the dataset\n",
    "        return self.data[idx]\n",
    "\n",
    "    def generate_number(self, length):\n",
    "        # Generate a random number of specified length\n",
    "        return random.randint(10**(length-1), 10**length - 1)\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        # Convert a string to a list of token IDs\n",
    "        return [self.vocab[c] for c in s if c in self.vocab]\n",
    "\n",
    "    def pad_sequence(self, seq, max_length):\n",
    "        # Pad a sequence with <PAD> tokens to reach the specified length\n",
    "        return seq + [self.vocab['<PAD>']] * (max_length - len(seq))\n",
    "\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        # Calculate samples per length combination to achieve desired total samples\n",
    "        samples_per_combination = max(1, self.num_samples // (self.max_length ** 2))\n",
    "        \n",
    "        # Generate addition problems for all possible length combinations\n",
    "        for i in range(1, self.max_length + 1):\n",
    "            for j in range(1, self.max_length + 1):\n",
    "                for _ in range(samples_per_combination):\n",
    "                    # Generate two random numbers\n",
    "                    num1 = self.generate_number(i)\n",
    "                    num2 = self.generate_number(j)\n",
    "                    result = num1 + num2\n",
    "                    \n",
    "                    # Create the input string (reversed for right-to-left processing)\n",
    "                    input_str = f\"{num1:0{i}}+{num2:0{j}}=\"\n",
    "                    input_str = input_str[::-1]  # Reverse the string\n",
    "                    \n",
    "                    # Create the target string (reversed)\n",
    "                    target_str = f\"{result}\"[::-1]\n",
    "                    \n",
    "                    # Tokenize and pad both input and target\n",
    "                    input_tokens = self.tokenize(input_str)\n",
    "                    target_tokens = self.tokenize(target_str) + [self.vocab['<EOS>']]\n",
    "                    \n",
    "                    max_seq_length = self.max_length * 2 + 2  # Maximum possible sequence length\n",
    "                    input_padded = self.pad_sequence(input_tokens, max_seq_length)\n",
    "                    target_padded = self.pad_sequence(target_tokens, max_seq_length)\n",
    "                    \n",
    "                    # Convert to PyTorch tensors\n",
    "                    input_tensor = torch.tensor(input_padded, dtype=torch.long)\n",
    "                    target_tensor = torch.tensor(target_padded, dtype=torch.long)\n",
    "                    \n",
    "                    data.append((input_tensor, target_tensor))\n",
    "        \n",
    "        # Shuffle the data for randomness\n",
    "        random.shuffle(data)\n",
    "        return data\n",
    "\n",
    "    def decode(self, tensor):\n",
    "        # Convert a tensor of token IDs back to a string, reversing and removing special tokens\n",
    "        return ''.join(self.inv_vocab[t.item()] for t in tensor if t.item() not in [self.vocab['<PAD>'], self.vocab['<EOS>']])[::-1]\n",
    "\n",
    "# Set parameters for the dataset\n",
    "max_length = 20  # maximum length of operands\n",
    "train_samples = 200_000  # Number of training samples\n",
    "test_samples = 1_000  # Number of test samples\n",
    "\n",
    "# Create training and test datasets\n",
    "addition_train = AdditionDataset(max_length, train_samples)\n",
    "addition_test = AdditionDataset(max_length, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition samples:\n",
      "Input: 29458670367+59799239011929961529=\n",
      "Target: 59799239041388631896\n",
      "Equation: 29458670367+59799239011929961529= 59799239041388631896\n",
      "\n",
      "Input: 8654772+427196354=\n",
      "Target: 435851126\n",
      "Equation: 8654772+427196354= 435851126\n",
      "\n",
      "Input: 33530729735093760+8921=\n",
      "Target: 33530729735102681\n",
      "Equation: 33530729735093760+8921= 33530729735102681\n",
      "\n",
      "Input: 62746988432+112950109=\n",
      "Target: 62859938541\n",
      "Equation: 62746988432+112950109= 62859938541\n",
      "\n",
      "Input: 687204568054000123+2615962370626995680=\n",
      "Target: 3303166938680995803\n",
      "Equation: 687204568054000123+2615962370626995680= 3303166938680995803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some samples\n",
    "print(\"Addition samples:\")\n",
    "for i in range(0,5):\n",
    "    input_tensor, target_tensor = addition_train[i]\n",
    "    input_str = addition_train.decode(input_tensor)\n",
    "    target_str = addition_train.decode(target_tensor)\n",
    "    print(f\"Input: {input_str}\")\n",
    "    print(f\"Target: {target_str}\")\n",
    "    print(f\"Equation: {input_str} {target_str}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbacusEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, max_length):\n",
    "        super().__init__()\n",
    "        # Create an embedding layer for the input tokens\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        # Create a separate embedding layer for positional encodings\n",
    "        self.pos_embed = nn.Embedding(max_length, embed_size)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get the sequence length of the input\n",
    "        seq_length = x.size(1)\n",
    "        \n",
    "        # Generate position indices\n",
    "        pos = torch.arange(seq_length, device=x.device).unsqueeze(0)\n",
    "        \n",
    "        # Truncate positions to max_length\n",
    "        # This ensures that positions beyond max_length use the same embedding\n",
    "        pos = torch.clamp(pos, max=self.max_length - 1)\n",
    "        \n",
    "        # Get the token embeddings\n",
    "        embedded = self.embed(x)\n",
    "        \n",
    "        # Get the positional embeddings\n",
    "        positional = self.pos_embed(pos)\n",
    "        \n",
    "        # Combine token embeddings and positional embeddings\n",
    "        return embedded + positional[:, :seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, ff_dim, num_layers, max_length):\n",
    "        super().__init__()\n",
    "        # Initialize the custom Abacus Embedding layer\n",
    "        self.embedding = AbacusEmbedding(vocab_size, embed_size, max_length)\n",
    "        \n",
    "        # Create a single Transformer encoder layer\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Create the full Transformer encoder by stacking multiple layers\n",
    "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final linear layer to project to vocabulary size\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            # Apply Abacus Embedding\n",
    "            x = self.embedding(x)\n",
    "            \n",
    "            # Pass through the Transformer encoder\n",
    "            x = self.transformer(x)\n",
    "            \n",
    "            # Project to vocabulary size\n",
    "            return self.fc_out(x)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in SmallTransformer forward pass: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, embed_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # For scale in attention computation\n",
    "        self.scale = head_size ** -0.5\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, C = x.shape # batch size, sequence length, channels, which is the embed_size so (32, 42, 64)\n",
    "        \n",
    "        # Create key, query, value projections\n",
    "        k = self.key(x)    # (B, T, head_size)\n",
    "        q = self.query(x)  # (B, T, head_size)\n",
    "        v = self.value(x)  # (B, T, head_size)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        att = (q @ k.transpose(-2, -1)) * self.scale  # (B, T, T)\n",
    "        \n",
    "        # Apply mask if provided (for causal attention)\n",
    "        if mask is not None:\n",
    "            att = att.masked_fill(mask == 0, float('-inf'))\n",
    "            \n",
    "        # Apply softmax and dropout\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "        \n",
    "        # Weighted aggregation of values\n",
    "        out = att @ v  # (B, T, head_size)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, embed_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, embed_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Concatenate outputs from all heads\n",
    "        out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n",
    "        # Project back to embed_size\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ArithmeticTransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, head_size, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, head_size, embed_size, dropout)\n",
    "        self.feed_forward = FeedForward(embed_size, ff_dim, dropout)\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Attention with residual connection and layer norm\n",
    "        x = x + self.attention(self.ln1(x), mask)\n",
    "        # Feed forward with residual connection and layer norm\n",
    "        x = x + self.feed_forward(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class ArithmeticTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, head_size, ff_dim, \n",
    "                 num_layers, max_length, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Keep the AbacusEmbedding layer\n",
    "        self.embedding = AbacusEmbedding(vocab_size, embed_size, max_length)\n",
    "        \n",
    "        # Create stack of transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ArithmeticTransformerBlock(embed_size, num_heads, head_size, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Layer norm before final projection\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        \n",
    "        # Final projection to vocabulary\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get embeddings\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Pass through transformer blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # Final layer norm and projection\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.fc_out(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Create a progress bar for each epoch\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            try:\n",
    "                # Reset gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy for this batch\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                non_pad_mask = targets.ne(addition_train.vocab['<PAD>'])\n",
    "                correct_predictions += (predicted[non_pad_mask] == targets[non_pad_mask]).sum().item()\n",
    "                total_predictions += non_pad_mask.sum().item()\n",
    "\n",
    "                # Update progress bar with current loss and accuracy\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{correct_predictions/total_predictions:.4f}\"\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                # Error handling and debugging information\n",
    "                print(f\"\\nError in batch {batch_idx}\")\n",
    "                print(f\"Input shape: {inputs.shape}, max value: {inputs.max().item()}, min value: {inputs.min().item()}\")\n",
    "                print(f\"Target shape: {targets.shape}, max value: {targets.max().item()}, min value: {targets.min().item()}\")\n",
    "                print(f\"Output shape: {outputs.shape}\")\n",
    "                raise e\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs} - Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "        \n",
    "        # Evaluation on test set\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                non_pad_mask = targets.ne(addition_train.vocab['<PAD>'])\n",
    "                total += non_pad_mask.sum().item()\n",
    "                correct += (predicted[non_pad_mask] == targets[non_pad_mask]).sum().item()\n",
    "                \n",
    "                # Calculate test loss\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        # Calculate test accuracy and average test loss\n",
    "        test_accuracy = correct / total\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        # Save the best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'New best model saved with accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "        print('-' * 60)\n",
    "\n",
    "    print(f'Training completed. Best test accuracy: {best_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_embedding_tracking(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
    "    # Characters to track (digits and operators)\n",
    "    chars_to_track = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '=']\n",
    "    char_indices = [addition_train.vocab[c] for c in chars_to_track]\n",
    "    \n",
    "    # Storage for histories\n",
    "    embedding_history = []\n",
    "    loss_history = []\n",
    "    global_steps = []\n",
    "    best_accuracy = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create a progress bar for each epoch\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), \n",
    "                          desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            try:\n",
    "                # Reset gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy for this batch\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                non_pad_mask = targets.ne(addition_train.vocab['<PAD>'])\n",
    "                correct_predictions += (predicted[non_pad_mask] == targets[non_pad_mask]).sum().item()\n",
    "                total_predictions += non_pad_mask.sum().item()\n",
    "                \n",
    "                # Store embeddings every 100 batches\n",
    "                if batch_idx % 100 == 0:\n",
    "                    # Fixed: Access embedding through the correct path\n",
    "                    current_embeddings = model.embedding.embed.weight[char_indices].detach().numpy()\n",
    "                    embedding_history.append(current_embeddings)\n",
    "                    loss_history.append(loss.item())\n",
    "                    global_steps.append(total_steps)\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{correct_predictions/total_predictions:.4f}\"\n",
    "                })\n",
    "                \n",
    "                total_steps += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError in batch {batch_idx}\")\n",
    "                print(f\"Input shape: {inputs.shape}, max value: {inputs.max().item()}, min value: {inputs.min().item()}\")\n",
    "                print(f\"Target shape: {targets.shape}, max value: {targets.max().item()}, min value: {targets.min().item()}\")\n",
    "                print(f\"Output shape: {outputs.shape}\")\n",
    "                raise e\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs} - Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "        \n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                non_pad_mask = targets.ne(addition_train.vocab['<PAD>'])\n",
    "                total += non_pad_mask.sum().item()\n",
    "                correct += (predicted[non_pad_mask] == targets[non_pad_mask]).sum().item()\n",
    "                \n",
    "                # Calculate test loss\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        # Calculate test accuracy and average test loss\n",
    "        test_accuracy = correct / total\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_accuracy,\n",
    "            }, 'best_arithmetic_model.pth')\n",
    "            print(f'New best model saved with accuracy: {best_accuracy:.4f}')\n",
    "        \n",
    "        print('-' * 60)\n",
    "    \n",
    "    # Convert histories to numpy arrays\n",
    "    embedding_history = np.array(embedding_history)\n",
    "    loss_history = np.array(loss_history)\n",
    "    global_steps = np.array(global_steps)\n",
    "    \n",
    "    return model, embedding_history, loss_history, global_steps, chars_to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 41/6250 [00:02<06:52, 15.04it/s, loss=2.3783, acc=0.0991]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[124], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[123], line 113\u001b[0m, in \u001b[0;36mArithmeticTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Pass through transformer blocks\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 113\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Final layer norm and projection\u001b[39;00m\n\u001b[1;32m    116\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[123], line 83\u001b[0m, in \u001b[0;36mArithmeticTransformerBlock.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Attention with residual connection and layer norm\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Feed forward with residual connection and layer norm\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[123], line 54\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Concatenate outputs from all heads\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x, mask) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Project back to embed_size\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n",
      "Cell \u001b[0;32mIn[123], line 54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Concatenate outputs from all heads\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Project back to embed_size\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[123], line 38\u001b[0m, in \u001b[0;36mHead.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m     att \u001b[38;5;241m=\u001b[39m att\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Apply softmax and dropout\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m att \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43matt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(att)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Weighted aggregation of values\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/torch/nn/functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Model parameters\n",
    "vocab_size = 14  # 0-9 digits <PAD>, <EOS>, +, =,\n",
    "embed_size = 64\n",
    "num_heads = 2\n",
    "ff_dim = 128\n",
    "num_layers = 2\n",
    "max_length = 20\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(addition_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(addition_test, batch_size=batch_size)\n",
    "\n",
    "max_seq_length = max_length * 2 + 2  # This should be 42 based on your current setup\n",
    "model = SmallTransformer(vocab_size, embed_size, num_heads, ff_dim, num_layers, max_seq_length)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_size-2)  # Assuming <PAD> is the second to last token\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs)\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "Training Configuration for Arithmetic Transformer\n",
    "\n",
    "Model Architecture Parameters:\n",
    "- vocab_size = 14: Vocabulary consists of digits 0-9 and special tokens (+, =, <PAD>, <EOS>)\n",
    "- embed_size = 64: Dimension of the embedding vectors\n",
    "- num_heads = 2: Number of attention heads in transformer\n",
    "- head_size = 32: Size of each attention head (embed_size // num_heads)\n",
    "- ff_dim = 256: Feed-forward network dimension (4x embed_size for better capacity)\n",
    "- num_layers = 2: Number of transformer blocks\n",
    "- max_length = 20: Maximum length of individual numbers\n",
    "- max_seq_length = 42: Total sequence length (max_length * 2 + 2 for two numbers plus operators)\n",
    "\n",
    "Training Configuration:\n",
    "- batch_size = 32: Process 32 addition problems simultaneously\n",
    "- num_epochs = 10: Complete dataset processed 10 times\n",
    "- learning_rate = 0.001: Step size for optimizer\n",
    "\n",
    "Data Processing:\n",
    "- The dataset contains 200,000 unique addition problems\n",
    "- These are processed in batches of 32 problems each\n",
    "- Results in 6,250 batches per epoch (200,000/32)\n",
    "- Each epoch processes all 200,000 problems in shuffled order\n",
    "- By training end, each problem will have been practiced 10 times\n",
    "- Total training examples processed: 2,000,000 (200,000 * 10 epochs)\n",
    "\n",
    "Loss Function:\n",
    "- CrossEntropyLoss with padding token ignored\n",
    "- Padding token is second to last in vocabulary (index 12)\n",
    "\n",
    "Optimization:\n",
    "- Adam optimizer with standard parameters\n",
    "- Learning rate of 0.001 balances learning speed and stability\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = 14  # 0-9 digits <PAD>, <EOS>, +, =\n",
    "embed_size = 64\n",
    "num_heads = 2\n",
    "head_size = embed_size // num_heads  # 32 per head\n",
    "ff_dim = embed_size * 4  # Common practice to use 4x embed_size\n",
    "num_layers = 2\n",
    "max_length = 20\n",
    "max_seq_length = max_length * 2 + 2  # 42 for your setup, 2 numbers (max 20 digits each) + 2 operators\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(addition_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(addition_test, batch_size=batch_size)\n",
    "\n",
    "# Create the model\n",
    "model = ArithmeticTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    num_heads=num_heads,\n",
    "    head_size=head_size,\n",
    "    ff_dim=ff_dim,\n",
    "    num_layers=num_layers,\n",
    "    max_length=max_seq_length,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Set up training criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_size-2)  # Assuming <PAD> is the second to last token\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6250/6250 [04:59<00:00, 20.85it/s, loss=1.5418, acc=0.3628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3 - Time: 299.84s\n",
      "Train Loss: 1.7137, Train Accuracy: 0.3628\n",
      "Test Loss: 1.4692, Test Accuracy: 0.4373\n",
      "New best model saved with accuracy: 0.4373\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6250/6250 [03:29<00:00, 29.90it/s, loss=1.1592, acc=0.4868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3 - Time: 209.06s\n",
      "Train Loss: 1.3682, Train Accuracy: 0.4868\n",
      "Test Loss: 1.1929, Test Accuracy: 0.5485\n",
      "New best model saved with accuracy: 0.5485\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6250/6250 [03:30<00:00, 29.74it/s, loss=0.7269, acc=0.6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3 - Time: 210.15s\n",
      "Train Loss: 0.9683, Train Accuracy: 0.6340\n",
      "Test Loss: 0.4973, Test Accuracy: 0.7942\n",
      "New best model saved with accuracy: 0.7942\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "vocab_size = 14  # 0-9 digits <PAD>, <EOS>, +, =\n",
    "embed_size = 64\n",
    "num_heads = 2\n",
    "head_size = embed_size // num_heads  # 32 per head\n",
    "ff_dim = embed_size * 4  # Common practice to use 4x embed_size\n",
    "num_layers = 2\n",
    "max_length = 20\n",
    "max_seq_length = max_length * 2 + 2  # 42 for your setup, 2 numbers (max 20 digits each) + 2 operators\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create datasets\n",
    "train_samples = 200_000\n",
    "test_samples = 1_000\n",
    "addition_train = AdditionDataset(max_length, train_samples)\n",
    "addition_test = AdditionDataset(max_length, test_samples)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(addition_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(addition_test, batch_size=batch_size)\n",
    "\n",
    "# Create the model\n",
    "model = ArithmeticTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=embed_size,\n",
    "    num_heads=num_heads,\n",
    "    head_size=head_size,\n",
    "    ff_dim=ff_dim,\n",
    "    num_layers=num_layers,\n",
    "    max_length=max_seq_length,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Set up training criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_size-2)  # Assuming <PAD> is the second to last token\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model with embedding tracking\n",
    "model, embedding_history, loss_history, global_steps, chars_to_track = train_model_with_embedding_tracking(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and training history saved to arithmetic_model_embedding.pth\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# After training completes, save the model with full configuration\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embed_size': embed_size,\n",
    "    'num_heads': num_heads,\n",
    "    'head_size': head_size,\n",
    "    'ff_dim': ff_dim,\n",
    "    'num_layers': num_layers,\n",
    "    'max_seq_length': max_seq_length\n",
    "}, 'arithmetic_model.pth')\n",
    "\n",
    "print(\"Model training completed and saved!\")\n",
    "\n",
    "# Test the model on a few examples\n",
    "print(\"\\nTesting the trained model:\")\n",
    "'''\n",
    "\n",
    "\n",
    "# Save the complete model state\n",
    "save_path = 'arithmetic_model_embedding.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'embedding_history': embedding_history,\n",
    "    'loss_history': loss_history,\n",
    "    'global_steps': global_steps,\n",
    "    'chars_to_track': chars_to_track,\n",
    "    'model_config': {\n",
    "        'vocab_size': vocab_size,\n",
    "        'embed_size': embed_size,\n",
    "        'num_heads': num_heads,\n",
    "        'head_size': head_size,\n",
    "        'ff_dim': ff_dim,\n",
    "        'num_layers': num_layers,\n",
    "        'max_length': max_seq_length,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'vocab': addition_train.vocab,\n",
    "    'inv_vocab': addition_train.inv_vocab\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Model and training history saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and all components loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Load the saved model\n",
    "checkpoint = torch.load('trained_addition_model.pth')\n",
    "\n",
    "# Recreate the model architecture\n",
    "loaded_model = SmallTransformer(\n",
    "    checkpoint['vocab_size'],\n",
    "    checkpoint['embed_size'],\n",
    "    checkpoint['num_heads'],\n",
    "    checkpoint['ff_dim'],\n",
    "    checkpoint['num_layers'],\n",
    "    checkpoint['max_seq_length']\n",
    ")\n",
    "\n",
    "# Load the model weights\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Function to preprocess input for the model\n",
    "def preprocess_input(input_str, max_length):\n",
    "    # Reverse the input string\n",
    "    input_str = input_str[::-1]\n",
    "    # Tokenize\n",
    "    tokens = [addition_train.vocab[c] for c in input_str if c in addition_train.vocab]\n",
    "    # Pad\n",
    "    padded = tokens + [addition_train.vocab['<PAD>']] * (max_length - len(tokens))\n",
    "    return torch.tensor(padded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Function to decode model output\n",
    "def decode_output(output_tensor):\n",
    "    _, predicted = output_tensor.max(2)\n",
    "    decoded = ''.join([addition_train.inv_vocab[t.item()] for t in predicted[0] if t.item() not in [addition_train.vocab['<PAD>'], addition_train.vocab['<EOS>']]])\n",
    "    return decoded[::-1]  # Reverse the output\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Load the saved model Arithmetic Transformer version\n",
    "checkpoint = torch.load('arithmetic_model.pth')\n",
    "\n",
    "# Recreate the model architecture\n",
    "loaded_model = ArithmeticTransformer(\n",
    "    checkpoint['vocab_size'],\n",
    "    checkpoint['embed_size'],\n",
    "    checkpoint['num_heads'],\n",
    "    checkpoint['head_size'],\n",
    "    checkpoint['ff_dim'],\n",
    "    checkpoint['num_layers'],\n",
    "    checkpoint['max_seq_length']\n",
    ")\n",
    "\n",
    "# Load the model weights\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Function to preprocess input for the model\n",
    "def preprocess_input(input_str, max_length):\n",
    "    # Reverse the input string\n",
    "    input_str = input_str[::-1]\n",
    "    # Tokenize\n",
    "    tokens = [addition_train.vocab[c] for c in input_str if c in addition_train.vocab]\n",
    "    # Pad\n",
    "    padded = tokens + [addition_train.vocab['<PAD>']] * (max_length - len(tokens))\n",
    "    return torch.tensor(padded).unsqueeze(0)  # Add\n",
    "\n",
    "# Function to decode model output\n",
    "def decode_output(output_tensor):\n",
    "    _, predicted = output_tensor.max(2)\n",
    "    decoded = []\n",
    "    for token in predicted[0]:\n",
    "        token_val = token.item()\n",
    "        if token_val == addition_train.vocab['<EOS>']:\n",
    "            break\n",
    "        if token_val != addition_train.vocab['<PAD>']:\n",
    "            decoded.append(addition_train.inv_vocab[token_val])\n",
    "    return ''.join(decoded)[::-1]  # Reverse at the end\n",
    "'''\n",
    "\n",
    "# Load the complete saved state\n",
    "checkpoint = torch.load('arithmetic_model_embedding.pth')\n",
    "\n",
    "# Extract the model configuration\n",
    "config = checkpoint['model_config']\n",
    "\n",
    "# Recreate the model\n",
    "loaded_model = ArithmeticTransformer(\n",
    "    vocab_size=config['vocab_size'],\n",
    "    embed_size=config['embed_size'],\n",
    "    num_heads=config['num_heads'],\n",
    "    head_size=config['head_size'],\n",
    "    ff_dim=config['ff_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    max_length=config['max_length'],\n",
    "    dropout=config['dropout']\n",
    ")\n",
    "\n",
    "# Load the model state dictionary\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Create optimizer (if needed)\n",
    "loaded_optimizer = optim.Adam(loaded_model.parameters(), lr=0.001)  # or whatever learning rate you want\n",
    "loaded_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Load training history and data\n",
    "loaded_embedding_history = checkpoint['embedding_history']\n",
    "loaded_loss_history = checkpoint['loss_history']\n",
    "loaded_global_steps = checkpoint['global_steps']\n",
    "loaded_chars_to_track = checkpoint['chars_to_track']\n",
    "loaded_vocab = checkpoint['vocab']\n",
    "loaded_inv_vocab = checkpoint['inv_vocab']\n",
    "\n",
    "# Set model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model and all components loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single-digit additions...\n",
      "0 + 0 = 0\n",
      "Correct result: 0\n",
      "Model's prediction is correct\n",
      "0 + 1 = 1\n",
      "Correct result: 1\n",
      "Model's prediction is correct\n",
      "0 + 2 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "0 + 3 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "0 + 4 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "0 + 5 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "0 + 6 = 16\n",
      "Correct result: 6\n",
      "Model's prediction is incorrect\n",
      "0 + 7 = 17\n",
      "Correct result: 7\n",
      "Model's prediction is incorrect\n",
      "0 + 8 = 18\n",
      "Correct result: 8\n",
      "Model's prediction is incorrect\n",
      "0 + 9 = 19\n",
      "Correct result: 9\n",
      "Model's prediction is incorrect\n",
      "1 + 0 = 1\n",
      "Correct result: 1\n",
      "Model's prediction is correct\n",
      "1 + 1 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "1 + 2 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "1 + 3 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "1 + 4 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "1 + 5 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "1 + 6 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "1 + 7 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "1 + 8 = 19\n",
      "Correct result: 9\n",
      "Model's prediction is incorrect\n",
      "1 + 9 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "2 + 0 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "2 + 1 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "2 + 2 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "2 + 3 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "2 + 4 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "2 + 5 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "2 + 6 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "2 + 7 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "2 + 8 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "2 + 9 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "3 + 0 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "3 + 1 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "3 + 2 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "3 + 3 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "3 + 4 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "3 + 5 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "3 + 6 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "3 + 7 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "3 + 8 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "3 + 9 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "4 + 0 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "4 + 1 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "4 + 2 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "4 + 3 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "4 + 4 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "4 + 5 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "4 + 6 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "4 + 7 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "4 + 8 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "4 + 9 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "5 + 0 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "5 + 1 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "5 + 2 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "5 + 3 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "5 + 4 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "5 + 5 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "5 + 6 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "5 + 7 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "5 + 8 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "5 + 9 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "6 + 0 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "6 + 1 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "6 + 2 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "6 + 3 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "6 + 4 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "6 + 5 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "6 + 6 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "6 + 7 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "6 + 8 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "6 + 9 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "7 + 0 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "7 + 1 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "7 + 2 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "7 + 3 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "7 + 4 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "7 + 5 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "7 + 6 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "7 + 7 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "7 + 8 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "7 + 9 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "8 + 0 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "8 + 1 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "8 + 2 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "8 + 3 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "8 + 4 = 2\n",
      "Correct result: 12\n",
      "Model's prediction is incorrect\n",
      "8 + 5 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "8 + 6 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "8 + 7 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "8 + 8 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "8 + 9 = 17\n",
      "Correct result: 17\n",
      "Model's prediction is correct\n",
      "9 + 0 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "9 + 1 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "9 + 2 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "9 + 3 = 2\n",
      "Correct result: 12\n",
      "Model's prediction is incorrect\n",
      "9 + 4 = 3\n",
      "Correct result: 13\n",
      "Model's prediction is incorrect\n",
      "9 + 5 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "9 + 6 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "9 + 7 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "9 + 8 = 17\n",
      "Correct result: 17\n",
      "Model's prediction is correct\n",
      "9 + 9 = 18\n",
      "Correct result: 18\n",
      "Model's prediction is correct\n",
      "\n",
      "Model accuracy on single-digit additions: 0.8100\n",
      "\n",
      "Testing commutative property...\n",
      "0 + 0 = 0\n",
      "Correct result: 0\n",
      "Model's prediction is correct\n",
      "0 + 0 = 0\n",
      "Correct result: 0\n",
      "Model's prediction is correct\n",
      "0 + 1 = 1\n",
      "Correct result: 1\n",
      "Model's prediction is correct\n",
      "1 + 0 = 1\n",
      "Correct result: 1\n",
      "Model's prediction is correct\n",
      "0 + 2 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "2 + 0 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "0 + 3 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "3 + 0 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "0 + 4 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "4 + 0 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "0 + 5 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "5 + 0 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "0 + 6 = 16\n",
      "Correct result: 6\n",
      "Model's prediction is incorrect\n",
      "6 + 0 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "0 + 7 = 17\n",
      "Correct result: 7\n",
      "Model's prediction is incorrect\n",
      "7 + 0 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "0 + 8 = 18\n",
      "Correct result: 8\n",
      "Model's prediction is incorrect\n",
      "8 + 0 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "0 + 9 = 19\n",
      "Correct result: 9\n",
      "Model's prediction is incorrect\n",
      "9 + 0 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "1 + 1 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "1 + 1 = 2\n",
      "Correct result: 2\n",
      "Model's prediction is correct\n",
      "1 + 2 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "2 + 1 = 3\n",
      "Correct result: 3\n",
      "Model's prediction is correct\n",
      "1 + 3 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "3 + 1 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "1 + 4 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "4 + 1 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "1 + 5 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "5 + 1 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "1 + 6 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "6 + 1 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "1 + 7 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "7 + 1 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "1 + 8 = 19\n",
      "Correct result: 9\n",
      "Model's prediction is incorrect\n",
      "8 + 1 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "1 + 9 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "9 + 1 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "2 + 2 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "2 + 2 = 4\n",
      "Correct result: 4\n",
      "Model's prediction is correct\n",
      "2 + 3 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "3 + 2 = 5\n",
      "Correct result: 5\n",
      "Model's prediction is correct\n",
      "2 + 4 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "4 + 2 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "2 + 5 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "5 + 2 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "2 + 6 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "6 + 2 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "2 + 7 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "7 + 2 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "2 + 8 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "8 + 2 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "2 + 9 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "9 + 2 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "3 + 3 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "3 + 3 = 6\n",
      "Correct result: 6\n",
      "Model's prediction is correct\n",
      "3 + 4 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "4 + 3 = 7\n",
      "Correct result: 7\n",
      "Model's prediction is correct\n",
      "3 + 5 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "5 + 3 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "3 + 6 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "6 + 3 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "3 + 7 = 10\n",
      "Correct result: 10\n",
      "Model's prediction is correct\n",
      "7 + 3 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "3 + 8 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "8 + 3 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "3 + 9 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "9 + 3 = 2\n",
      "Correct result: 12\n",
      "Model's prediction is incorrect\n",
      "4 + 4 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "4 + 4 = 8\n",
      "Correct result: 8\n",
      "Model's prediction is correct\n",
      "4 + 5 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "5 + 4 = 9\n",
      "Correct result: 9\n",
      "Model's prediction is correct\n",
      "4 + 6 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "6 + 4 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "4 + 7 = 11\n",
      "Correct result: 11\n",
      "Model's prediction is correct\n",
      "7 + 4 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "4 + 8 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "8 + 4 = 2\n",
      "Correct result: 12\n",
      "Model's prediction is incorrect\n",
      "4 + 9 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "9 + 4 = 3\n",
      "Correct result: 13\n",
      "Model's prediction is incorrect\n",
      "5 + 5 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "5 + 5 = 0\n",
      "Correct result: 10\n",
      "Model's prediction is incorrect\n",
      "5 + 6 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "6 + 5 = 1\n",
      "Correct result: 11\n",
      "Model's prediction is incorrect\n",
      "5 + 7 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "7 + 5 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "5 + 8 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "8 + 5 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "5 + 9 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "9 + 5 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "6 + 6 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "6 + 6 = 12\n",
      "Correct result: 12\n",
      "Model's prediction is correct\n",
      "6 + 7 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "7 + 6 = 13\n",
      "Correct result: 13\n",
      "Model's prediction is correct\n",
      "6 + 8 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "8 + 6 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "6 + 9 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "9 + 6 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "7 + 7 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "7 + 7 = 14\n",
      "Correct result: 14\n",
      "Model's prediction is correct\n",
      "7 + 8 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "8 + 7 = 15\n",
      "Correct result: 15\n",
      "Model's prediction is correct\n",
      "7 + 9 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "9 + 7 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "8 + 8 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "8 + 8 = 16\n",
      "Correct result: 16\n",
      "Model's prediction is correct\n",
      "8 + 9 = 17\n",
      "Correct result: 17\n",
      "Model's prediction is correct\n",
      "9 + 8 = 17\n",
      "Correct result: 17\n",
      "Model's prediction is correct\n",
      "9 + 9 = 18\n",
      "Correct result: 18\n",
      "Model's prediction is correct\n",
      "9 + 9 = 18\n",
      "Correct result: 18\n",
      "Model's prediction is correct\n",
      "\n",
      "Model accuracy on commutative additions: 0.8182\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def test_addition(num1, num2):\n",
    "    input_str = f\"{num1}+{num2}=\"\n",
    "    input_tensor = preprocess_input(input_str, checkpoint['max_seq_length'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_tensor)\n",
    "        \n",
    "    result = decode_output(output)\n",
    "    print(f\"{num1} + {num2} = {result}\")\n",
    "    print(f\"Correct result: {num1 + num2}\")\n",
    "    print(f\"Model's prediction is {'correct' if int(result) == num1 + num2 else 'incorrect'}\")\n",
    "    \n",
    "    # Return the predicted result as an integer\n",
    "    return int(result)\n",
    "\n",
    "\n",
    "# Test it\n",
    "#test_addition(4, 5)\n",
    "#test_addition(6, 6)\n",
    "#test_addition(10670, 990)\n",
    "#test_addition(12379, 9821)\n",
    "#test_addition(9821, 12379)\n",
    "\n",
    "# Test all possible single-digit additions\n",
    "# And check model accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        predicted = test_addition(i, j)\n",
    "        total += 1\n",
    "        if i + j == predicted:\n",
    "            correct += 1\n",
    "            \n",
    "print(f\"\\nModel accuracy on single-digit additions: {correct/total:.4f}\")\n",
    "\n",
    "# Check Commutative Property, accuracy should be 1.0\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    for j in range(i, 10):\n",
    "        predicted1 = test_addition(i, j)\n",
    "        predicted2 = test_addition(j, i)\n",
    "        total += 2\n",
    "        if i + j == predicted1:\n",
    "            correct += 1\n",
    "        if i + j == predicted2:\n",
    "            correct += 1\n",
    "\n",
    "print(f\"\\nModel accuracy on commutative additions: {correct/total:.4f}\")\n",
    "'''\n",
    "\n",
    "def test_addition(num1, num2):\n",
    "    # Calculate max_seq_length from the model's config\n",
    "    max_seq_length = checkpoint['model_config']['max_length']  # This is already set to max_length * 2 + 2\n",
    "    \n",
    "    input_str = f\"{num1}+{num2}=\"\n",
    "    input_tensor = preprocess_input(input_str, max_seq_length)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_tensor)\n",
    "        \n",
    "    result = decode_output(output)\n",
    "    print(f\"{num1} + {num2} = {result}\")\n",
    "    print(f\"Correct result: {num1 + num2}\")\n",
    "    print(f\"Model's prediction is {'correct' if int(result) == num1 + num2 else 'incorrect'}\")\n",
    "    \n",
    "    # Return the predicted result as an integer\n",
    "    return int(result)\n",
    "\n",
    "# Test single digit additions\n",
    "print(\"Testing single-digit additions...\")\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        predicted = test_addition(i, j)\n",
    "        total += 1\n",
    "        if i + j == predicted:\n",
    "            correct += 1\n",
    "            \n",
    "print(f\"\\nModel accuracy on single-digit additions: {correct/total:.4f}\")\n",
    "\n",
    "# Test commutative property\n",
    "print(\"\\nTesting commutative property...\")\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    for j in range(i, 10):\n",
    "        predicted1 = test_addition(i, j)\n",
    "        predicted2 = test_addition(j, i)\n",
    "        total += 2\n",
    "        if i + j == predicted1:\n",
    "            correct += 1\n",
    "        if i + j == predicted2:\n",
    "            correct += 1\n",
    "\n",
    "print(f\"\\nModel accuracy on commutative additions: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0:\n",
      "  Top 1: Token '9' with probability 1.000\n",
      "  Top 2: Token '0' with probability 0.000\n",
      "  Top 3: Token '8' with probability 0.000\n",
      "\n",
      "Position 1:\n",
      "  Top 1: Token '1' with probability 0.618\n",
      "  Top 2: Token '<EOS>' with probability 0.355\n",
      "  Top 3: Token '0' with probability 0.011\n",
      "\n",
      "Position 2:\n",
      "  Top 1: Token '<EOS>' with probability 0.995\n",
      "  Top 2: Token '1' with probability 0.005\n",
      "  Top 3: Token '4' with probability 0.000\n",
      "\n",
      "Position 3:\n",
      "  Top 1: Token '<EOS>' with probability 1.000\n",
      "  Top 2: Token '1' with probability 0.000\n",
      "  Top 3: Token '8' with probability 0.000\n",
      "\n",
      "Position 4:\n",
      "  Top 1: Token '<EOS>' with probability 0.997\n",
      "  Top 2: Token '3' with probability 0.002\n",
      "  Top 3: Token '1' with probability 0.000\n",
      "\n",
      "Position 5:\n",
      "  Top 1: Token '<EOS>' with probability 0.999\n",
      "  Top 2: Token '3' with probability 0.000\n",
      "  Top 3: Token '8' with probability 0.000\n",
      "\n",
      "Position 6:\n",
      "  Top 1: Token '<EOS>' with probability 0.999\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '1' with probability 0.000\n",
      "\n",
      "Position 7:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '1' with probability 0.000\n",
      "\n",
      "Position 8:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '1' with probability 0.000\n",
      "\n",
      "Position 9:\n",
      "  Top 1: Token '<EOS>' with probability 0.932\n",
      "  Top 2: Token '4' with probability 0.022\n",
      "  Top 3: Token '3' with probability 0.021\n",
      "\n",
      "Position 10:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '1' with probability 0.001\n",
      "\n",
      "Position 11:\n",
      "  Top 1: Token '<EOS>' with probability 1.000\n",
      "  Top 2: Token '1' with probability 0.000\n",
      "  Top 3: Token '3' with probability 0.000\n",
      "\n",
      "Position 12:\n",
      "  Top 1: Token '<EOS>' with probability 0.999\n",
      "  Top 2: Token '1' with probability 0.001\n",
      "  Top 3: Token '3' with probability 0.000\n",
      "\n",
      "Position 13:\n",
      "  Top 1: Token '<EOS>' with probability 1.000\n",
      "  Top 2: Token '3' with probability 0.000\n",
      "  Top 3: Token '4' with probability 0.000\n",
      "\n",
      "Position 14:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '7' with probability 0.000\n",
      "\n",
      "Position 15:\n",
      "  Top 1: Token '<EOS>' with probability 0.999\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '8' with probability 0.000\n",
      "\n",
      "Position 16:\n",
      "  Top 1: Token '<EOS>' with probability 0.992\n",
      "  Top 2: Token '3' with probability 0.003\n",
      "  Top 3: Token '1' with probability 0.002\n",
      "\n",
      "Position 17:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '1' with probability 0.002\n",
      "  Top 3: Token '4' with probability 0.000\n",
      "\n",
      "Position 18:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '4' with probability 0.000\n",
      "\n",
      "Position 19:\n",
      "  Top 1: Token '<EOS>' with probability 0.998\n",
      "  Top 2: Token '1' with probability 0.001\n",
      "  Top 3: Token '3' with probability 0.000\n",
      "\n",
      "Position 20:\n",
      "  Top 1: Token '<EOS>' with probability 1.000\n",
      "  Top 2: Token '1' with probability 0.000\n",
      "  Top 3: Token '2' with probability 0.000\n",
      "\n",
      "Position 21:\n",
      "  Top 1: Token '<EOS>' with probability 1.000\n",
      "  Top 2: Token '1' with probability 0.000\n",
      "  Top 3: Token '4' with probability 0.000\n",
      "\n",
      "Position 22:\n",
      "  Top 1: Token '<EOS>' with probability 0.999\n",
      "  Top 2: Token '3' with probability 0.001\n",
      "  Top 3: Token '7' with probability 0.000\n",
      "\n",
      "Position 23:\n",
      "  Top 1: Token '<EOS>' with probability 0.672\n",
      "  Top 2: Token '3' with probability 0.266\n",
      "  Top 3: Token '8' with probability 0.018\n",
      "\n",
      "Position 24:\n",
      "  Top 1: Token '<EOS>' with probability 0.810\n",
      "  Top 2: Token '3' with probability 0.128\n",
      "  Top 3: Token '9' with probability 0.019\n",
      "\n",
      "Position 25:\n",
      "  Top 1: Token '9' with probability 0.382\n",
      "  Top 2: Token '0' with probability 0.228\n",
      "  Top 3: Token '3' with probability 0.154\n",
      "\n",
      "Position 26:\n",
      "  Top 1: Token '3' with probability 0.436\n",
      "  Top 2: Token '1' with probability 0.241\n",
      "  Top 3: Token '<EOS>' with probability 0.204\n",
      "\n",
      "Position 27:\n",
      "  Top 1: Token '<EOS>' with probability 0.805\n",
      "  Top 2: Token '5' with probability 0.084\n",
      "  Top 3: Token '8' with probability 0.075\n",
      "\n",
      "Position 28:\n",
      "  Top 1: Token '1' with probability 0.727\n",
      "  Top 2: Token '9' with probability 0.145\n",
      "  Top 3: Token '3' with probability 0.076\n",
      "\n",
      "Position 29:\n",
      "  Top 1: Token '1' with probability 0.311\n",
      "  Top 2: Token '3' with probability 0.266\n",
      "  Top 3: Token '<EOS>' with probability 0.232\n",
      "\n",
      "Position 30:\n",
      "  Top 1: Token '1' with probability 0.786\n",
      "  Top 2: Token '0' with probability 0.115\n",
      "  Top 3: Token '9' with probability 0.040\n",
      "\n",
      "Position 31:\n",
      "  Top 1: Token '1' with probability 0.535\n",
      "  Top 2: Token '0' with probability 0.238\n",
      "  Top 3: Token '9' with probability 0.166\n",
      "\n",
      "Position 32:\n",
      "  Top 1: Token '1' with probability 0.594\n",
      "  Top 2: Token '0' with probability 0.185\n",
      "  Top 3: Token '3' with probability 0.097\n",
      "\n",
      "Position 33:\n",
      "  Top 1: Token '1' with probability 0.658\n",
      "  Top 2: Token '0' with probability 0.181\n",
      "  Top 3: Token '9' with probability 0.108\n",
      "\n",
      "Position 34:\n",
      "  Top 1: Token '9' with probability 0.442\n",
      "  Top 2: Token '1' with probability 0.384\n",
      "  Top 3: Token '0' with probability 0.132\n",
      "\n",
      "Position 35:\n",
      "  Top 1: Token '1' with probability 0.423\n",
      "  Top 2: Token '0' with probability 0.303\n",
      "  Top 3: Token '9' with probability 0.238\n",
      "\n",
      "Position 36:\n",
      "  Top 1: Token '1' with probability 0.452\n",
      "  Top 2: Token '9' with probability 0.406\n",
      "  Top 3: Token '0' with probability 0.117\n",
      "\n",
      "Position 37:\n",
      "  Top 1: Token '1' with probability 0.798\n",
      "  Top 2: Token '9' with probability 0.103\n",
      "  Top 3: Token '0' with probability 0.083\n",
      "\n",
      "Position 38:\n",
      "  Top 1: Token '1' with probability 0.600\n",
      "  Top 2: Token '0' with probability 0.225\n",
      "  Top 3: Token '3' with probability 0.094\n",
      "\n",
      "Position 39:\n",
      "  Top 1: Token '<EOS>' with probability 0.875\n",
      "  Top 2: Token '3' with probability 0.108\n",
      "  Top 3: Token '4' with probability 0.012\n",
      "\n",
      "Position 40:\n",
      "  Top 1: Token '1' with probability 0.542\n",
      "  Top 2: Token '0' with probability 0.326\n",
      "  Top 3: Token '9' with probability 0.074\n",
      "\n",
      "Position 41:\n",
      "  Top 1: Token '9' with probability 0.487\n",
      "  Top 2: Token '0' with probability 0.235\n",
      "  Top 3: Token '1' with probability 0.220\n",
      "\n",
      "Final output: 91111191111113919\n",
      "Correct result: 9\n"
     ]
    }
   ],
   "source": [
    "def debug_model_output(num1, num2):\n",
    "    input_str = f\"{num1}+{num2}=\"\n",
    "    input_tensor = preprocess_input(input_str, checkpoint['max_seq_length'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_tensor)\n",
    "        \n",
    "    # Look at raw logits\n",
    "    logits = output[0]  # Remove batch dimension\n",
    "    \n",
    "    # Print token probabilities for each position\n",
    "    for pos in range(len(logits)):\n",
    "        probs = F.softmax(logits[pos], dim=0)\n",
    "        top_tokens = torch.topk(probs, 3)\n",
    "        print(f\"\\nPosition {pos}:\")\n",
    "        for i, (prob, token_idx) in enumerate(zip(top_tokens.values, top_tokens.indices)):\n",
    "            token = addition_train.inv_vocab[token_idx.item()]\n",
    "            print(f\"  Top {i+1}: Token '{token}' with probability {prob:.3f}\")\n",
    "    \n",
    "    result = decode_output(output)\n",
    "    print(f\"\\nFinal output: {result}\")\n",
    "    print(f\"Correct result: {num1 + num2}\")\n",
    "\n",
    "# Test with a simple example\n",
    "debug_model_output(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_test_set(num_samples, max_digits):\n",
    "    test_set = []\n",
    "    for _ in range(num_samples):\n",
    "        num1 = random.randint(1, 10**max_digits - 1)\n",
    "        num2 = random.randint(1, 10**max_digits - 1)\n",
    "        result = num1 + num2\n",
    "        test_set.append((num1, num2, result))\n",
    "    return test_set\n",
    "\n",
    "# Generate a test set\n",
    "num_test_samples = 1000\n",
    "max_test_digits = 20  # Maximum number of digits in each operand\n",
    "test_set = generate_test_set(num_test_samples, max_test_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy: 0.6875\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m evaluate_on_dataset(loaded_model, train_loader_for_eval, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate on test data for comparison\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m evaluate_on_dataset(loaded_model, \u001b[43mtest_loader\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Print comparison\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccuracy comparison:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_on_dataset(model, dataloader, dataset_name=\"Dataset\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(2)\n",
    "            \n",
    "            # Create a mask for non-padding tokens\n",
    "            non_pad_mask = targets.ne(addition_train.vocab['<PAD>'])\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct += (predicted[non_pad_mask] == targets[non_pad_mask]).sum().item()\n",
    "            total += non_pad_mask.sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"{dataset_name} Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "train_loader_for_eval = DataLoader(addition_train, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_accuracy = evaluate_on_dataset(loaded_model, train_loader_for_eval, \"Training Data\")\n",
    "\n",
    "# Evaluate on test data for comparison\n",
    "test_accuracy = evaluate_on_dataset(loaded_model, test_loader, \"Test Data\")\n",
    "\n",
    "# Print comparison\n",
    "print(f\"\\nAccuracy comparison:\")\n",
    "print(f\"Training Data: {train_accuracy:.4f}\")\n",
    "print(f\"Test Data:     {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 100 large number samples (21-30 digits): 0.0000\n",
      "Testing on specific addition patterns:\n",
      "999999 + 1 = 99991999900 (True: 1000000)\n",
      "Correct: False\n",
      "\n",
      "1 + 999999 = 11999000 (True: 1000000)\n",
      "Correct: False\n",
      "\n",
      "999999999999999 + 1 = 00999990099999990999999999999999900 (True: 1000000000000000)\n",
      "Correct: False\n",
      "\n",
      "1000000000000000 + 1000000000000000 = 0000011010002000000000000000 (True: 2000000000000000)\n",
      "Correct: False\n",
      "\n",
      "123456789 + 987654321 = 91951616571110877600 (True: 1111111110)\n",
      "Correct: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_larger_additions(model, max_seq_length, num_samples=100):\n",
    "    correct = 0\n",
    "    for _ in range(num_samples):\n",
    "        num1 = random.randint(10**20, 10**30 - 1)  # 21 to 30 digit numbers\n",
    "        num2 = random.randint(10**20, 10**30 - 1)\n",
    "        true_result = num1 + num2\n",
    "        \n",
    "        input_str = f\"{num1}+{num2}=\"\n",
    "        input_tensor = preprocess_input(input_str, max_seq_length)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "        \n",
    "        predicted_result = decode_output(output)\n",
    "        \n",
    "        try:\n",
    "            if int(predicted_result) == true_result:\n",
    "                correct += 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    accuracy = correct / num_samples\n",
    "    print(f\"Accuracy on {num_samples} large number samples (21-30 digits): {accuracy:.4f}\")\n",
    "\n",
    "# Test on larger numbers\n",
    "test_larger_additions(loaded_model, checkpoint['max_seq_length'])\n",
    "\n",
    "def test_specific_patterns(model, max_seq_length):\n",
    "    test_cases = [\n",
    "        (999999, 1),  # Testing carry over\n",
    "        (1, 999999),  # Testing different order\n",
    "        (10**15 - 1, 1),  # Large number + small number\n",
    "        (10**15, 10**15),  # Two large, round numbers\n",
    "        (123456789, 987654321),  # Ascending + descending\n",
    "    ]\n",
    "    \n",
    "    for num1, num2 in test_cases:\n",
    "        input_str = f\"{num1}+{num2}=\"\n",
    "        input_tensor = preprocess_input(input_str, max_seq_length)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "        \n",
    "        predicted_result = decode_output(output)\n",
    "        true_result = num1 + num2\n",
    "        \n",
    "        print(f\"{num1} + {num2} = {predicted_result} (True: {true_result})\")\n",
    "        print(f\"Correct: {int(predicted_result) == true_result}\")\n",
    "        print()\n",
    "\n",
    "# Test on specific patterns\n",
    "print(\"Testing on specific addition patterns:\")\n",
    "test_specific_patterns(loaded_model, checkpoint['max_seq_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo  # Better alternative to torchsummary for transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
      "==========================================================================================================================================================================\n",
      "SmallTransformer                              [32, 42]                  [32, 42, 14]              33,472                    --                        --\n",
      "├─AbacusEmbedding: 1-1                        [32, 42]                  [32, 42, 64]              --                        --                        --\n",
      "│    └─Embedding: 2-1                         [32, 42]                  [32, 42, 64]              896                       --                        28,672\n",
      "│    └─Embedding: 2-2                         [1, 42]                   [1, 42, 64]               2,688                     --                        2,688\n",
      "├─TransformerEncoder: 1-2                     [32, 42, 64]              [32, 42, 64]              --                        --                        --\n",
      "│    └─ModuleList: 2-3                        --                        --                        --                        --                        --\n",
      "│    │    └─TransformerEncoderLayer: 3-1      [32, 42, 64]              [32, 42, 64]              33,472                    --                        --\n",
      "│    │    └─TransformerEncoderLayer: 3-2      [32, 42, 64]              [32, 42, 64]              33,472                    --                        --\n",
      "├─Linear: 1-3                                 [32, 42, 64]              [32, 42, 14]              910                       --                        29,120\n",
      "==========================================================================================================================================================================\n",
      "Total params: 104,910\n",
      "Trainable params: 104,910\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.06\n",
      "==========================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.86\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.89\n",
      "==========================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import torchinfo  # Better alternative to torchsummary for transformers\n",
    "\n",
    "def summarize_transformer(model, batch_size=32, seq_length=42, vocab_size=None):\n",
    "    \"\"\"\n",
    "    Provides a detailed summary of a transformer model using torchinfo.\n",
    "    \n",
    "    Args:\n",
    "        model: The transformer model to analyze\n",
    "        batch_size: Number of samples in a batch\n",
    "        seq_length: Length of input sequences\n",
    "        vocab_size: Size of vocabulary (if None, will use model's vocab_size if available)\n",
    "    \"\"\"\n",
    "    # Create dummy input tensor with proper dtype\n",
    "    if vocab_size is None:\n",
    "        try:\n",
    "            vocab_size = model.vocab_size\n",
    "        except AttributeError:\n",
    "            vocab_size = 1000  # default fallback\n",
    "    \n",
    "    # Generate random indices within vocab size range\n",
    "    dummy_input = torch.randint(0, vocab_size, (batch_size, seq_length), dtype=torch.long)\n",
    "    \n",
    "    # Get model summary\n",
    "    summary = torchinfo.summary(\n",
    "        model,\n",
    "        input_data=dummy_input,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
    "        depth=4,  # Adjust this to see more/less layers\n",
    "        device='cpu'  # Change to 'cuda' if using GPU\n",
    "    )\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "    # Get model summary\n",
    "summary = summarize_transformer(\n",
    "    loaded_model,\n",
    "    batch_size=32,\n",
    "    seq_length=42,\n",
    "    vocab_size=checkpoint['vocab_size']\n",
    "    )\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Transformer Model for Arithmetic Operations\n",
    "\n",
    "This is a compact transformer model designed for arithmetic tasks. Here's a breakdown of its architecture:\n",
    "\n",
    "## Model Overview\n",
    "- **Total Parameters**: 104,910 (very lightweight!)\n",
    "- **Memory Footprint**: Only 0.89 MB\n",
    "- **Max Sequence Length**: 42 tokens\n",
    "- **Embedding Dimension**: 64\n",
    "- **Vocabulary Size**: 14 (likely digits 0-9 plus special tokens)\n",
    "\n",
    "## Architecture Components\n",
    "\n",
    "### 1. Input Processing (AbacusEmbedding)\n",
    "- **Token Embedding**: Converts each input number/symbol into a 64-dimensional vector\n",
    "- **Positional Embedding**: Adds position information to each token to maintain sequence order\n",
    "- These embeddings combine to give the model understanding of both WHAT each token is and WHERE it appears\n",
    "\n",
    "### 2. Transformer Encoder\n",
    "- **Number of Layers**: 2\n",
    "- Each layer contains:\n",
    " - Self-attention mechanism (allows model to weigh importance of different positions)\n",
    " - Feed-forward neural network\n",
    "- Helps model understand relationships between different positions in the input sequence\n",
    "\n",
    "### 3. Output Layer\n",
    "- Linear projection layer that converts the 64-dimensional features back to vocabulary size (14)\n",
    "- Produces predictions for each position in the sequence\n",
    "\n",
    "This model's architecture suggests it's optimized for tasks like addition or basic arithmetic, where it needs to process sequences of numbers and operators. The small vocabulary size (14) is perfect for digits 0-9 plus a few special tokens (like '+', '=', etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdYAAAHqCAYAAAAJexwOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3zTdf4H8Nc3oxnde9EFZW/hZMtSTvCUH+K5B8vtOXCcuFGUk/OU81RwlKKiiHd4yqmgoAIOkI2ICAU6aUv3zE6+vz+Sb5q0aWlKmrTwej4efdB88x3vpIjpK++8P4IoiiKIiIiIiIiIiIiIiKhdZIEugIiIiIiIiIiIiIioO2GwTkRERERERERERETkBQbrREREREREREREREReYLBOREREREREREREROQFButERERERERERERERF5gsE5ERERERERERERE5AUG60REREREREREREREXmCwTkRERERERERERETkBQbrREREREREREREREReYLBOROclQRDa9bV169azus4zzzwDQRA6dOzWrVt9UsPZXPs///mP369NRERE1N2tXr26U19jupo0aRIGDRrks/O1JT09HXPmzDnjftLjz8vLc26bNGkSJk2a1Gm1tWXSpEmt/izS09M77bpn83pep9PhmWee8Xisp+eXiIj8TxHoAoiIAmHHjh1ut5977jl89913+Pbbb922Dxgw4Kyus2DBAlx66aUdOvaCCy7Ajh07zroGIiIiIgqM7Oxs9OvXr8X28/H13RtvvBHQ6/fs2RMffPBBi+0qlSoA1ZyZTqfD4sWLAaDFGxKXXXYZduzYgcTExABURkREEgbrRHReGj16tNvt2NhYyGSyFtub0+l00Gq17b5Ojx490KNHjw7VGBYWdsZ6iIiIiKjrGjRoEEaOHBnoMrqEQL+ZoNFozpnX1rGxsYiNjQ10GURE5z2OgiEiaoX0sdrt27dj7Nix0Gq1mDdvHgBg3bp1mDZtGhITE6HRaNC/f388+uijaGxsdDuHp1Ew6enp+NOf/oRNmzbhggsugEajQb9+/bBq1Sq3/Tx9dHTOnDkICQnB8ePHMWPGDISEhCAlJQUPPvggjEaj2/FFRUW46qqrEBoaioiICNxwww3YvXs3BEHA6tWrffIc/frrr5g5cyYiIyOhVqsxbNgwvPvuu2772Gw2LFmyBH379oVGo0FERASGDBmCf/7zn859ysvLcdtttyElJQUqlQqxsbEYN24ctmzZ4pM6iYiIiLoqQRBwzz33IDs72/l6aeTIkdi5cydEUcTf//53ZGRkICQkBFOmTMHx48c9nuf777/H6NGjodFokJycjCeffBJWq9VtH5PJhCVLlqBfv37O11xz585FeXm5235msxmPPPIIEhISoNVqMX78eOzatcvjdXfu3Ilx48ZBrVYjKSkJixYtgtlsbrFf81EweXl5EAQBL730El5++WXnYxwzZgx27tzZ4vi3334bffr0gUqlwoABA/Dhhx9izpw5PhvlcvDgQQiCgKysrBb3bdy4EYIgYMOGDc5tP/zwA6ZOnYrQ0FBotVqMHTsWX3zxxRmv09pIHNfHkpeX5wzOFy9e7BxbI43haW0UzKpVqzB06FCo1WpERUVh1qxZOHLkSIvrtPf3CSIiahs71omI2lBSUoIbb7wRjzzyCF544QXIZPb3I3NycjBjxgzcf//9CA4Oxu+//44XX3wRu3btajFOxpODBw/iwQcfxKOPPor4+Hi88847mD9/PjIzM3HRRRe1eazZbMYVV1yB+fPn48EHH8T27dvx3HPPITw8HE899RQAoLGxEZMnT0ZVVRVefPFFZGZmYtOmTbjmmmvO/klxOHr0KMaOHYu4uDi8+uqriI6Oxpo1azBnzhycPn0ajzzyCABg2bJleOaZZ/DEE0/goosugtlsxu+//46amhrnuW666Sbs27cPzz//PPr06YOamhrs27cPlZWVPquXiIiIyN+sVissFovbNkEQIJfL3bZ9/vnn2L9/P/72t79BEAT89a9/xWWXXYZbbrkFJ0+exGuvvYba2losXLgQs2fPxoEDB9yaN0pLS3Httdfi0UcfxbPPPosvvvgCS5YsQXV1NV577TUA9maHmTNn4vvvv8cjjzyCsWPHIj8/H08//TQmTZqEPXv2QKPRAABuvfVWvPfee3jooYdwySWX4Ndff8WVV16J+vp6t7p/++03TJ06Fenp6Vi9ejW0Wi3eeOMNfPjhh+1+jl5//XX069cPy5cvBwA8+eSTmDFjBnJzcxEeHg4AeOutt3D77bdj9uzZeOWVV1BbW4vFixd7HQQ3/1kAgEwmg0wmw9ChQzF8+HBkZ2dj/vz5bvusXr0acXFxmDFjBgBg27ZtuOSSSzBkyBBkZWVBpVLhjTfewOWXX461a9ee9WvuxMREbNq0CZdeeinmz5+PBQsWAECbXepLly7FY489huuuuw5Lly5FZWUlnnnmGYwZMwa7d+9G7969nfu25/cJIiJqB5GIiMRbbrlFDA4Odts2ceJEEYD4zTfftHmszWYTzWazuG3bNhGAePDgQed9Tz/9tNj8n9q0tDRRrVaL+fn5zm16vV6MiooSb7/9due27777TgQgfvfdd251AhA//vhjt3POmDFD7Nu3r/P266+/LgIQN27c6Lbf7bffLgIQs7Oz23xM0rX//e9/t7rPtddeK6pUKrGgoMBt+/Tp00WtVivW1NSIoiiKf/rTn8Rhw4a1eb2QkBDx/vvvb3MfIiIiou4iOztbBODxSy6Xu+0LQExISBAbGhqc2z799FMRgDhs2DDRZrM5ty9fvlwEIP7yyy/ObdJr1s8++8ztvLfeeqsok8mcrznXrl0rAhDXr1/vtt/u3btFAOIbb7whiqIoHjlyRAQgPvDAA277ffDBByIA8ZZbbnFuu+aaa0SNRiOWlpY6t1ksFrFfv34iADE3N9etzokTJzpv5+bmigDEwYMHixaLxbl9165dIgBx7dq1oiiKotVqFRMSEsRRo0a51ZOfny8qlUoxLS1NPBPpOfL0NX/+fOd+r776qghAPHr0qHNbVVWVqFKpxAcffNC5bfTo0WJcXJxYX1/v9rgHDRok9ujRw/kz8/R6vvnzILnlllvcHkt5ebkIQHz66adb7Cv9/ZKe3+rqalGj0YgzZsxw26+goEBUqVTi9ddf73ad9vw+QUREZ8ZRMEREbYiMjMSUKVNabD958iSuv/56JCQkQC6XQ6lUYuLEiQDQ4uOWngwbNgypqanO22q1Gn369EF+fv4ZjxUEAZdffrnbtiFDhrgdu23bNoSGhrZYOPW666474/nb69tvv8XUqVORkpLitn3OnDnQ6XTOBWIvvPBCHDx4EHfddRe++uor1NXVtTjXhRdeiNWrV2PJkiXYuXOnx48PExEREXU37733Hnbv3u329fPPP7fYb/LkyQgODnbe7t+/PwBg+vTpbp3p0vbmrxlDQ0NxxRVXuG27/vrrYbPZsH37dgD2rviIiAhcfvnlsFgszq9hw4YhISHBOX7wu+++AwDccMMNbue7+uqroVC4f+j9u+++w9SpUxEfH+/cJpfLverYvuyyy9w6+IcMGeL2GI8ePYrS0lJcffXVbselpqZi3Lhx7b5Or169Wvwsdu/ejSeffNK5zw033ACVSuU2NnHt2rUwGo2YO3cuAPsnQ3/++WdcddVVCAkJcXvcN910E4qKinD06NF21+ULO3bsgF6vd46KkaSkpGDKlCn45ptv3La35/cJIiI6M46CISJqQ2JiYottDQ0NmDBhAtRqNZYsWYI+ffpAq9WisLAQV155JfR6/RnPGx0d3WKbSqVq17FarRZqtbrFsQaDwXm7srLS7RcciadtHVVZWenx+UlKSnLeDwCLFi1CcHAw1qxZg5UrV0Iul+Oiiy7Ciy++6FzMa926dViyZAneeecdPPnkkwgJCcGsWbOwbNkyJCQk+KxmIiIiIn/q379/uxYvjYqKcrsdFBTU5nbX132A59d40mso6TXZ6dOnUVNT4zxHcxUVFW77N38NplAoWryGrays9PhazZvXb83PqVKpAMD5uliqp7XXtrm5ue26jlqtPuPPIioqCldccQXee+89PPfcc5DL5Vi9ejUuvPBCDBw4EABQXV0NURTb9TrYX6TrtVbT5s2b3ba15/cJIiI6MwbrRERtaL7wKGDv1C4uLsbWrVudXeoA3GaGB1p0dLTHBaZKS0t9eo2SkpIW24uLiwEAMTExAOy/hC1cuBALFy5ETU0NtmzZgsceewx//OMfUVhYCK1Wi5iYGCxfvhzLly9HQUEBNmzYgEcffRRlZWXYtGmTz2omIiIiOhedPn26xTbpdZ8UXMfExCA6OrrV11ahoaFu+5eWliI5Odl5v8ViaREYR0dHe3x96evXnEDbj9GX5s6di3//+9/YvHkzUlNTsXv3bqxYscJ5f2RkJGQyWbteB3uiVqtRW1vbYrv0xkZHSM9RazW1VQ8REXUcR8EQEXlJCtulbhrJm2++GYhyPJo4cSLq6+uxceNGt+0fffSRz64xdepU55sMrt577z1otVqMHj26xTERERG46qqrcPfdd6Oqqgp5eXkt9klNTcU999yDSy65BPv27fNZvURERETnqvr6emzYsMFt24cffgiZTIaLLroIAPCnP/0JlZWVsFqtGDlyZIuvvn37AgAmTZoEAPjggw/czvfxxx+3WPxz8uTJ+Oabb9xCb6vVinXr1vnssfXt2xcJCQn4+OOP3bYXFBTgp59+8tl1JNOmTUNycjKys7ORnZ0NtVrtNk4xODgYo0aNwieffOL2aVObzYY1a9agR48e6NOnT6vnT09Px7Fjx9wWXq2srGzxWJp37rdlzJgx0Gg0WLNmjdv2oqIi5/hGIiLyPXasExF5aezYsYiMjMQdd9yBp59+GkqlEh988AEOHjwY6NKcbrnlFrzyyiu48cYbsWTJEmRmZmLjxo346quvAAAyWfveV925c6fH7RMnTsTTTz+Nzz//HJMnT8ZTTz2FqKgofPDBB/jiiy+wbNkyhIeHAwAuv/xyDBo0CCNHjkRsbCzy8/OxfPlypKWloXfv3qitrcXkyZNx/fXXo1+/fggNDcXu3buxadMmXHnllb55QoiIiIgC4Ndff20RRgP2ed+xsbE+u050dDTuvPNOFBQUoE+fPvjyyy/x9ttv484773Su63Pttdfigw8+wIwZM3DffffhwgsvhFKpRFFREb777jvMnDkTs2bNQv/+/XHjjTdi+fLlUCqVuPjii/Hrr7/ipZdeQlhYmNt1n3jiCWzYsAFTpkzBU089Ba1Wi9dffx2NjY0+e2wymQyLFy/G7bffjquuugrz5s1DTU0NFi9ejMTExHa/rtXr9a2+tnVtCJHL5bj55pvx8ssvIywsDFdeeaXzda1k6dKluOSSSzB58mQ89NBDCAoKwhtvvIFff/0Va9eu9fipV8lNN92EN998EzfeeCNuvfVWVFZWYtmyZS2e29DQUKSlpeGzzz7D1KlTERUVhZiYGKSnp7c4Z0REBJ588kk89thjuPnmm3HdddehsrISixcvhlqtxtNPP92u54iIiLzDYJ2IyEvR0dH44osv8OCDD+LGG29EcHAwZs6ciXXr1uGCCy4IdHkA7J003377Le6//3488sgjEAQB06ZNwxtvvIEZM2YgIiKiXef5xz/+4XH7d999h0mTJuGnn37CY489hrvvvht6vR79+/dHdna228JJkydPxvr16/HOO++grq4OCQkJuOSSS/Dkk09CqVRCrVZj1KhReP/995GXlwez2YzU1FT89a9/xSOPPOKDZ4OIiIgoMKQFL5t7++23sWDBAp9dJyEhAa+//joeeughHDp0CFFRUXjsscewePFi5z5yuRwbNmzAP//5T7z//vtYunQpFAoFevTogYkTJ2Lw4MHOfbOyshAfH4/Vq1fj1VdfxbBhw7B+/Xpce+21btcdNGgQtmzZggcffBC33HILIiMjcdNNN2H27Nm47bbbfPb4brvtNgiCgGXLlmHWrFlIT0/Ho48+is8++wwFBQXtOsfJkycxZswYj/eZzWa3hVnnzp2LpUuXory83OPPcOLEifj222/x9NNPY86cObDZbBg6dCg2bNiAP/3pT23WMW7cOLz77rv429/+hpkzZ6Jnz554+umn8eWXXzoXkJVkZWXh4YcfxhVXXAGj0YhbbrnFbWFVV4sWLUJcXBxeffVVrFu3DhqNBpMmTcILL7yA3r17t/3kEBFRhwiiKIqBLoKIiPzjhRdewBNPPIGCggL06NEj0OUQEREREXVITU0N+vTpg//7v//DW2+9FehyiIjoPMSOdSKic9Rrr70GAOjXrx/MZjO+/fZbvPrqq7jxxhsZqhMRERFRt1FaWornn38ekydPRnR0NPLz8/HKK6+gvr4e9913X6DLIyKi8xSDdSKic5RWq8Urr7yCvLw8GI1G53iVJ554ItClERERERG1m0qlQl5eHu666y5UVVVBq9Vi9OjRWLlyJQYOHBjo8oiI6DzFUTBERERERERERERERF5o3/LZREREREREREREREQEgME6EREREREREREREZFXGKwTEREREREREREREXnhvFu81Gazobi4GKGhoRAEIdDlEBEREVEbRFFEfX09kpKSIJOxJ6S9+JqXiIiIqPvga97u6bwL1ouLi5GSkhLoMoiIiIjIC4WFhejRo0egy+g2+JqXiIiIqPvha97u5bwL1kNDQwHY/6KGhYUFuBoiIiIiaktdXR1SUlKcr+Goffial4iIiKj74Gve7um8C9alj8KGhYXxlwwiIiKiboLjTLzD17xERERE3Q9f83YvHNpDREREREREREREROQFButERERERERERERERF5gsE5ERERERERERERE5IXzbsY6EREREREREREREbWf1WqF2WwOdBmdTqlUQi6Xt2tfButERERERERERERE1IIoiigtLUVNTU2gS/GbiIgIJCQknHExWQbrRERERERERERERNSCFKrHxcVBq9WeMWzuzkRRhE6nQ1lZGQAgMTGxzf0ZrBMRERERERERERGRG6vV6gzVo6OjA12OX2g0GgBAWVkZ4uLi2hwLw8VLiYiIiIiIiIiIiMiNNFNdq9UGuBL/kh7vmWbKM1gnIiIiIiIiIiIiIo/O5fEvnrT38TJYJyIiIiIiIiIiIiLyAoN1IiIiIiIiIiIiIiIvMFgnIiIiIiIiIiIionPKG2+8gYyMDKjVaowYMQLff/+9T8/PYJ2IiIiIiIiIiIjaJycHWLQIuO46+585OYGuiKiFdevW4f7778fjjz+O/fv3Y8KECZg+fToKCgp8dg0G60RERERERERERHRm2dlAv37A3/8OfPyx/c9+/YDVqwNdGZGbl19+GfPnz8eCBQvQv39/LF++HCkpKVixYoXPrqHw2ZnIo6pGE06UN0CjlGNQcnigyyEiIiIiIiIiIvJeTg6wYAFgs7W8b/58YPx4IDPT/3WRX4miCLNV9Pq4k+UNKKrWo0ekBj1jQ7w+XikXIAhCu/Y1mUzYu3cvHn30Ubft06ZNw08//eT1tVvDYL2TfZ9Tjvs+OoBxmdH4YMHoQJdDRERERERERETUJlEUUXTkV1QVFUITEYHQqGgoFz+LaAAeo01BALKygKVL/Vwp+ZvZKuL17457dUx1owl7C6qhN1mhCZJjRGokIoODvDrH3ZMzEaRoX7BeUVEBq9WK+Ph4t+3x8fEoLS316rptYbDeyTRKOQBAZ7IGuBIiIiIiIiIiIqK26Wpr8OvWLTj603aYjUYoVSpE9UjBgL27ESWKnoN1UQTy8vxcKXUXtQYz9CYrYkKCUNFgQp3B7HWw3hHNO9xFUWx313t7MFjvZNog+1OsZ7BOREREdF7avn07/v73v2Pv3r0oKSnBf//7X/zf//1fm8ds27YNCxcuxOHDh5GUlIRHHnkEd9xxh38KJiIiovOSyaDHke+34tTR32BobIDFZEJkYjIaqyths9qgi2xjxLEgAOnp/iqVAkgpF3D3ZO9G/pwsb8CqH3NR1WhCekww5o3L8HocjFLe/kA8JiYGcrm8RXd6WVlZiy72s8FgvZNpgtixTkRERHQ+a2xsxNChQzF37lzMnj37jPvn5uZixowZuPXWW7FmzRr8+OOPuOuuuxAbG9uu44mIiIjaq6q4CPm/7Ed1aQkMDQ2oLMyD2WiEKjgYEUnJECAgLiMTvUeNwam6Bgg790KEh3Ewomifs07nPEEQ2j2SRdIvMQy3T+zlnLHeqwMz1r0RFBSEESNGYPPmzZg1a5Zz++bNmzFz5kyfXYfBeifTMlgnIiIiOq9Nnz4d06dPb/f+K1euRGpqKpYvXw4A6N+/P/bs2YOXXnqJwToRERH5xMl9u7H7f+tRUVgAs0EPmUwOVUgIlCoV0oYOR31FBXqN+ANCo2IQFhePqKQeCI9LQCXkiF78HERBAKSxGqJon6/OhUupDb1iQzo9UHe1cOFC3HTTTRg5ciTGjBmDt956CwUFBT79FCiD9U4mBet6kyXAlRARERFRd7Bjxw5MmzbNbdsf//hHZGVlwWw2Q6lUBqgyIiIiOheU5+di25pVqCousofiAKwwQxsejrDYeNRXVEAbFo7kfgMRldTDeVxUUg/gqWeA62+0B+l5efbxL/PnM1SnLueaa65BZWUlnn32WZSUlGDQoEH48ssvkZaW5rNrMFjvZM5RMGarzwfkExEREdG5p7S0tMXsx/j4eFgsFlRUVCAxMbHFMUajEUaj0Xm7rq6u0+skIiKi7qmhugqNNVXOUF1itdgwYsYVECA4u9Q9yswEli71Q6VEZ+euu+7CXXfd1WnnZ7DeyaTFS0URMFpsUCvlAa6IiIiIiLq65s0YouMX39aaNJYuXYrFixd3el1ERETU/YXHxTfP1AEAQWoVMoaN9H9BRN2ULNAFnOs0LkE656wTERER0ZkkJCSgtLTUbVtZWRkUCgWio6M9HrNo0SLU1tY6vwoLC/1RKhEREXVDUUk9EKQNbrE9vmfvAFRD1H2xY72TyWUCVAoZjBYbdCYLooKDAl0SEREREXVhY8aMwf/+9z+3bV9//TVGjhzZ6nx1lUoFlUrlj/KIiIioGys6chi7NvwHDRVlbtuVai1Gz74mQFURdU/sWPeDpgVM2bFOREREdL5paGjAgQMHcODAAQBAbm4uDhw4gIKCAgD2bvObb77Zuf8dd9yB/Px8LFy4EEeOHMGqVauQlZWFhx56KBDlExER0Tki78BefPaPJcjdt7vFfamDBrc+U52IPGLHuh9ogxSo1pmhNzNYJyIiIjrf7NmzB5MnT3beXrhwIQDglltuwerVq1FSUuIM2QEgIyMDX375JR544AG8/vrrSEpKwquvvorZs2f7vXYiIiLqvn7/aTsOffs1TAY9wuMSUJ53Eob6+hb7BWmCMfSS6QGokKh7Y7DuB2ql/YMBnLFOREREdP6ZNGmSc/FRT1avXt1i28SJE7Fv375OrIqIiIjORbkH9uC3779DeW4uKosLIa1SWppz1OP+Qdpg/OHyWVy0lKgDGKz7gTbI/jRzFAwREREREREREflKVXERio4cRuFvh1B05DAaKsvbfawmPByZI0ajz+jxnVgh0bmLwbofaBwz1tmxTkREREREREREZ6uquAiFv/2KfV9+hqriImdn+pkIMhkUyiBEJiVj2CUzkNx/IGerE3UQg3U/0DqDdUuAKyEiIiIiIiIiou7q2+w3cXTHDzCbjBBtIixGfdsHyGRQqtQI0mgQHBGJ5L79EZuSzkCdyAcYrPuBFKxz8VIiIiIiIiIiIuqIb1atxIGvPvfqmEsW3IUe/Qehruw0wuLiGaYT+ZAs0AWcDzRK+/sXHAVDREREREREREQdkX/ogFf7D7/0cgyZeimiknogfdgIhup0Xtm+fTsuv/xyJCUlQRAEfPrppz6/BjvW/UDLGetERERERERERHQWTAadh60CIAByhQJpQy4AREDfUIuMYSMwZvZ1fq+RqKtobGzE0KFDMXfuXMyePbtTrsFg3Q+co2A4Y52IiIiIiIiIiLx0cMtGNFZXu21TKIMw+OI/AhCQMewCZAwbGZjiiLqg6dOnY/r06Z16DQbrfqBhxzoREREREREREXVA7oE92PreO4Aoum0PiYnFlDm3B6gqOm+JImA1e39c5XGgJh+ISAOiM70/Xq4EBMH74zoRg3U/aOpYZ7BORERERERERETtV3riOCxGY4vt0cmcmU4BYDUD3//Du2N0lUDhLsCsA5RaIOVCQBvt3TkmPAgogrw7ppNx8VI/0CgdwbqZwToREREREREREbVPVXERdLU1Hu8Tbf6thajDDLX2UD041v6noTbQFfkEO9b9QBNkf5o5CoaIiIiIiIiIiNqjoigfG197BWV5Jzzer6+v8W9BRIB9JMuEB707pvI4sOMNQFcBRPUCxtzl/TgYudK7/f2AwbofcBQMERERERERERF5Y+Pry1GWe7zV+xUqlR+rIXIQBO9HssQPAMbf1zRjPaZ359TmZwzW/cC5eKnZEuBKiIiIiIiIiIioq/v+w3dRdjKn9R0EAakDhvivIKKzFdPbr4F6Q0MDjh9vemMqNzcXBw4cQFRUFFJTU31yDQbrfqB1zFjnKBgiIiIiIiIiIjqT4uO/t3qfUq1Gcp8B6DNmvB8rIupe9uzZg8mTJztvL1y4EABwyy23YPXq1T65BoN1P9A6ZqxzFAwREREREREREbnKPbAHxTlHkdS7LzKGjYTVYoHNw9QDTXg4hv/xT0js1QdhcfGISuoRgGqJuodJkyZBFMVOvQaDdT9wjoJhsE5ERERERERERA7H9/yMzW+/BqNOhyCVCv0nTAYgwqjXu+0XEh2LPz/xHMN0oi6EwbofcPFSIiIiIiIiIiJq7vjuHTDqdIAoQt9Qj4ObNyI4IgJWiwUQZIBoAwCo1JoAV0pEzckCXcD5QArWTVYbLFZbgKshIiIiIiIiIqJAKy/IQ31lBQQANosFMpkMAkQER0YjIj4B4XFxkCuVCI6MhjYyEnVlpwNdMhG5YMe6H0ijYABAZ7YiTM73M4iIiIiIiIiIzldVxUX4Ye17qK8ohzYiAgqlCnKFHBaTCYqgIETEJWDARVOQ8/MOWK0WRMQlICwuPtBlE5ELBut+ECSXQSYANhEwmKwIUysDXRIREREREREREQWAaLPh4JaNKMs9AW1EJILVagy4aDJCo2IgQoQAwbk4aY/+g1BXdpqLlRJ1QQzW/UAQBGiDFGgwWriAKRERERERERHReUq02bD/q8+Rd2AfTAY9rJUW9Og/CMn9BnoMzqOSejBQJ+qiGKz7iSZIzmCdiIiIiIiIiOg8UlVchNqy0wiPi7eH6l9/gdITObCaTUgfNgL1FeXIGHYBw3OibiigwfrSpUvxySef4Pfff4dGo8HYsWPx4osvom/fvq0es3XrVkyePLnF9iNHjqBfv36dWe5ZkRYw1ZstAa6EiIiIiIiIiIg6y4m9u1BRmAezyYRTRw7DqNNBJpPBZNSjsaoKos2GIK0W+vo6xKSkIbnfwECXTEQdENBgfdu2bbj77rvxhz/8ARaLBY8//jimTZuG3377DcHBwW0ee/ToUYSFhTlvx8bGdna5Z0WjtAfr7FgnIiIiIiIiIjo3/fb9Vny/djVsZgtkSgVkMhlCo2NRW1YKi8kEQS6HOiQEKm0wUgcOQZ/R49itTtRNBTRY37Rpk9vt7OxsxMXFYe/evbjooovaPDYuLg4RERGdWJ1vSR3rDNaJiIiIiIiIiLq3srwTKDmeg7L8k6gvK0Ncr0xExMZjx/q1aKyugiCTQRGkQnhcHGRyOaJ6pMJiMKCushyiKCIyIZmhOlE316VmrNfW1gIAoqKizrjv8OHDYTAYMGDAADzxxBMex8MAgNFohNFodN6uq6vzTbFe0gbZn2o9g3UiIiIiIiIiom6psqgAe7/8DHkH98Nk0MPY2ACIQP6vBxCTlgGLyQQIAgRBBrlCgT6jxiGhZ2+ExcUDAE79fhgQgeT+nhcrJaKz15Hx4x3RZYJ1URSxcOFCjB8/HoMGDWp1v8TERLz11lsYMWIEjEYj3n//fUydOhVbt2712OW+dOlSLF68uDNLbxcNO9aJiIiIiIiIiLqtw9u/xY5/r0VDdQVsVisEmRwQRciVQbBZLZAJAqJTUlFZWAhRtCE+oxf6jB7vFqAzTCfqfGczftwbXSZYv+eee/DLL7/ghx9+aHO/vn37ur27MGbMGBQWFuKll17yGKwvWrQICxcudN6uq6tDSkqK7wpvp6ZRMFy8lIiIiIiIiIiouyjLP4mCXw9i3xcboKurgc1mg0wuhyAIsMlksNmsUKrUGDxlGnr0H8SudKIAO5vx497oEsH6X/7yF2zYsAHbt29Hjx7e/4MzevRorFmzxuN9KpUKKpXqbEs8a1KwzlEwRERERERERERdT1VxEWrLTiM8Lt4ZiJ86dgTfZr+JhspKGHUNkCmDALMZClUQYpJTEZfRC0adDsn9+mPI1EsBsCudzm2iKMJi875xOK82D6caTyE5OBnp4eleH6+QKSAIgtfHAd6NH/dGQIN1URTxl7/8Bf/973+xdetWZGRkdOg8+/fvR2Jioo+r8y2N0v5U68wM1omIiIiIiIiIAs01SBdFEds/WA1dbTUgAjFp6QiNjkXRkV9RU1oCq9UCq8UCuUKJ6B4p6P2HMegzZjxDdDrvWGwWvH3oba+OqTZU42D5QegtemgUGgyNHYpIdaRX57h18K1QypVeHQO0f/x4RwQ0WL/77rvx4Ycf4rPPPkNoaChKS0sBAOHh4dBoNADso1xOnTqF9957DwCwfPlypKenY+DAgTCZTFizZg3Wr1+P9evXB+xxtIcmSAaAHetERERERERERIFWVVyEre9n4fSJHFitVkQmJqG+ohwmvR5mgwGlJ44BEACIzmPkyiAER0Zi2LQZGDzljwGrnai7qTfVQ2/RI1odjUpDJepN9V4H6x3V3vHjHRHQYH3FihUAgEmTJrltz87Oxpw5cwAAJSUlKCgocN5nMpnw0EMP4dSpU9BoNBg4cCC++OILzJgxw19ld4g2yP5UM1gnIiIiIiIiIgqs2rLTOH0yB7raWgAiSnOOonmQ7va9IECukCM8NgHJ/Qb6t1jyOePJXJhPFUGZ3AOqnh2boHG+UsgUuHXwrV4dk1ebh/ePvI9qQzVSw1JxU/+bvB4Ho5B5H2Of7fjxM9bk8zN6QRTFM+6zevVqt9uPPPIIHnnkkU6qqPNolI7FSzkKhoiIiIiIiIjIb45VHMPyzX/DiYrj6KFNxOyk6YizhkOADK0G6c0EaTSITU3HBTMu5/iXbq5u+3aUvbgMosEA9eDBiLv3XobrXhAEweuRLL2jemPuoLkobihGUkgSMsI79/n21fjxM+kSi5eeD5oWL/V+uD8REREREREREXkve382FmyYD4iACBFCpYDswo9xXeUfMMqY3vIAQQYBgDxIieDwSMgUCihVavS+cDT6jOZM9e7O9M23sN66ALEVlTArFagpKEBJTQ0Sn3qK4XonywjP6PRAXdKe8eO+wGDdTzSOYF3HUTBERERERERERJ0upzIHC/63ADaI9ikvsIfrEIG10buRWh2MGCEUgkyAJiQUcoUSQVot5Eolhl58KXr0H4S6stMIi4tnoH4uyM6Gcv58RLhM0IiuqkJJQz2KzWYkPfccw/VzRHvGj/sCg3U/kWasM1gnIiIiIiIiIup8q/avgiAl6q4EQBAF7IosxMy6CxAeH4++o8cjvmcvCBDcgnQG6ueInBxgwQIIzcZSiwASS0uR+/vvMJ86xWD9HNGe8eO+wGDdT5pGwTBYJyIiIiIiIiLqbHm1efYOdQ9EiKhS6iGTyxCVkIw+o8cxRD+XrVoFCC3fZJGWq42oKIcyOdnvZVH3xmDdT5yjYMycsU5ERERERERE1NnSw9M9d6wDECCghzYRI8f9H/qM4ez0c15eHtBGF3OQTM5udfKaLNAFnC/YsU5ERERERERE5D/zhs9rtWMdgoCnb3gFo2dfy1D9fJCe7rFjXWKoq0PRI3/1Xz10TmCw7idaJWesExERERERERH5S+/o3si6IgsyQQa5IHf7M2tmFkb2nxDoEslf5s3z2LEubakJD0f9hg0oef4F/9ZF3RpHwfiJOsj+HobebIUoihDaeJeMiIiIiIiIiIjO3pxhczA+dTyy9mUhrzYP6eHpmH/BfGRGZQa6NPKn3r2BrCxg/nyIggBYmxpfSxISYA4KAgDUrF+PqOuu41gYahcG636iDbI/1aIIGC02qJXyAFdERERERERERHTuy4zKxNKLlwa6DAq0OXOA8eMhZGXB+uuvqM/LQ0WjzhmqAwB0OtRt2oTYu+4MWJnUfXAUjJ9oXIJ0joMhIiIiIiIiIiLys8xMYOlSyP/3P0QcOgTVlVe22KV206YAFEbdEYN1P5HLBKgU9qdbZ7IEuBoiIiIiIiIiIqLzW9xddwEqlds2c04Oyt5YEaCKqDthsO5H2iB717qeHetEREREREREREQBpeqZAXlMjPtGUUTlm2+ifvv3gSmKug0G634kzVnnKBgiIiIiIiIiIqLAU/ft23Kj0Yjqjz7yfzHUrTBY9yONo2OdwToREREREREREVHgRV57LaBUttgu6vUBqIZ8YcWKFRgyZAjCwsIQFhaGMWPGYOPGjT6/DoN1P3KOgjFzxjoREREREREREVGghV40ocWcdQAInT49ANWQL/To0QN/+9vfsGfPHuzZswdTpkzBzJkzcfjwYZ9eR+HTs1GbNEp2rBMREREREREREXUplpZNsMqEhAAUQr5w+eWXu91+/vnnsWLFCuzcuRMDBw702XUYrPuRlqNgiIiIiIiIzm05OcCqVUBeHpCeDsybB/Tu3WK3E+UNKKzSISVKi16xIX4vk4go4Nr576U/yNRq2AwGt23VH31k72YnN6IoAmaz18cZc/NgPnUKyuRkqDLSvb+wUglBELw+zGq14t///jcaGxsxZswY76/bBgbrfiTNWNczWCciIiIiIjr3ZGcDCxYAggCIov3PZcuArCxgzhznbifKG7B8yzF8+9tpWGwiLkiLxNrbfPvLPhFRl9bOfy/9RRYcDFtNjdu2xp9+gvFkLlQ9M/xeT5dmNqPizbe8OsRSXQ39gQMQdToIWi00w4ZBERnp1Tlibr8NCApq9/6HDh3CmDFjYDAYEBISgv/+978YMGCAV9c8E85Y9yON0v4+BjvWiYiIiIiIzjE5OfaQyGYDrFb3P+fPB44fd+5aWKXDlsOlaDTbYLSK2HGyCuP+9k0Aiyci8iMv/r30F2VKSsuNBgOq1q71ey3nIltdHUSdDrKYGIg6HWz19Z1+zb59++LAgQPYuXMn7rzzTtxyyy347bfffHoNdqz7UdPipQzWiYiIiIiIzimrVtk7Lj0RBHsX5tKlOFHegIOFtdBbRLddTtUYMOCpjfjfXyZwNAwRndva+e+lP0XPm4eivXtbjDhp3LYNxuuuY9e6K6XS3j3uBWNuHqreexfWqirI01IRdfMt3o+DUSq92j0oKAiZmZkAgJEjR2L37t345z//iTfffNO767aBwbofOYN1U8sFEYiIiIiIiKgby8uzjzPwwCaKyN39KzZ+m4MdJypRUmuAQgZYbO776Uw2TP3HNsQEK/HS1cMwqW9c59dNRORveXkQRREeo3VRtP976mehF01A/JNP4vQzz9g75yU2G8ynTjFYdyEIglcjWQBA3bcPoucvaJqxHoDnUxRFGI1Gn56Twbofabh4KRERERER0bkpPb3VDkwRwM+2MHy8pwiiKCIxXA0RIvIqdPAUxVc0mjEnezfG9Izi7HUiOvekp0MU4DlYFwT7v6d+ZjyZi+qPPnIP1QEo4uOhTE72ez3nIlXPDL8F6o899himT5+OlJQU1NfX46OPPsLWrVuxadMmn16HM9b9SMvFS4mIiIiIiM5N8+Z57FgXAQgi8PuMqxCikiM6JAhKhQyjMqLwwpWDoJK3fsodJ6vwwLr9nVczEVEAFP75EsBma/HGogjY/x2dP98vddRt3Ijcm29GztSLcXL2bJiaz9/WahF9++3sVu+GTp8+jZtuugl9+/bF1KlT8fPPP2PTpk245JJLfHoddqz7kSaIi5cSERERERGdk3r3ts8Fnj/f3nEpis4/19/5DEriUjAkOAiXDkqAIAjoEalBr9gQXHdhGoYu/gq1es8jQzccKMYr1wz384MhIuoc3xd9j+WFr2PAvB54ZlWRvXNdBCAIkMExX90xF7szGE/monbDZ2jcuROGXw8DltbHNSvj4xF60YROq4U6T1ZWll+uw2Ddj7RKxygYLl5KRERERER07pkzBxg/3h4M5eUB6ekQ5s/HBeEJiKvWO8P05g4+/Uc8sG4//ru/uMV9VhFYuysf112Y1vn1ExF1ovd+fQ+v7n8VRpsRxyZEYG8fDa7aXosRhmikDZmIiLse9Hmobjh5EuYTJxDUKxOVa95H7b//02KB0tYoExJ8Wgudexis+5E0CqbB0L7/gImIiIjo3PDGG2/g73//O0pKSjBw4EAsX74cEyZ47oDaunUrJk+e3GL7kSNH0K9fv84ulYjOVmYmsHSp26ZegMdA3dUr1wzHPVN6Y+o/trW4728bf8eFGdFnPAcRUVd1sOwg3jj4Boy2psUjC+NVePO6dDzyh0cwtM9sn1+zcs0aVK58EzajEaLB0O5AHQCgViN0+nSf10TnFs5Y96PMOPuLoMPFdTCwa52IiIjovLBu3Trcf//9ePzxx7F//35MmDAB06dPR0FBQZvHHT16FCUlJc6v3r17+6liIgqUXrEhWD33Dy221+otuPHtndh6tMwn18mpzMGiLYtw3frrsGjLIuRU5vjkvEREnnxf9D2e+vEpNFoa3bYLENA3qi8uiL/A59es/OADlP39JVgrKiDW17c7VJcnJiJ46lTEP/YYoq7+s8/ronMLO9b9KDMuBEnhahTXGrDzZCUm9Y0LdElERERE1MlefvllzJ8/HwsWLAAALF++HF999RVWrFiBpc26Wl3FxcUhIiLCT1USUVcxqW8cZg1PajEWpqTOiLnZu/HAJb1x79Q+Ho/derQMnx0oRmmtHnqjFVaICA6SI0StRKhagXqDBXvLP8GBxmUQIAAQIUDAsh+XIWtmFuYMm9P5D5CIzivfF32Ph7c93CJUV0CB6RnTcevQW5ERfnaLg+ZU5uCtb19CbunvyIjrg+vDJ0P7+huA0XjmgwEI4eFQJCQgeNQoRF17LRcrpXZjsO5HgiBgYt9YrN1ViG3HyhmsExEREZ3jTCYT9u7di0cffdRt+7Rp0/DTTz+1eezw4cNhMBgwYMAAPPHEEx7HwxDRuemeKb3x5S8lMFpFt+0igJc35+DjPYVY8n+DMalvHLYeLcN/95/CL4U1KKrWwWxr/bxm4RSKVS8CggjR5ZwAMP+z+RifOh6ZUZ23aCARnX++PPlli1BdDjmu6XcNHh31aCtHtV/2/mws2LAAgihChAihYjteFt7BcxGJmFUVfsbjg6dMQfxDDzFMpw5hsO5nE/vE2YP1o+XA5YGuhoiIiIg6U0VFBaxWK+Lj4922x8fHo7S01OMxiYmJeOuttzBixAgYjUa8//77mDp1KrZu3YqLLrrI4zFGoxFGl66suro63z0IIvK7XrEhuG5UKlb/lO/x/qJqA+Zk73b0nLdfg3wz0MpRIgRk7cvC0otb/yQNEZE3cmtzsTl/c4vtcdo4XNPvmrM+f05lDhZsWAAbbPZ/2gDnP3FPXliCC8o0SGsI8nywVov4Rx/luBc6KwzW/WxsZjQUMgEnKxpRUKlDarQ20CURERERUScTBMHttiiKLbZJ+vbti759+zpvjxkzBoWFhXjppZdaDdaXLl2KxYsX+65gIgq4Z64YhKjgIKz47jj0Fs/xuTehOgBYhLI2jhKRV5vn5RmJiFr3Vd5XbouVSm4bcttZj38BgDc3Pg/BZmu5gqQACDZgfa8aLDzomBah1UKZlARlTAyUKSmInjuXXep01rh4qZ+FqZW4IC0SALDtmG8WniEiIiKirikmJgZyubxFd3pZWVmLLva2jB49Gjk5rS8uuGjRItTW1jq/CgsLO1wzEXUd907tgyNLZiBEJW/3MWqFgP4JIRieEoH+iaGICw1CcJD9eIUYh6a2TneCICA9PN0HVRMR2e0u3t1iW7gyHFf1vcon58+rzmvjrUKgONgMCAJkERGIf/RRpLz6KqLnz2eoTj7DjvUAmNQ3Frtyq7DtWDluGpMe6HKIiIiIqJMEBQVhxIgR2Lx5M2bNmuXcvnnzZsycObPd59m/fz8SExNbvV+lUkGlUp1VrUTUdf26+FL832s/4EBRbav7KOXAhelRuPWiXm7reZ0ob0BRtR4HC6ux+dif8UXZJ60EUSLmXzDf57UT0fmrTN+5DaUZif0hVG6Hp0/iCACSTMEInjIFkddcg9CLJgAAA3XyKQbrATCxTyyWbTqKn05UwmixQqVof/cBEREREXUvCxcuxE033YSRI0dizJgxeOutt1BQUIA77rgDgL3b/NSpU3jvvfcAAMuXL0d6ejoGDhwIk8mENWvWYP369Vi/fn0gHwYRBdin94wHAKzdlY/lm3NQ2WCEQi4gKUKD4amRuHxoklugLukVG4JesSGY2CcW907tg9UHdJi/YT4ECPaF/hx/Zl2RxYVLicin6kwt13yxiW2ssOyl2yYvxMuH30KLYF0ERAG4OfaPiP/LgwzTqdMwWA+AAYlhiA1VobzeiD151RiXGRPokoiIiIiok1xzzTWorKzEs88+i5KSEgwaNAhffvkl0tLSAAAlJSUoKChw7m8ymfDQQw/h1KlT0Gg0GDhwIL744gvMmDEjUA+BiLqQ6y5Mw3UXpnX4+DnD5mB86nhk7ctCXm0e0sPTMf+C+QzVicinFn67EFXGqhbbw1RhPrtG7+jeyJqZ1fRmoc3mXJ751eQ7ceHNDzFUJwD29Ygee+wx3HfffVi+fLnPzstgPQAEQcDEPrH4z94ibD1axmCdiIiI6Bx311134a677vJ43+rVq91uP/LII3jkkUf8UBURna8yozKx9OKlgS6DiM5R//7939hcuNnjfT1Ce/j0WnyzkM5k9+7deOuttzBkyBCfn5uLlwbIpL6xAID/7i9Gjc4U4GqIiIiIiIiIiIjOTm5tLv6x9x8e75NDjkvTL/X5NaU3C9fOXoulFy9lqE5ODQ0NuOGGG/D2228jMjLS5+dnsB4glwyIR6/YYFQ0GPHc50cCXQ4REREREREREdFZ2VWyC42Wxhbb00PT8cToJ3BV36sCUBX5kiiKsFpsXn9VnmpA7i/lqDzV0KHjRdHz0tttufvuu3HZZZfh4osv7oRngqNgAkalkGPZVUNw1codWL+vCJcPTfS40AwREREREREREVF3IJfJW2xLD03H/678XwCqoc5gs4rYuzHPq2P0DWaUnqyFxWSFIkiOhJ7h0IQovTrHiOnpkCuEdu//0UcfYd++fdi9e7dX1/EGO9YDaERaFOaOtS+i8Ngnh1BvMAe4IiIiIiIiIiIiIu/k1ubiP8f+g7VH1ra4T2fWBaAi6kpMOjMsJis0oUpYTFaY9JZOvV5hYSHuu+8+rFmzBmq1utOuw471AHvoj32w5chpFFTp8I+vj+GZKwYGuiQiIiIiIiIiIqIzyq3NxQdHPsDnJz6HzqKDiJbjOmyiLQCVUWeRyQWMmJ7u1TE1p3U48E0BDA1mhMdpMWxqKiLitV5ft7327t2LsrIyjBgxwrnNarVi+/bteO2112A0GiGXt/x0hbcYrAeYNkiBx2b0xx1r9mLr0TIADNaJiIiIiIiIiKhr+r7oe/xW+RtsNhv+e/y/KNGVtLn/6KTRfqqM/EEQBK9GsgBAdHIILpiWhvpKA0Kj1YhMCO6k6uymTp2KQ4cOuW2bO3cu+vXrh7/+9a8+CdUBButdQkaM/S9TnaFzPwZBRERERERERETUUSv2r8Dbh96GWWzfOGO5TY6a+hpct/46pIenY97weegd3buTq6SuKDIhuNMDdUloaCgGDRrkti04OBjR0dEttp8NButdQLjGPqy/Vm+GKIoQBO/e9SEiIiIiIiIiIupMH//+MVb+shI2tG+0S3V9NU5VnsIvBb8AsHc6L/tpGbKuyMKcYXM6sVIi/2Cw3gWEaew/BqtNhM5kRbCKPxYiIiIiIiIiIuoacmtzkX04u92hutFsxKnKUwDgnLsuivY/52+Yj/Gp45EZldk5xRJ5sHXrVp+fU+bzM5LXNEo5FDJ7l3qdoX0fpSEiIiIiIiIiIvKHUw2nYLAY2r1/dUN1m/dn7cs625KIAo7BehcgCILbOBgiIiIiIiIiIqKuIjkkGamhqW3uI3OJGc2WtvOtvNo8X5RFFFAM1ruIMEewXqfnAqZERERERERERNR1ZIRnYMGQBUgJSWlxX5QqCpdnXI7Xpr6GXuG9AABKhbLN86WHp3dGmUR+xWHeXUSY2v6jqGPHOhERERERERERdTETekxAj9AeWPf7OhyqOIRodTT+3PfPmNBjgnMf6f7v8r/D17Vft3qu+RfM90fJRJ2KwXoXEcZRMERERERERERE1IVlhGfg0VGPnvH+R0c9itUHVmP+hvnORUsB+zjkrCuyuHApnRMYrHcRzlEwXLyUiIiIiIiIiIi6uTnD5mB86nj8Y8c/kFOVg95RvfHgmAcZqtM5g8F6FxGm5ox1IiIiIiIiIiI6d2RGZWLFZSsCXQZRp+DipV1EOEfBEBEREREREREREXULDNa7iDCNY/FSjoIhIiIiIiIiIiIi6tIYrHcRTaNgGKwTERERERERERERdWUM1rsIjoIhIiIiIiIiIiIiOjvPPPMMBEFw+0pISPD5dbh4aRcR5gjW6wxcvJSIiIiIiIiIiIioowYOHIgtW7Y4b8vlcp9fg8F6FxGmdsxYZ8c6ERERERERERERUYcpFIpO6VJ3u0annp3aTRoFw2CdiIiIiIiIiIiIuiJRFGGzej9xo6r4FOrKTyMsNh5RScleHy+TKyAIQrv3z8nJQVJSElQqFUaNGoUXXngBPXv29Pq6bWGw3kVIo2DqjRZYbSLksvb/RSEiIiIiIiIiIiLqbDarBT//92OvjtHX16H46BGYjUYoVSok9e0PTWiYV+cYNetqyBXK9u07ahTee+899OnTB6dPn8aSJUswduxYHD58GNHR0V5dty1cvLSLCFM3/cVo4Jx1IiIiIiIiIiIiOgcYGhtgNhqhDY+A2WiEsbGxU683ffp0zJ49G4MHD8bFF1+ML774AgDw7rvv+vQ67FjvIoIUMmiUcujNVtTqzQjXtu8dGCIiIiIiIiIiIiJ/kMkVGDXraq+OqSo+hX1ffgZdXS0iE5NwwYyZXo+Dkck7HmMHBwdj8ODByMnJ6fA5PGGw3oWEaRTQm62oM3DOOhEREREREREREXUtgiC0eySLJDY1HX+4Yjbqyk4jLC4eUUk9Oqk6z4xGI44cOYIJEyb49LwM1ruQMLUSp+uM7VrA1GoTIRPg1dB+IiIiIiIiIiIiIn+LSurht0D9oYcewuWXX47U1FSUlZVhyZIlqKurwy233OLT6zBY70LCHQuY1p4hWDeYrbjklW3IjA1B9twL/VEaERERERERERERUZdXVFSE6667DhUVFYiNjcXo0aOxc+dOpKWl+fQ6DNa7kDBHsH6mUTB5lY0orNKjqFoPg9kKtVLuj/KIiIiIiIiIiIiIurSPPvrIL9eR+eUq1C5havv7HHV6S5v7NRrt94sicKpG3+l1EREREREREREREVETButdSHtHwTQYrc7vC6p0nVoTEREREREREREREbljsN6FtHcUjNSxDgAFlQzWiYiIiIiIiIiIiPyJwXoXEqZ2BOtn7Fh3CdbZsU5ERERERERERETkVwzWu5D2joJpZLBOREREREREREREFDAM1ruQMI1j8VJD24uXNrjcX8hgnYiIiIiIiIiIiMivGKx3Ie0eBWNy71gXRbFT6yIiIiIiIiIiIiKiJgzWu5CwDoyC0ZmsqGw0dWpdRERERERERERERNSEwXoXIs1YrzOcKVi3ut3mnHUiIiIiIiIiIiIi/2Gw3oVIHesGsw1Gi7XV/RqM7jPYCyoZrBMRERERERERERH5C4P1LiRUpYAg2L+v07e+gKm0eKlGKQfAjnUiIiIiIiIiIiIiyalTp3DjjTciOjoaWq0Ww4YNw969e316DQbrXYhMJiBEpQDQ9jiYRsfipX0TQgEwWCciIiIiIiIiIiICgOrqaowbNw5KpRIbN27Eb7/9hn/84x+IiIjw6XUCGqwvXboUf/jDHxAaGoq4uDj83//9H44ePXrG47Zt24YRI0ZArVajZ8+eWLlypR+q9Q/nnPU2FjCVRsEMSAoDwGCdiIiIiIiIiIiICABefPFFpKSkIDs7GxdeeCHS09MxdepU9OrVy6fXCWiwvm3bNtx9993YuXMnNm/eDIvFgmnTpqGxsbHVY3JzczFjxgxMmDAB+/fvx2OPPYZ7770X69ev92PlnSdMbQ/Wa9sI1hsdwXr/RHuwXshgnYiIiIiIiIiIiDqZKIoQLTavv0wlDdD/VglTSUOHjhdFsd01btiwASNHjsSf//xnxMXFYfjw4Xj77bd9/lwofH5GL2zatMntdnZ2NuLi4rB3715cdNFFHo9ZuXIlUlNTsXz5cgBA//79sWfPHrz00kuYPXt2Z5fc6cI00iiY1mesNxrtC5sOcATrpXUGGMxWqB0z14mIiIiIiIiI/ConB1i1CsjLA9LTgXnzgN69A10VEfmaVUTdd4VeHWJrNMNYUAfRZIMQJIMqNQyyYKVX5wibnAIohHbte/LkSaxYsQILFy7EY489hl27duHee++FSqXCzTff7NV12xLQYL252tpaAEBUVFSr++zYsQPTpk1z2/bHP/4RWVlZMJvNUCrdfyhGoxFGo9F5u66uzocV+96ZRsHYbKJzFExqlBbBQXI0mqw4VaNHr9gQv9VJRERERERERAQAyM4GFiwABAEQRfufy5YBWVnAnDmBro6IAsxmsEA02SALUcDWYIHNYPE6WPfqejYbRo4ciRdeeAEAMHz4cBw+fBgrVqw4N4N1URSxcOFCjB8/HoMGDWp1v9LSUsTHx7tti4+Ph8ViQUVFBRITE93uW7p0KRYvXtwpNXeGM42C0Zmtzu9DVAqkRGnxe2k9Cqp0DNaJiIiIiIiIyL9ycuyhus3W8r7584Hx44HMTP/XRUSdQy7Yu8e9YC7XoeHHU7A1WqCM0SBkXDKUsVqvr9teiYmJGDBggNu2/v37+3yUeEBnrLu655578Msvv2Dt2rVn3FcQ3J9IacZO8+0AsGjRItTW1jq/Cgu9+6iCv4VJHesGz8G6NF9dJgBqpQypUfa/hAWVnLNORERERERERH62apW9Q90TQbB3rRPROUMQBAgKmVdfQYkhCJ2YgpAxSQidmIKgxBCvz+Ep923NuHHjcPToUbdtx44dQ1pamk+fiy7Rsf6Xv/wFGzZswPbt29GjR482901ISEBpaanbtrKyMigUCkRHR7fYX6VSQaVS+bTeztQ0CsbzjHVpDEywSgFBEJqCdS5gSkRERERERET+lpdnH//iiSja7yei854yVut9l3oHPfDAAxg7dixeeOEFXH311di1axfeeustvPXWWz69TkA71kVRxD333INPPvkE3377LTIyMs54zJgxY7B582a3bV9//TVGjhzZYr56dxSmdixe2sooGKljPVRl3y81msE6EREREREREQVIenrbHevp6f6shogIf/jDH/Df//4Xa9euxaBBg/Dcc89h+fLluOGGG3x6nYAG63fffTfWrFmDDz/8EKGhoSgtLUVpaSn0er1zn0WLFrkNlb/jjjuQn5+PhQsX4siRI1i1ahWysrLw0EMPBeIh+NyZRsE0GJo61gEgxdGxXtgJwbrY2jvOREREREREREQAMG9e2x3r8+f7tx4iIgB/+tOfcOjQIRgMBhw5cgS33nqrz68R0GB9xYoVqK2txaRJk5CYmOj8WrdunXOfkpISFBQUOG9nZGTgyy+/xNatWzFs2DA899xzePXVVzF79uxAPASfaxoF00qwbnQP1jtrFMxdH+zFpJe2Qm+ynnlnIiIiIiIiIjo/9e5tn6MukwFyuX1ROOlr+QtcuJSIzlkBnbHeno7o1atXt9g2ceJE7Nu3rxMqCjwpWK/SmTze32iyB+shjmA9PkwNANCZrNCZLNAGnf2PtFZnxpeH7HPsj5c1YHCP8LM+JxERERERERGdo+bMAcaPtwfsuzcBigrgojQg7RRQkQPE9A50hUREPhfQjnVqqUekvQO9uMYAs9XW4v4Go72DPFglt/8ZJIdKYf8xVjZ4DuO9dbCoxvl9ayNpiIiIiIiIiIicMjOBpUuBR/4EXBICJEcBjRVATX6gKyMi6hQM1ruY+DAVNEo5rDYRRdX6FvdLi5eGqOyd7YIgICZEBQCoaDD6pIb9BTXO72tbGUlDREREREREROSm/BhwdBNgqAFKDwFyJRCRFuiqiIg6BYP1LkYQBKRF27vWcysaWtwvLV4a4uhYB4DokCAAvutY319Y7fyewToRERERERERtUveD0BDKSBTABYjoFADVbn2cTBEROcYButdUEZMMAAgt6LlgqTNFy8F4NOOdVEU2bFORERERERERN6TyQGlBhAczYB5PwBblwI//YvhOhGdcxisd0HpjmA9r6KxxX2NHoL16GBHx3rj2Xes51Y0uoXpDNaJiIiIiIiIqF3SxgKpY4CoDEATBZh19s716jzOWieicw6D9S4oI9oRrFd6CNZN0igYl2Ddhx3rrt3qAIN1IiIiIl944403kJGRAbVajREjRuD7779vc/9t27ZhxIgRUKvV6NmzJ1auXOmnSomIiM5CTG9gyhPAiDn27nVjPVBx1B6si2KgqyMi8ikG611QunMUTMtgvcFoBeAerMf4cMa6NF9dG2T/2BaDdSIiIqKzs27dOtx///14/PHHsX//fkyYMAHTp09HQUGBx/1zc3MxY8YMTJgwAfv378djjz2Ge++9F+vXr/dz5URERB0Q0xsIS7Z3q8uVgCIYUIUBghDoyoiIfIrBehckzVgvrtHDaLG63ddgsAfdbqNgpGC90Xcd62N7RQMA6hisExEREZ2Vl19+GfPnz8eCBQvQv39/LF++HCkpKVixYoXH/VeuXInU1FQsX74c/fv3x4IFCzBv3jy89NJLfq6ciIioA3ZnAxvuBRrL7OG6zQiExAERaYGujIjOI+np6RAEocXX3Xff7bNrMFjvgmJCghCiUsAmAoVV7guYNnroWI8Oto+COduOdb3Jit9L6wEAE/vGAWDHOhEREdHZMJlM2Lt3L6ZNm+a2fdq0afjpp588HrNjx44W+//xj3/Enj17YDZ7fm1mNBpRV1fn9kVEROR3/xwOfHE/UH/KZaNgn7se0ztQVRHReWj37t0oKSlxfm3evBkA8Oc//9ln12Cw3gUJgoD0GC0A4GS5+ziYBufipXLnNqljveIsg/VDp2phtYlICFOjX0IoAAbrRERE1P3p9Xr88MMP+O2331rcZzAY8N5773XatSsqKmC1WhEfH++2PT4+HqWlpR6PKS0t9bi/xWJBRUWFx2OWLl2K8PBw51dKSopvHgAREVF7vTcLqD7ZcrsgACHxLbcTEXWi2NhYJCQkOL8+//xz9OrVCxMnTvTZNRisd1HprSxg6mnx0ljH4qVVjUbYbB1fDGR/gX2++rCUCIRrlAAYrBMREVH3duzYMfTv3x8XXXQRBg8ejEmTJqGkpMR5f21tLebOndvpdQjN5sqKothi25n297RdsmjRItTW1jq/CgsLz7JiIiIiLxXubv2+sET/1UFE1IzJZMKaNWswb968Nl+De4vBeheV4VzAtGkUjCiKaHR0rIeom4L1yGB7x7pNBKp1He9al+arD09tCtbr9OazCutbc6ioFi98eQT1Bgb3RERE1Hn++te/YvDgwSgrK8PRo0cRFhaGcePGtbpwqK/FxMRALpe36E4vKytr0ZUuSUhI8Li/QqFAdHS0x2NUKhXCwsLcvoiIiPwqOMbzdrMO2P4SUJHj33qIqFOIogiLxeL11+nTp3H06FGcPn26Q8dLjSYd8emnn6KmpgZz5szx3RMBQHHmXSgQnB3rFU0d60aLDWar/S+R6+KlSrkMEVolanRmVDaaEO3oYPfWgcIaAMDw1EhnsG4TgQaTBWFqZYfO2Zp/bD6KrUfL0Tc+FLNH9PDpuYmIiIgkP/30E7Zs2YKYmBjExMRgw4YNuPvuuzFhwgR89913CA4O7tTrBwUFYcSIEdi8eTNmzZrl3L5582bMnDnT4zFjxozB//73P7dtX3/9NUaOHAml0revyYiIiHzmsr8DH1zl+b7CncDXTwHXr/VvTUTkc1arFd9//71Xx+h0OhQWFsJsNkOpVCIlJQVardarc0yYMAEKRcei7KysLEyfPh1JSUkdOr417FjvotJjWo6CkbrVASA4yP0vUnSwNGfd2KHrGcxWlNYZAAC940KgVsoRpLD/9ajV+b6rXFqU9Ww67ImIiIjORK/Xt3gB/vrrr+OKK67AxIkTcezYsU6vYeHChXjnnXewatUqHDlyBA888AAKCgpwxx13ALCPcbn55pud+99xxx3Iz8/HwoULceTIEaxatQpZWVl46KGHOr1WIiKiDut9CTDkmtbvP7YJ2Lvab+UQUddhMBhgNpsRHBwMs9kMg8Hgt2vn5+djy5YtWLBggc/PzY71LqqnI1gvqTVAb7JCEyRHo9EKANAo5ZDL3OcBRYeocKK8EZUdXMC0vN4eyAcp7N3vABCuUaK83ohavRm+XP5KFEWU1Nr/A5IeExEREVFn6NevH/bs2YP+/fu7bf/Xv/4FURRxxRVXdHoN11xzDSorK/Hss8+ipKQEgwYNwpdffom0tDQAQElJidtomoyMDHz55Zd44IEH8PrrryMpKQmvvvoqZs+e3em1EhERnZUr3wI0EcDe9wCLvtmdNmDLs0DaOCCmdyCqIyIfkMvlmDBhglfHVFZWYseOHdDpdIiKisKYMWNaHXHY1nU7Ijs7G3Fxcbjssss6dHxbGKx3UZHBQQjXKFGrNyO/qhH9EsLQ4OhYdx0DI4kJsXesV3awY13qVk8IUzuH+EvBep2PFzCtM1igM9kD9QYjZ6wTERFR55k1axbWrl2Lm266qcV9r732Gmw2G1auXNnpddx111246667PN63evXqFtsmTpyIffv2dXJVREREnWD6MuAPtwK7s4Cf3wLg0lCnr+RIGKJuThAEr0eyxMfHY/z48aipqUFERARiYlpZk8HHbDYbsrOzccstt3R4jExbOAqmC3OOg3HMWW802YP1ULWnYN0+V72ysWMd66W1TcG6RJqzXuvjYF26FgDnmwVEREREnWHRokX48ssvW73/jTfegM1m82NFRERE54GY3sD0v3le0PTYl0D2ZVzMlOg8ExMTg8zMTL+F6gCwZcsWFBQUYN68eZ1yfgbrXVhGtH2I/0lHsN7Usd7yow/RwfZgvaKDo2BOOzrW48M7P1gvrm36OFi9gcE6ERERERER0Tnnu78Bjac935f/A5A9g+E6EXWqadOmQRRF9OnTp1POz2C9C2vesd7gCKGbL1wKANFnGAVjs4mw2cRWr+UM1kNVzm3sWCciIiIiIiKiDin9BQCQAysWwYDroMMiGJAjjYZpLLOPhSEi6qY4Y70Ly3AG6zoAQKMjhA5pa8a6h1EwNpuIWW/8CItNxIZ7xrdY+BQASuvsgXyCHzrWS2qaOtYbGawTERERERERnXuCY5ENExbAAAGACEAAsAwmZEGNOQgCCncGuEgioo5jx3oXJgXrOWX1EEWxzcVLo0OkUTAtO9aLa/U4WFSLw8V1OFXdfFVuu9OOLvJ4lxnrYZ02CqapY52jYIiIiIiIiIjOPTmKICyAATYBsApo+hPAfBhwHDbAYuQ4GCLqthisd2F94kOhlAuo1plRVK1Ho9H+cakQD4uXRgdLo2BadqznOkbJAEBeZWOL+wGg1DEKxh8d6xwFQ0RERERERHRuW1X1G1p+Xh6AYO9cz4IJkCmBmnw/V0ZE5BscBdOFqZVyDEgMw8GiWuwvrEGjqfVRMFLHeoPRAoPZCrWyaYFT12A9v7IRQKzbsaIousxYbxms1/m4q9x18VIG60REROQvx44dw9atW1FWVgabzeZ231NPccYrERGRL+WZGyF6TNbtY2HyYANEGxCR5te6iIh8hcF6FzcsJQIHi2pxoKAGerO9Y93T4qVhagWC5DKYrDZUNpqQHKFx3ufesa5rcWyt3gyjxf7LZVxY5y5eKoqie8e6wQJRFCEI9v/b/mdvEf7+1e945+Y/YHCPcJ9dt6MsVhve3ZGPsb2i0T8xLNDldMimX0tw6FQtHprW1/k8ExERnW/efvtt3HnnnYiJiUFCQoLb/xMFQWCwTkRE5GPpMX0hFGzzeJ8AIB0yILYvENPbv4UREfkIR8F0cUNTIgAAB4tqnAt9BqvkLfYTBAHR0gKmzeast+xYdyeNgYnUKt063Z0d6z4M1uv0FuhMVudti010hvoA8NXhUpyuM+KH4xU+u+bZeG9HPp77/De88OWRQJfSYU9vOIzXvzuBw8V1gS6FiIgoYJYsWYLnn38epaWlOHDgAPbv3+/82rdvX6DLIyIiOufMG/sQRMFD7CTaO9bnKyOASX/1d1lERD7DYL2LG+YI1n89VYsaR8DtaRQMAJdg3X3O+pk61ks9LFwKdE7Hekmd3u3cgPs4GOlaNfqWs+L9zWYT8e6OPACeZ9f7yoaDxdh+rLxTzm0wW3G6zv5GS7mHhW2JiIjOF9XV1fjzn/8c6DKIiIjOG72jeyPriizIBBnkECADIAcgE4Cs8D7IvPRFoPclgS6TiKjDOAqmi0uPDkaYWoE6gwX7C6oBeF68FACig+1jXCpcAlSTxYbCqqYwvaBSB6tNhFzW9PFn53z1NoJ113EtZ6Okxn6tpAgNrDYRDUYLGgwWxDhmxNfqzG5/BtLWY2XId7wRoTN1ziz4ygYj7vtoPzRKOX55ehoUct++1+U6dqcrPKdERESB8uc//xlff/017rjjjkCXQkTU5RzXGVCgNyFVY2/W2lndAAjA6IgQZGrVZziaqHVzhs3B+NTxyPrx78irPIb04HjMz5yOzJSxHAFDRN0eg/UuTiYTMDQlAt/nVKDeII2COUPHemNTd3VhtQ42EdAGyWG22mCy2lBaZ3CbwS51NCe0EqxbbSIaTdZWO+W9IS1cmhSuRnWjyR6se+pY7wIhcPaPec7vXcfX+FJVowmiaD9/cY0BqdFan57fdaHYal3gPwVAREQUKJmZmXjyySexc+dODB48GEql0u3+e++9N0CVERH5nxSkAyK+qazFxyXVaLSJkMEeEkjtOclKBf7ePwXFBhN+rtUhTCE4+o5FRAUpEBekxOiIEBTojVhdVI4ykxUjwrWY2yOWgTw5ZUZlYunlbwa6DCIin2Ow3g0MdwTrktYCbqnru6K+qWM9t9w+BiYjJhh6kxUnKxqRX9HoFqxLM9bjw91f+KiVMueCqLV6s0+CdamDOiFcjTzHvHfpDQOgaQRMoEfBHC+rd3vOOytYr3d5UyG/qtH3wXpNU8d6V3izgoiIKFDeeusthISEYNu2bdi2zX0hNUEQGKwT0TnvuM6AT09XY19tI440GlBnsUBvA2wu+9gAuH5W95TZght/yXXbx5UKQLhSjgqz1bnPgQY9viqvxbJ+KZgSHd4ZD4WIiKhNFosFzzzzDD744AOUlpYiMTERc+bMwRNPPAGZzHfTIhisdwPSAqaS4KDWgvWWHevSfPWMmGA0Gi04WdGIvEodxmY2HXdaCrubdawLgoAwjRIVDUbU6sxuYXxHFbuMgglR2zvFpEVZjRYrDGb7y7Fave9Gr+hNVnx24BSm9o9HbKiqXce8+1M+APtzf7CwBjqTpd3jcCobjAhRK6BStFxktrkGlzcV8ip1mODjT8IV1zR1rPtyVj4REVF3k5ubG+gSiIgCZs2pcvwj9zROmy2thuStaWt/I4Ayc8smpCKTBX/5rQCLeibgxuRYAO7jZtjNTkREnenFF1/EypUr8e6772LgwIHYs2cP5s6di/DwcNx3330+uw6D9W6gebDe6uKlHmasn3QE6z1jglFnsAAoR35lo9txUsd6QnjL0Dlco7AH6z4KZUsdi5cmhqsR6ngc0igY12vUNhtbcqpGj/V7i3DzmDREaIO8uuYHP+djyRdHcMOoWjw/a/AZ96/Vm7F+XxEA4O5JvXDb+3thEwGjxQa1su2wvLTWgIv+/h0uTI/CmgWjzngt1279/IrGNvbsmBKOgiEiImpBFEUA8Mn6MUREXZUUZOfqjVh6ohgNNtGv16+0WPHsiWLsrGnESZ0RR3UGRCjkmBQdhjtT4xiuExFRp9mxYwdmzpyJyy67DACQnp6OtWvXYs+ePT69jm9XSqROEROiQo/Ipm7xVhcvlTrWG1w71hsAABmxwUh3jBnJaxasSzPW40JbvrBxXcC0Ld/+fhrPbDgMs7Xt/gdp8dKEcLXzDQJpHIrr4po1za731rYTeHnzMbzzvffdZnvy7Iu+nihvaNf+3+eUQ2eyoldsMKb0i3Nub884mCMldTBZbDhQWNOuazUYmx5nXqWujT075hRHwRARETm99957GDx4MDQaDTQaDYYMGYL3338/0GUREflGTg6waBHq/3w1frnnPrzy9fd4/kQxlp0sgdEmwrv2pPZrq/WoziriP2U12NegR6NNxCmTBZ+frsHP1e373YyIiKgjxo8fj2+++QbHjh0DABw8eBA//PADZsyY4dPrsGO9mxiWEoGianv3cbDK80sXacZ6ZWNTx3pehT2sTY8ORo3WHqzmuwS4ZqvNuX9CeOvBet0ZgvW/bfwdx043YELvGEztH+9xH1EUUeIYO5MUrnG+QSCNQ3EN73UmK4wWq3OcSrHjuF25VW3W4ckvRTUA7F3v7VHtGKXTOy4UCrkMKoUMRosNOpMFUcFtvxw97ej+lxZlPdNcereO9Urfd6y7joJp/mYFERHR+eTll1/Gk08+iXvuuQfjxo2DKIr48ccfcccdd6CiogIPPPBAoEskIuq47GxgwQKIgoBgUcQAQcCrK17Dk399BjmXXA4RQJBMgFYmoKdGhSqzBTqrCEBEn2A1xkWG4PK4SOysrseWyno0WKwIUcoRLBPQaBUBUUSoUo5wx+9nvzcaIAAYExEMAQJO6o3O+zZV1KHI2PrvHrU2Gz4urcKoyBB2rRMRdUOiKEIUvc+YdLpc6PVF0Gh6QKvN8Pp4QVC2+xOnf/3rX1FbW4t+/fpBLpfDarXi+eefx3XXXef1ddvCYL2bGJYSgc9/KYFSLrQ6u9u5eGmDCbV6MxQywTnmJSMmGNWOjuW8ykbnvPCyeiNEEVDKBUR5GLHSno51URSdof/J8kZM7e95v1q9GXrH/D3XjnWpa7t5R3Wt3oy4UPtjrXSMtzlQVOMWuJ9Jeb3RGcqX1BhgtYmQy9r+j7DOEXaHOoJ/bZDcEayfuWNder4BoKzOgJDYkDb3b3BZvLSgSgebTYTsDPW1lyiKKHEN1jkKhoiIzmP/+te/sGLFCtx8883ObTNnzsTAgQPxzDPPMFgnou4rJwdYsACw2SAAEGD/aLoI4LkXn8GRYSNQnZaBIaFa/F98BKZEh+O4zoBCvQkpzeadZ2rVzpnoHTWnhwFzf8lFjt7Y6j6/1Onwv7IaXB4XwXCdiKibEUUz8vJWeHWMyVyN2tp9sFr1kMs1CA+/AEHKSK/OkZ5+JwShfZ+/WrduHdasWYMPP/wQAwcOxIEDB3D//fcjKSkJt9xyi1fXbQtHwXQTw1MjADQF3Z7Eh6nQNz4UVpuIdbsLnCNfooKDEKENQnKEBnKZAIPZhrJ6+4ucUkfoHBeq9hjotidYrzdanKFzbhtd11K3elRwENRKuTNYbzRaPV7DdTRMlaOL3GSx4ddTta1eo7lDp2qc31tsIsrqDa3v7FDvDNbtj13rWCy2PcG6NFan+fcWqw0L3t2Dl78+6ra/6+KlRosNp9tR3+ofc/HqNzln3K9Ob0GjS80cBUNEROezkpISjB07tsX2sWPHoqSkJAAVERH5yKpVgIcOPgEABAE3b9qAEeHBuDc9HlOiwwHYA/TJ0WGdEmpnatW4PSUGrf/mCugBvJxbihdPluC47sy/AxERUfdmMdfCatUjSBkNq1UPi6WuU6/38MMP49FHH8W1116LwYMH46abbsIDDzyApUuX+vQ67FjvJi5IjcQdE3uhd1zrHdCCIGD++Aw8sv4XrP4xD/Fh9hdJGTHBAIAghQzJERoUVOmQV9GI+DA1yhwd1vFhLRcuBdoXrEvhPADklrcVrNu7pxMcdUmjYKQgu/moEtfbrnPj9+RVY0RaVKvXcfVLkXsIf6paj8RwTSt7w1GP/bquHesAoHPpLm/NadeOdZeQ/HBxHbYcOY2fTlRg4bS+LtdyP2deha7N+qw2Ec99cQRWm4g/DUlEzzY64qXRNwqZAItNRJ3B3K6OfSIionNRZmYmPv74Yzz22GNu29etW4fevXsHqCoiIh/IywNEzwuTykQRY2sqMNjPi4VKXe8rCstwopXfJc0AviivxYAQNR5IT/RbbUREdHYEQYn09Du9Okany0VBQTbM5ipotelITZ3r9TgYQWjrLdvm19NBJnPvJ5fL5bDZ2l4b0lsM1rsJQRDw6PR+Z9zvimFJWPbV7yiuNWDltpMAmoJ1AEiL1qKgSof8Sh1G9Yx2ji7xNF8dAMLaEayXuATrzRdGdVXsWEgzKcIRrDcbBdP8GlKHtdFidS5wCgC786px+8RWL+OmRbBeo8fIMxxT33wUjMqbjnWDx++lWec6kxVmqw1Kuf0/7oZmYX1+ZSPG9Ipu9fwNRgusNvuL5v0FNW0G69IbGZlxIfi9tB6iaJ+VH3mGOfFERETnosWLF+Oaa67B9u3bMW7cOAiCgB9++AHffPMNPv7440CXR0TUcenpHjvWAfvvkfF9eyM+AONWbkyOxY3JsVhzqhyvF5Qh32BG8zjDBuDl3NMQRRELM5L8XiMREXlPEIR2j2SRhIT0RVrabTAYiqBW90BwcM9Oqs7u8ssvx/PPP4/U1FQMHDgQ+/fvx8svv4x58+b59DocBXOOUSvluGl0OgDgSIn9YxWuwXp6tP37/Cp7AF7q7Fj3/EKrPR3rrnO8S2oN0Jk8d3ZLne1SR7YUXEvhcvMFUqWZ4NIYGMne/CrYbJ47MlyJougM1ns6ngNpFnxb6hwd62HSKBilo2Pd7G2w3jQKxnXhVNfnUnrDINQR3ue5LCzriWsQf6Cwps19pTA/NUrrfBODC5gSEdH5avbs2fj5558RExODTz/9FJ988gliYmKwa9cuzJo1K9DlERF13Lx5rXasQxSB+fP9W08zNybH4v2hvfBwRjw8rZRlBvBKXhnWnCr3d2lERORHwcE9ER19UaeH6oB9faWrrroKd911F/r374+HHnoIt99+O5577jmfXofB+jnoxtGpCFI0/Wibd6wDTQHuaUfYnXA2wXqt+0y8vArP4XCxNArG0R0fHCQF6/bAuvnimtI1pTEw9tnsMlTrzDhZ0dBqPa51VTQYIZcJuGRAPAD3gLs1LTrW2zkKxmy1ocJlZI1ryO4a6Lu+gdDgCPEHJIUBAAqqWu/4t+/f/mD9lPMTAhrnz7GaC5gSEdF5bMSIEVizZg327t2Lffv2Yc2aNRg+fHigyyIiOju9ewNZWYBMBsjl7n9mZQGZmYGuEJla+7iXB9PjPN5vBrCrtu0mIyIiovYKDQ3F8uXLkZ+fD71ejxMnTmDJkiUICvLtFIcOBeuFhYUoKipy3t61axfuv/9+vPXWWz4rjDouOkSF2RckO2977Fiv9K5jvXk3uavS5sF6K+NgpA5q5ygYqWPd4D4KRuPoEHcG646O9bhQFYan2FcM3p1X3eL8BrMVW347DYOjs1zqVu8TH4pejpEpp9rRsd40Y93Rsd7OUTDSgrDO2y4d68Wtdaw7gvJByfZFhFp7U0Iijc0B7J9IMLTRRS+NgkmKUCMy2PEGCRcwJSKi80hdXZ3b9219ERF1a3PmAEePAg8/DFx9tf3Po0ft27uAnMoczP7sASzeNB/1ua/Cos9vsY9V9O3cWyIios7WoWD9+uuvx3fffQcAKC0txSWXXIJdu3bhsccew7PPPuvTAqlj5o2zLwCgUsicYTrQ1LF+srwRH+0qcAa5rQbr2nZ0rDvC+SDH3PDcCs/B+knHwqYZMfaQu2nGuvvipVKN0oz1ygZ7QB0TosLIdClYr2px/vd35GPBe3tw/0cHAAC/FNUAAIYkhyM50j5+pkMd69IomFZG3EhcO9QB4LTL4qWtjYKRHvugZHvHen5lI8TWPsYJ98VOLTYRh4trW9236Y0MDSI09nfkavTsWCciovNHZGQkysrKAAARERGIjIxs8SVtJyLq9jIzgaVLgbVr7X92gU51AHhh55vo+1o/fHLgX6gr+xq6wvdQuftK6Es3uO23vboB31a2/vsNERFRV9OhxUt//fVXXHjhhQCAjz/+GIMGDcKPP/6Ir7/+GnfccQeeeuopnxZJ3usdH4pVc0ZCIZNBE9Q0yS4lSosguQw6kxWPfnLIub21xUtdR8GIogjBw6I4pY7O6OGpEfg5t8oZoLuqM5idHd09Y+1Bv3PGuiMsrnUJ1n8vrXcG7dIomOiQIIxMjwIA7PHQsf6bY6b8psOl2HioBIdO2V+UDUkJR3KEI1iv1rf6OCRSeC0t3KpVScH6GTrWHcF6TIgKFQ1GnK4zOK/VWse69Nj7J4ZBEIBGkxUVDSbEhqo8XqP5Yqf7C2owIi3K477FrqNgHG+QVDeyY52IiM4f3377LaKi7P+flJpCiIjIf7ac+hWPf3UX0GLZUqDu2GIow4dBoUkFAOisNvxSr8eU6HA/V0lERNQxHQrWzWYzVCp78LdlyxZcccUVAIB+/fqhpKTEd9XRWZnSL77FNrVSjlevG45vfz+N8nojyhuM6BsfhnRHl3hzUrBusYnQmawIVrX8KyPNWB/TKxo/51Z5HAUjhe1xoSrnoqBSx3qjyQqbTXSOm0lzdNhLM9elUTBRwUG4IDUCMgEoqNKhrM6AOJdO+4KqpjEqT352GEaLPQgf2iMCiY7xM3qzFdU6M6KCPc9UstpEZ3jdYsb6GYJ1aSTOkB7h+Pb3MhjMNtQZLFDKBVS7jGCRHqfNJqLB0QUfHaxCUrgGp2r0KKhqbD1YN7gH663NWbfaROeYn6RwDSIdwToXLyUiovPJxIkTPX5PRET+sWrfKkAQAI8fyhWgL/0UoRn3AgC0chmGhGr8Wh8REdHZ6NAomIEDB2LlypX4/vvvsXnzZlx66aUAgOLiYkRHR/u0QPK9SwclYNlVQ5E990J8/pcJ+MfVQ1vt4NYo5VDK7fd5GgfTYLQ4O7zH9LT/7D2NgjlRZl9sVJp1DsAtpG8wWZyjX1KjtG7Xcx0FE6pWol+CfWzKnnz3rnUpWA9TK1DRYES9wYIguQx94kOhUsgR5wir25qz7toR3hSsSzPWzzAKxtGRnxqlRYQjyC6rM7S4nvS4Gk0WSFNfQtWKpoVl25izLtUnBe9SsG6ziZibvQuXvLwNtTozyuoNsNpEKGQCYkNVzlEwtVy8lIiIzlObNm3CDz/84Lz9+uuvY9iwYbj++utRXd3yk3BERHT26nRFQKujLkUojCVIVSvRV6vCXzMS2K1ORETdSoeC9RdffBFvvvkmJk2ahOuuuw5Dhw4FAGzYsME5IobODYIgOLvWazwsfCl1aYeqFc4FOKsaTS0WyTxR7gjW45rmvasUMmdoX1ZnhMVmf8HVfMZ6lUvHOgCMSLPPQXXt1tabrCh3BNv/vHY4pPcJ+ieFIUhh/2veNGe99eBaWrg0SCGDSmHvVG9vx/rp2qaFYOND7R3ypXWGFnPdpWBdCskVMgEqhczZqZ/fyuKv9vrsx4zrFQ1BAIqq9ahoMOLTA6fw3dFy5JQ1YM3P+c7RMwnhashlgjPor+bipUREdJ56+OGHnYuUHjp0CAsXLsSMGTNw8uRJLFy4MMDVERGdmwZH94Ks1TGcAhLDUvFinxRkDc7Ajcmxfq2NiIjobHUoWJ80aRIqKipQUVGBVatWObffdtttWLlypc+Ko64hJsTeHV3h6Bx3JQXrieFqBKsUzq7w3GbhsDNYd+lYFwTBOQ6mqNoedivlAhId896lUTAVjmA92hGs90kItZ/T0QXvenyoWoHJ/eKci7eO7dX0CQppznpRGx3rzvnq6qZu+mBnx/oZgvV6KVhXIS7M/jycrjO2Hqw7rhWiVkAQBOc4nrzKM3esJ4RrkOl4LnecqMSyTUed+6z6Idc5eicp3P6YI7TS4qUM1omI6PyUm5uLAQMGAADWr1+Pyy+/HC+88ALeeOMNbNy4McDVERGdm+YNn4dW5sAAEHHr8HmYHB2GTK3nNb+IiIi6sg4F63q9HkajEZGR9s7h/Px8LF++HEePHkVcXJxPC6TAk+aYn3bM7HZVXCt1RtsD3IwYe9d1bkWD234nHEGva7AO2ENlAM7wOVwT5AyB6wwWWG2icxRMtCPglwLl4+VN15DGwEhjZB6f0R9rbx2Ne6f0du7T1LHeerAuzT8PdcyBB+Bc/PVMo2CkNxkSwtSId3nOpO7xILn9PzcpWK9vNsu9PR3rUhgfqlZgWEoEAGDx/35DaZ0ByREaJEdoUNlowoqtJwAASY7Z8hHSIrQcBUNEROepoKAg6HT21wtbtmzBtGnTAABRUVHOTnYiIvKt3tG9kXVFFmSCDHJBDkGQQRDkAGS49aLleHDAqECXSERE1GEdWrx05syZuPLKK3HHHXegpqYGo0aNglKpREVFBV5++WXceeedvq6TAije0YVeVt9Gx7ojSO4ZG4yfc6uQ6zIn3Gy1OcPiXnHuwbrUDS7NIQ/XKJyjZwB70F3VrGNdGidTWKWDwWyFWilvEazLZALG9HKf99/D0bHe1oz1eoN72A20fxRMWZ39+YkLUyPe0bFeVmdwBum940NwuLiuKViXOtZV9seb5kXHeohKgWGpEfj33iLnJwkend4PVY0mPL3hME465twnOR5zZDBHwRAR0flt/PjxWLhwIcaNG4ddu3Zh3bp1AIBjx46hR48eAa6OiOjcNWfYHIxPHY+sfVnIq81Deng65l8wH5lRmYEujYiI6Kx0qGN93759mDBhAgDgP//5D+Lj45Gfn4/33nsPr776qk8LpMCLcwmJmyuRurQd41vSo6WO9aau68IqHcxWERql3BnAS0JbdKwroZTLnCNiSmoNzkA7OsQerMeGqBCmVsAmAnmOwL55sO5JezrW641Sx7prsH7mUTCNRouzAz0h3LVjvWkUzIBE+6KrtXr7fs7uc8djTY8OhiDYO9rLPbyJYa/PJVh3dKwDwPDUCPxpSCKuHpninEUPAImOYD3csXhpDTvWiYjoPPXaa69BoVDgP//5D1asWIHk5GQAwMaNG3HppZcGuDoionNbZlQmll68FGtnr8XSi5cyVCcionNCh4J1nU6H0FD7nOuvv/4aV155JWQyGUaPHo38/HyfFkiB5xoSN1fqGAUjzUWXRsHkuQTr0hiYnrHBkMncF66RAnSpi1waAyN1rZ90jJQJcgnbBUFwdr6fKLOfu9ARrKe0FaxH2O9rz4z1UFVT17yzY93Y+igYaUxOcJAcISoF4hyLl56uN6C4xn5ff0ewXudcvNT+pzQORxMkR4bjjYkjJZ4/kt5gaDqmb3woIh2Lkj5x2QAIggBNkBxzxqa7PGZ7HdJ+dQYLLFZbq4+DiIjoXJWamorPP/8cBw8exPz5853bX3nlFTaGEBERERGdY+rr63H//fcjLS0NGo0GY8eOxe7du316jQ4F65mZmfj0009RWFiIr776yjmjsqysDGFhYT4tkALPNSRurnnHes/Ypo51UbQvUuNp4VJJiGOWeVF1U8c6AEQ4gmBpEc7okCAILqvJO+esOxYwLayyH99msO7oWK/Vm50jVZpzLl6qcVm8VOUI1s2td6xLbzrEO54HaRRMcY0epY7QfUCSe7DuaexMv0T7G1atBuvGpi53hVyGDxaMxrrbRmNEWqRzn5vHpDnfDJA+QeA2XsfQ9qx4IiKic5XNZsOxY8fwww8/YPv27W5fRERERER07liwYAE2b96M999/H4cOHcK0adNw8cUX49SpUz67RodmrD/11FO4/vrr8cADD2DKlCkYM2YMAHv3+vDhw31WHHUNTaNgPHSsO0JjaZZ3SpQWMsEeAJc3GBEXqsaJsjaCdUcXuhTaNw/WpVBeGgMjcXaslzdAFMV2jYIJUdnnt9fqzThVrUffhNAW+9QZPC1eeuZRMFLHenyoFKy7d/kr5YLz8dcb7YuyNs1Yb/rPsH9CGL48VIrfS+s9XkcaHyN1uUthvasIbRDen38himsM6Om4pkIuQ6hKgXqjBTU6k9u4GCIiovPBzp07cf311yM/P9/55r9EEARYrW2vpUJERERERN2DXq/H+vXr8dlnn+Giiy4CADzzzDP49NNPsWLFCixZssQn1+lQsH7VVVdh/PjxKCkpwdChQ53bp06dilmzZvmkMOo6pJC4rN4AURSdneN6kxU1jsUwpY51lUKO5EgNCqv0OFbaYA/WpY51x6KjrkIc3eDS77fOYN0xE1zqWI8KVrkd18ulY72iwQS92QpBAJIdAX9rkiM09mC9RucxWPfURR7s6P42WWywWG1QyFt+0EMK1qXnITZUBUFoelyJ4RrnmwWAvWvduRCpy7WkcTGtday7zlhvy4i0KIxIc98WEaxEvdHCBUyJiOi8dMcdd2DkyJH44osvkJiY6PZJOCIiIiIiah9RFGFu1qjSHid0BhQazEhRK9FLqz7zAc0oBaHdr+EtFgusVivUavfraDQa/PDDD15fuzUdCtYBICEhAQkJCSgqKoIgCEhOTsaFF17os8Ko64gNsYfaZquIap3Z2e1c6jJXPNQl6B2VEY3CqiKs/ikX4zKjm2asx3jqWFe63ZaC9TCNe8d6TLMO60xHx/rJigbkOxYwTQrXIEjR9nSj5EgNfiupc850b64pWHftWJc7v9eZrQjzEKxLz4XU3a+UyxAdrEJFg71jPTlCA6VchuAgORpNVvs4mmaLlwJAf0cH+vGyBhgtVqgUTde22USPYXx7RWiCUAg9avVcwJSIiM4/OTk5+M9//oPMTC6YR0RERETUUWZRxD/zT3t1TJXZgj21jdBZRWjlAkaGByNK6V22dV9aPILaGayHhoZizJgxeO6559C/f3/Ex8dj7dq1+Pnnn9G7d2+vrtuWDs1Yt9lsePbZZxEeHo60tDSkpqYiIiICzz33HGw2Lox4rglSyJxhutSZDQAlNfZwOiFc7faO0V2TekEmAFuOlGHr0XLU6s0QhKaFTV01D4ilrm7pT2n8SvNRMCmRGgTJZTCYbfg5t8q+LartbnWgqaO9qMZzsC7NP3ftWA+SyyB3LLqqM3r+mLg0JichrOmdMGnOOtA0Kkd6w8B1zrtr93lSuBphagUsNtG5MKtEZ7Y6O+BDm70h0R7Sc1rjoWO9vN6IXY7nkYiI6Fw0atQoHD9+PNBlEBERERGdd2rNVuisImKVcuisIuosnT+G8f3334coikhOToZKpcKrr76K66+/HnK5/MwHt1OHOtYff/xxZGVl4W9/+xvGjRsHURTx448/4plnnoHBYMDzzz/vswKpa4gLVaGq0YSyeiP6J9q3SQuXJoa7B9o9Y0Mwa3gPrN9XhEWfHAJgD7RdO78loc1GmjSNgnEPjpuPglHIZUiP0eLY6QZ893sZACAlsvX56hIpWC+pabkQKwDUO2ash7kE64IgQBskR73BAp3J88KfUsd6vFuwrsbhYvtIF2nh1HCNEiW1BtTqzR7nuQuCgH6JYdiVW4UjJXVuM9SlDne5TIBa6f17YhFa+5sTnkbBLPz4AL7PqcDnfxmPQcnhXp+biIioq/vLX/6CBx98EKWlpRg8eDCUSvfXGkOGDAlQZURERERE3YdSEHBfWrxXx5zQGfBWYTkqzVZkaFW4LSXW63EwSi9HOfbq1Qvbtm1DY2Mj6urqkJiYiGuuuQYZGRlenactHQrW3333Xbzzzju44oornNuGDh2K5ORk3HXXXQzWz0HxYWr8Xlrv1rFe2myuuKt7p2bi0wOnnPt4WrgUOHPHuqR5x7p0zmOnG7CvoBpA2wuXSiIdnfc1es9zxj2NggHgEqx7fkfNuXipS5e66/fJEfbnyGPHerPnYIBLsO6qwWivOUSl6NBcWOnNilpdy1Ew0mKphVU6ButERHROmj17NgBg3rx5zm2CIDjXj+HipUREREREZyYIQrtHskj6h2hxd1o8CvUmpGiCkNmBGesdFRwcjODgYFRXV+Orr77CsmXLfHbuDgXrVVVV6NevX4vt/fr1Q1UVx0mci6SQuMx1FEytfZxKoodgPS06GFdd0APr9hQCaD1YD26lYz1c4x6kRwe3DNalOes2x3iU1OgzB+vhLsG2J54WLwWA4CAFAKPHYF0URecoGNeO9bjQpu+TI7Qtru9pxjoA9E+0L6p6pNQ9WJdqO9PCpa2JlEbBNHvsRosV5fX2+qWwvzOYLDbMyd6FULUCK28cwUXjiIjIr3JzcwNdAhERERHReStTq/ZroP7VV19BFEX07dsXx48fx8MPP4y+ffti7ty5PrtGhxK6oUOH4rXXXsOrr77qtv21117jx2jPUVJIfNoRIANAaW3rHesAcM+UTKzfVwSLTUSvuJbz1YGWIbHU0d2yY919FAzQMqxPaUfHuhRs17UarLcczwI0LWDa6GEUTLXODJPVvraAa5juGrK7joIB2u5Y759oH/9ypKTe2UUHNIXezUP/9gpvZRTM6dqmn2ljJwbr3xw5jZ9OVAIAqhpNHn+mREREnSUtLS3QJRARERERkZ/U1tZi0aJFKCoqQlRUFGbPno3nn3++xUjIs9GhhG7ZsmW47LLLsGXLFowZMwaCIOCnn35CYWEhvvzyS58VR12Hs2O9vqljvbhGmrHuOVhPidLiwWl98Z+9hZjaz/PspeYhcXhrwXobHeuS9oyCaatj3WoT0ejoSA/z2LEO6D10rEtvMEQHByFI0TT73HUUjPQcuQb7rY2d6RMfCplgD5/L642IcwT0Db7qWG82Cqa4tmkh18ZWRt34wtrdhc7vC6v1DNaJiMjv3n//faxcuRK5ubnYsWMH0tLSsHz5cmRkZGDmzJmBLo+IiIiIiHzk6quvxtVXX92p1/B+BUQAEydOxLFjxzBr1izU1NSgqqoKV155JQ4fPozs7Gxf10hdgBTuSh3rZqsNx8sbAAA9YzyPeQGAOyf1wjcPTmq1q901JNYo5VAp7J3hEc1HwXiYsZ4R09QFr1HKPYbvzbkG66Iout0nBddA6x3rnkbBHCyqAQCkx7h35Usd9EnhaqiVcrfrV+tMTR3rzYJytVLufGy/ucxZr2+lw729IpzBuvubCiUuwXpnjYIpqtbh+5xy5+3CKl2nXIeIiKg1K1aswMKFCzFjxgzU1NQ4Z6pHRERg+fLlgS2OiIiIiIi6nQ4F6wCQlJSE559/HuvXr8cnn3yCJUuWoLq6Gu+++64v66MuIi7Ufcb6sdP1MFlsCFUrkNaO2eatcQ2JXbvUpQAasIfm2qCWYXKwSoEkR2CfGqVt18xu6byu3emSOscYGJVC5tZ5br+WFKy3DJ6/OXIaADC5b6zb9j7xoXh+1iC8fM2wFtcvqW3q/Pc02kUaByMtKgqcfce6NLe+Rt+sY72mqZbOGgXz7z1FcH0fo7CawToREfnXv/71L7z99tt4/PHHIZfLndtHjhyJQ4cOBbAyIiIiIiLqjjocrNP5RZoXXt5ghM0m4lBRLQBgSI/ws1qEMtglMHcN09XKpnA7qo1O9F6OcTDtma/uPK/cft7m42BaG80CABqlvc7mHesGsxU/HK8AAEzt33LczQ2j0jC6Z7TztvQYT9XYu8QVMgEqRcv/DJvmrDd1rJ/tjPXIVjrWi2tcRsEYfT8KxmoT8W/nIrb2TvzCKn1bhxAREflcbm4uhg8f3mK7SqVCY2NjACoiIiIiIqLujME6tUuso2PdbBVRrTPhl1P2YH1wcsRZnVcuE6ANch+TAgCCICDCcTvGwxgYSd/4UABAz1jPi6M2JwiCc4HU5rPGpY715vPVAThr1DXr6N5xohIGsw1J4Wr0Swg94/WdwXq1PVgOVSs8vjExoM1gvWOLLEQ4Fi+tN1hgcSy2Crh3z3dGx/r2nHIU1xoQoVVi3vgMAPbRMERERP6UkZGBAwcOtNi+ceNGDBgwwP8FERERERFRt9ax1lc67yjlMkQHB6Gy0YTTdUa3jvWzFaJSQGeyugXrgH00TFm9sc1FLm+9qCe0QXJcPyqt3dcL1yhQ0WBso2PdQ7Cu8jxjfYtjDMyU/nHt6tyXQn2jxR5stzYvvV+iPaQ/Ud4Ik8WGIIXMWV/HR8E0Pb+1erPzeXXrWPcw6uZsfbSrAAAwa3gyesXaP2HAGetERORvDz/8MO6++24YDAaIoohdu3Zh7dq1WLp0Kd55551Al0dERERERN2MVwndlVde2eb9NTU1Z1MLdXFxYWpUNppQVK3D76X2TurByT4I1tUKlNUbWwbrjpngbY2CiQ9TY+G0vl5dT7pOXYtg3X7bU0e41jEKxnUuuyiK+Pb3MgDA1H4tx8C0dW1JiMpz93lCmBoqhQxGiw2ltQakRmtbXey0veQyAWFqBeoMFtS4BOuuHeu+Xry0zmDGN0fsz9G1f0h1zqo/VaOH1SZCLuv4GCEiIiJvzJ07FxaLBY888gh0Oh2uv/56JCcn45///CeuvfbaQJdHRERERETdjFcJXXh42yFqeHg4br755rMqiLqu+DAVjpQA3+dUwGwVEaFVokek5qzPG+oIil0XLwWAcMft6DZGwXSEFG5707EuBcJ6l47uIyX1KKk1QKOUY0yv6BbHtHVtSWgrIbkgCEiO0OBkRSNO1ejtwboj+G+ty709ooKDUGewoKzOiF6xIWg0WtyeB1+Pgsktb4TFJiIuVIW+CaGw2kQoZALMVhGn6wxIijj7vz+t+fb309hxohIP/7Ffi8VoiYjo/HTrrbfi1ltvRUVFBWw2G+Li4gJdEhERERERdVNeJXTZ2dmdVQd1A3GOOevS+JPByWe3cKkk2BEuNw+d0xwLkmZEt29+enu1HqxLM9Y9LF4a1HIUzDeO52FcZgzUSrlX15a0tRBpkiNYl0a1OGesd7BjHQB6x4cir1KHIyV1GNMrGiW17ouInu3ipb+X1uHfe4pwz+RMRAYHId8x8iUt2v6zlMsEJEVoUFClQ2GVrlOD9SVfHMHJ8kb0SwjD7BE9Ou06RETU/cTExAS6BCIiIiIi6ubYxkntFh+mBtA0OsQX89UBIMYxkiTOcX7JfRf3RtYtI3HlBb4NRaVFPL3qWA+yb3ML1qUxMP3b3+0WpJBB4xLCt9V9nhRhfz6kYN05Y/0sOtYHJtkXRT1cXOc4t/1nGSS3/1NwNqNgqhtNmLNqN7J+yMUn+08BAAoqGwEAqVFNb46kRNnD9MJqfcuT+IjNJqKoyn7+zb+d7rTrEBFR91FZWYm7774bAwYMQExMDKKioty+iIiIiIiIvMHFS6ndmgffg5MjfHLeBy7pgwFJYfjTkES37aFqJab2b9/scm+EtdKxXucM1tvqWLfvU15vxMGiGgDAlH7efYw8XKOE3mwP6Nualy51cxfXunesd3TGOgAMTLK/GXK42L74rNSx3jM2GL+X1jsfn7dEUcSiTw6htM4e1JfXGwEABc061gEgJVILoLJTFzAtbzDCZLUvELs9pxwGs7XdnyogIqJz04033ogTJ05g/vz5iI+P98mn7oiIiIiI6PzFYJ3aTRoFI/FVx3pGTDDumNjLJ+dqj6ZRMO4hctPipWfuWN9fUA1RBPolhDo7+dsrTKOAY+3XNrvPkx3B+ilHV7lzFMxZdKwPSrZ3rOeUNcBgtjo71jPjQvB7aT3MVhFGixUqhXch9Ee7C7HpcKnzdnWjCQCQX2kPz1OjXIJ1x/eF1Z0XrBe5dMPrTFb8eLyiU96kISKi7uOHH37ADz/8gKFDhwa6FCIiIiIiOgdwFAy1m2uAHBMShMRw7wLlrqIji5c2n7EuBca94kI6fH3A8zx3iRSsF9foIYoiGqRRMKrWjzmThDA1ooKDYLWJOFpa7xwzk+nyOLyds36ivAHP/u83APY3GgCgSmcP1qWO9VSXjnVpwVtpVEtnOFXjfm6OgyEion79+kGv77z/9xARERERUdc1adIkrF692qfnZLBO7RYf1tSxPshHC5cGQmvBep2zY71lcK1tNgomv8o+OzzdJTD29vpAO0fB1OhhMNtgsYn2Y86iY10QBLc569K8/JRILdRK+z8HjV7OWX/9u+PQm60YlxmNv0zpDcDesW4wW52jYdL83LF+ytGxnuB4M2jLkdOwOp4/IiI6P73xxht4/PHHsW3bNlRWVqKurs7ti4iIiIiIyBscBUPtFhOigiAAoggMSfbNGJhAkILtulY61sPaMQpG6lhPc1mUs73C2hmsJzg+EaAzWXGqxn49QQC0ZzkrfGBSOL7PqcCvxbXO+e2JEWqEqBQwmE1eL2B6stz+JsNNo9MQrrEvDFutM6GoWg9RtD/GqOAg5/72GetAaZ0BJosNQQrfv78nPV8zhyfhw58LUNFgwoHCaoxI4+J0RETnq4iICNTW1mLKlClu20VRhCAIsFq9+8QWERERUaepyAGq84HINCCmd6CrIXIjiiLMVu+bF0+WN6CoWo8ekRr0jPV+AoRSLnS5Jl8G69RuSrkM0cFBqGgwYXCPiECX02Gtj4JpvWNdGgWjN1ths4lNs8PPtmO9je5ztVKOmBAVKhqM+L203r5/kAIy2dn9IyLNWT98qhYljhnrSeEaBKsUqGgwed2xLs0z7xGphVJuD8mrdWYUOLr6U6O0bv/wxYQEQaOUQ2+2orhGj/QY79+cOBOpYz09OhiT+8Zhw8FifP3baZ8G67+X1iH7hzzcd3Fv56cLiIio67rhhhsQFBSEDz/80K+Ll1ZXV+Pee+/Fhg0bAABXXHEF/vWvfyEiIqLVY+bMmYN3333XbduoUaOwc+fOziy143JygFWrgLw8ID0dmDcP6M0QgIiI6IwqcoD8n4DqPMBYb/+SKYDiA4C5AUgYCkx9kuE6dSlmq4jXvzvu1THVjSbsLaiG3mSFJkiOEamRiHRpwmyPuydnIkjBYJ26sbnjMvDTiQqMy4wOdCkd5hqsS11qQNsz1oNV9mBdFIEGk8U5wzs92vtQ2DVYP9NCpMkRalQ0GHFMCtbPYgyMZGCS/dMGvxbXOcejJISrnV353nSsG8xWVDQYHbVqYLbZAAA1OhNyK1ouXArYx9H0iNQgp6wBhdW6TgnWpbA/OUKDaQPjseFgMTYfPo1F0/v77Brv/pSPdXsKkRqtxd2TM312XiIi6hy//vor9u/fj759+/r1utdffz2KioqwadMmAMBtt92Gm266Cf/73//aPO7SSy9Fdna283ZQkHe/ePhNdjawYAGcH2sUBGDZMiArC5gzJ9DVERERdV0VOcCWZ4CTWwGzHhClT88JAGRAUDBQtBvI38Fgnbq9WoMZepMVMSH2ht06g9nrYN1bL7zwAl544QXnbb1ej507d+Kee+5xbtu4cSMmTJjQ4WswWCev3D05s9uHiFKwbbWJaDBaEKpWwmK1Oce8uI5qkagVTeNXck7Xw2oToVLIEBeqarFve68PAKFnWIg0KUKDg0W1TR3rbYyOaa+0KC1CVApngB4dHAS1Uu5888CbxUulxU+1QXJEaJXOjwLZRODXU7X263no6k+J0tqD9U5YwFQURecbHz0iNYgNjYBSLuBkRSOOlzW4LdR6NqRRQs0/+UBERF3TyJEjUVhY6Ndg/ciRI9i0aRN27tyJUaNGAQDefvttjBkzBkePHm2zFpVKhYSEBH+V2jE5OfZQ3fHGupv584Hx44HM7v26kYiIqNNU5wMlvwBWMyBK/y+VunFtLl9cL4y6FqVc8DobPFnegFU/5qKq0YT0mGDMG5fh9TgYpdy7bvU77rgDV199tfP2DTfcgNmzZ+PKK690bktOTvbqnM0xWKfzjlopQ5BcBpPVhlq9GaFqpVuXtqcucplMgDZIDp3JiiMl9pA7LVrbobEs7R0FAzQtYHrstO861mUyAQMSw7ArrwqAfb46AAQ7QvtGU/s71qUAOzlCA0EQEKQQEKpSoN5owcHCGgCex+WkRNofV2csYFqjMzvfJEmK0ECtlGN4SiR25VXhcHGtz4J16XmSPulARERd21/+8hfcd999ePj/2bvv+Dbq+3/gr9MeluW9HTvDGSQhOxBWEigjBdIWvuy25EugM4WWUgq0lPBrKS0tnUCh/SYEOqFllw0lAZoA2YvEcRLvPWVbsvb9/jjdSbKGJcfbr2cfKbF0kk4XJZZf99br873vYf78+dBqw09un3766UP+mDt27IDValVCdQA488wzYbVasX379rjB+tatW5GTk4O0tDSsXLkSDzzwAHJycmJu73K54HK5lK9HZEHWzZulCfUoREGAsGkT8OCDw78fRERE41FnDeBok4L1UGotIGgBQQ1YS4CSs0Zn/4hikPOfZMzOT8VXV05XOtanD6JjPVkZGRnIyAhWAhuNRuTk5GDGEA5+DP2qgUl4//33cfnll6OgoACCIODFF1+Mu/3WrVshCELEr6NHj47MDtOEIAiCMpUuTxvL4ahBq1J6wvszBXrWjzRKP6hOGcTCpUC/YH2ACXQ5WK/ucCS0faJOK0gNPoZVegwlWE+iCkbuMi9MD3aMyx/lOdkmdaxHW+C1OFAPU9sx9MG6HPZnpehhCCz0Kof7Ne1D93jycUp2sVciIhod11xzDY4cOYKbbroJy5Ytw8KFC7Fo0SLlv8Ohqakpahiek5ODpqammLdbs2YN/vrXv+I///kPHn74YezcuRPnn39+WHDe34MPPgir1ar8Ki4uHpLnEFdVlVT/EoXoF+E+mlz3JhER0YTk9wN1u4CKt6X6FwD49GVg6wOA1wNojUBaCTDrUuD0a4Gl64GMqVIVjNYwuvtONISmZ6dg5czsEQnVR8qoTqzb7XYsWLAA//u//4srr7wy4duVl5cjNTUYDGZnZw/H7tEEZjVq0NbrUoL17jgLl8qM/YL1aBUniT12ch3rQPBn1oG2T9S8Qqvyezm8T9ENIlgPmViXpZu0qOkIbtO/Yx2QFjoFgNrOxKtg/H4RgoABF5urixL2y/swlBPycmVOrzOxKhi/X0R5cw/KclKgiXHyhoiIhk9lZeWQ3dfGjRtx//33x91m586dAKJ/3wpd4yWaa665Rvn9vHnzsHTpUpSUlODVV18N++hqqLvvvhu333678nV3d/fwh+ulpTEn1gEBfZmF0AHobLKju92J1EwD0vOGfm0VIiKiMaetQqp6qf0EOPpvwN4KWIuBvHlA/iLgvZ8AjnYAIuAVgdR84ML7pS71inekbnV1LtDTyI51ojFsVIP1NWvWYM2aNUnfTv5YLNFgyeG23JPd3Rd74VKZvLin3HdeeorBukYlQK+JH7AWhATWwNBNrM8NmVjPt4ZXwfQm0bEeb2IdkJ5jQVrkGfbiDGn7ugQn1n1+ETdt2YnjLb145PpFWDQlPfY+yf3qaZHBek2cx3O4vaho7sXpRdYBw3sg+SqYf+2uw53PHcAdF83EhvP5poiIaKSVlJQM2X1t2LAB1157bdxtSktLceDAATQ3N0dc19raitzc3IQfLz8/HyUlJaioqIi5jV6vh16f/Novp+Smm6SFSvsRA/9/ctnl0H1Qj0Pb6uB2+pBZmIIVX5jOcJ2IiCautgrgvQeBY28CHgekjvQAewfQfhw4+C/AYw9eLghA/sJgeJ5eAhisUrgOATj+DlCyguE60SnaunXrkN/nuOxYX7RoEZxOJ0477TT88Ic/xOrVq0d7l2icsUZUwSQ+sS73d0/JHNwPhVOzzFg+NQPTsswDBriRwXr8xU4TNSMnBTqNCm6vH/nyxLqyeGniE+t1USbWM0zBYL0w3Rh1OlsOutvtblS12VGaFTyWv3+3Au12N3546Rzlts/tqcO2Y60AgOv/9DEe++JirJ4VvWc2WtgvB/nxFku998XDeG5PHZ5ctwyrZ8fusJUpE+sJHi+5J39frS2h7YmI6NS9/PLLWLNmDbRaLV5++eW4265duzbh+83KykJWVtaA261YsQI2mw2ffPIJli9fDgD4+OOPYbPZcNZZifeltre3o7a2Fvn5+QnfZkSUlQGbNgHr10MUBIj+YC3MttV3oK7WiBR7M2xtTgAiGo534cTuFiy9dOro7TMREdFwaasA/n4D0F4eYwMv4Or386CgkUL0nNOCl2WVAXMuB1rLAXO2FMJ3VTNYJxqDxlWwnp+fjz/+8Y9YsmQJXC4X/vznP+OCCy7A1q1bcd5550W9zags5ERjXv9gvTswdZyawMS6rCRKxUkiNGoVnv3qioS2zTTroNeo4PJKZ7mHYvFSANCqVThzWiY+qGjFvMD0+ql0rMvVLgCQFhKsR6uBAaQTGKtmZWNreSv+9MFJPPCF+QCAj0+24+G3jwGQpvPvuHgW7C4vfvmm9MakwGpAg82JW57ahYf+53Rcsbgo4r7rAnUvoWG/3OneaOuD2+uHLsonBQ7UdQEAdpxsTyhYdyQ5sd4VeK3VDcOCrUREFN3nP/95pef885//fMztBEGAz5f4J7YSNWfOHFxyySW45ZZb8MQTTwAAvvKVr+Cyyy4LW7h09uzZePDBB/GFL3wBvb292LhxI6688krk5+ejqqoK99xzD7KysvCFL3xhyPfxlK1bB5xzDoRNm+DYX47qXgv2T70IfblTYNAIEAD4vT5Ih9ePw/9tgKPXg5K5GSiZN/DJCSIionGjejvQfiyJGwhASi5QvEyaSA9Veg6w52nA1QNkz5Q62IlozBlXwfqsWbPCfghZsWIFamtr8ctf/jJmsP7ggw8O2IFJk48c/srBelVgoc3QgLg/eWIdANQqIWwiergIgoDCNKOyEGi84D9Zj39xMdp73UroHKyCSSwo9vr8aOp2AgCKQo5Fhjk4VR8rWAeAr62cjq3lrfjn7jp8+zMzkZWiwy/fCp7Zf3TrcZw5LROfVHWgpceFKRkmvH7bufjhi4fwwt56fO9fB7CsNEPZf1m03vfsFD0MWhWcHj8auvrCJuQBqf9crok5WDfwRLnfLyqfXEj0eHU5pNdabYdjwG5dIiIaGn6/P+rvR9Jf//pX3HrrrbjooosASJPxjzzySNg25eXlsNmk7z9qtRoHDx7E008/ja6uLuTn52P16tV45plnYLFYRnz/EzJjBvDggzADMB9qQ8p/6mD0ibBmG2Cy6lFf0SX3w6C3w4WDW+tQsbMZZ35uKuaeG3mSnIiIaPyKvqh3VOmlwDnfAUrOipxGzyoDsmYC3Q3AzDWcVicao8ZVsB7NmWeeib/85S8xrx+VhZxozEvtN7Eu13SU5cRemdgcEqwXphmhHaEFKAtCgvWh6lgHAJNOA1NG8P7MchWMO7GguKnbCZ9fhE6tQnZKsNM1tGM93gKvZ0zNwMLiNOyr7cJT26uwtDQdO6s6odeocMGcHLx2sAnffmavElzfvWY2zHoNHr5qAY639OJgvQ27qztjButFGcFgXRAEFKebUNHSi9pOR0Sw3tLjUj4VcKjBNmDw7fAEpxp7Xd6EgnJbnxsAYHf70OnwICPkOBER0cSVkZER970qIC1mKjMajXjzzTeHe7eGTcm8LKRmGdHT7oQl04Dje1qg0QjwekKCBhFw9nrw/jPH0HC8C0vXTGXvOhERjX8lide8ISUP+OwvgLILo1/fVgG0HJF62ivelBY9ZbhONOaMTDI4jPbu3Ru3b1Kv1yM1NTXsF1GwCkYKbStaegEAM3NjT4IZQ6pg4gXGQy108c+hqoKJRq66sSe4eKlcA5OfZoBKFQyV08OqYGL/kCwIAr62choA4OkdVfjZ60cBAF9eUYJfXb0Qs3ItaOt1w+nxY1lpOi6ZlwcAUKkELJ6SBgA4VB8+XW53eZXJ8MJ+/fTFcRYwrWoPLhzT4/Siuj1+XUtoXY7PL8LpGXgKUt4vQJpaJyKikeP3+7F582ZcdtllmDdvHubPn4+1a9fi6aefDgu1aWik55kxZW4m0vPMyJligTFVB5UGET95+L3AsY9b8Pwv92DnqydHZV+JiIiGTFYZoLcmtu2ym2KH6gDQWQ2IXqljvatG6lgnojFnVIP13t5e7Nu3D/v27QMAVFZWYt++faipqQEgTZt/+ctfVrb/zW9+gxdffBEVFRU4fPgw7r77bjz33HPYsGHDaOw+jWOhHetOjw/VgWB1Zm5iE+sjG6wHA+KhnFjvLyXJjvVolStAeLA+0HG68LQ8TMsyo9vpxdGmHph1anx91QwYtGo8esMiGLVqCALww0tPC5sIn1covVk52C9Yl/cp1aCJWIhWrqWJtoBpTb8gvf/99tf/GMmL38Yjd6wDQO0Y7Fl/7WAjdlZ1jPZuEBENOVEUsXbtWtx8882or6/H/PnzMXfuXFRXV2PdunVjs7d8AimZl4WV183CvPMKMX9lIUypkQuxO3s9+OSVKvzt/o9QfahtFPaSiIhoiCy8duBt1Dqgq06aSo8lvQSwlgCVtcA/jwB3/ga4+26gIs5tiGjEjWoVzK5du7B69Wrla7my5cYbb8SWLVvQ2NiohOwA4Ha7cccdd6C+vh5GoxFz587Fq6++is9+9rMjvu80voUG6ydb7fCLUhibbdHHvI0pNFiPM4k91EKDdctwTqwnG6x3Rg/WQytO4nWsA1JX/VfOm4a7nj8IAFh/7jTl9jNyLHjxm2ej1+XBguK0sNvNL5KC9cMN3fD7RWViXtmnKF35xUqwHhlqV3fYw74+1GDD5QsKYu53/6n+HpcX8ZY7FUURtrCJ9chwfzTVdjjwjb/uQY5Fj09+8JnR3h0ioiG1ZcsWvP/++3j33XfD3ncCwH/+8x98/vOfx9NPPx02zEFDq2RelrJQaWaBGdv+cQxilA/IdTY68NoTB7H0khIsu3TaCO8lERHREFjzENBZAxx7PfY25hygrVyaQo9V75JVBrScBjzwDCAAQA0gvAE89BCwaZO0eDgRjbpRDdZXrVoV9+O3W7ZsCfv6zjvvxJ133jnMe0WTgRKsO9yoaJH61WfmWuL2ZI9WFUxh2MR65JTXUEl28VJlYr3fIq4lmSbkWw0oSjcq9xnPFxYXYtOHlXB6fbj53Klh183Ki17NMyM7BXqNCr0uL6o7HJga6EyvC0yC9w/7AaA4sJ/RpsXl6pfp2WacaLVHVMz017+HvtcZ/5j1eXxw+4J1MWNtYv1ok/R3oK3XlfTCqqIo4pt/24NOuwdP3bQcOs24bxgjognm73//O+65556IUB0Azj//fNx1113461//ymB9hMw9twjt9XYc3FYfdX03v0fE7terkFOSqoTxJKlor8DmvZtRZatCqbUUNy26CWWZ7NslIhpzCpfEDtbNuYDWCPR1AQ17gbSS6OF6RQXw3Y2AKAa+X4Z801y/HjjnHGnxcCIaVUxAaFIKnVivaJb61cvi9KsDwcU9AaAkc3Qm1oezY12pgnH7EuqbjVUFY9CqsfV7q/DMV1Yk9Lh6jRqv3XYu3r19FVINiZ040KhVmJMvrZcQWttSJy9cmh4ZrE/JjN2xLgfrl50uTakfqu+Oewwc/YP1AU5GhParA2OvY/1Eq/R3wC9CWcQ1Ud19Xrx2sAk7TrZjF6tkiGgMOnDgAC655JKY169Zswb79+8fwT2i+auKUDwnHQaLNupPIz4vcOj9upHfsTHsyb1PYvajs/GL7b/As4efxS+2/wKzH52NLfu2jPauERFRfwULASHKz7al5wH/+yowPXCy/8C/gA9/E70SZvNmINbAkyBIU+tENOoYrNOkJAfr3U4vypulad2ynNj96gBg1AaD9YEqToZSvtUAvUYFrVpAmnE4J9al5+fziwmFq3WdcogdeSz0GnXYgqYD0apVSU86zw/0rIdOl8eqpwGA4sB+djk86O7XiS537F94Wi50ahVsfZ64dS29/atgBphY7x+sy8durDgRWLwXAPrciS1eKwudvt96rHXI9omIaKh0dHQgNzc35vW5ubno7OwcwT2i9Dwzzr16JlZ8bhqWXzoV5vTIKr6G4zZUH25HZ5M9yj1MLhXtFbj5lZvhF/3wib6w/65/eT2Odxwf7V0kIqJQZRcCy28Kvyx9KnDZr6Tp9OmfAQQVYMoAuuuiL0xaVSVNq0cjitL1RDTqGKzTpCQH6z6/iH21XQCkKph45FqT3FQ9jCF968PNoFXjiS8twWM3LEmoWmWwTCFVNwNNYPv9ojKxHm06fCTIwfrBupBgPUY9DSD9+WUG+ttDJ8a7HG50B4Lx6dkpSv1MvAVMHa4kJ9b73NI+BF439Z198PsH/lTASDnZFgwtHJ7kgnX5mAPA1vKWIdsnIqKh4vP5oNHE/v6pVqvh9SZWg0ZDJz3PjNPOKcSyS6di9Q2zoDOGv7dyO3x47fEDePWR/Tj8weSeXt+8dzMERB9YECBg0x5OLRIRjTlrHgIu/y0w61LgjK8DN/wzWPmSOQ0wZQLd9YCzO3qAXloaf2K9tHS49nxsqqiQFm+97jou4kpjyqh2rBONFoNWBZ1aBbfPj9YeFwBgZm78ifUZgYn2JSXpw75//a2aFW9pzKGhVgkwatXo8/jgcPmAOIejze6C2+uHSgDyrIZh37do5hZKVTCHGmwQRRFN3U4lZI/1Z1mUYUK73Y3ajj7MLZCCebkGJscinTCZV2jFwXobDtbbcOnp+VHvp3+Q3tNvAr4/eeHSWXkWHKizwe3zo7nHiXyrUbneYtAkNeU/VERRxPGwifXkwqXQ6ftjzb2o7+qL+okBIqLRIooi1q1bB70++gLlLpdrhPeI+iuZl4WzrpiOrX87FlYh6/eIsLU58cGz0kT23HOLRmkPR1eVrSpmRZ0IEVW2qpHdISIiSsySddKv/rLKgIxpQGcVYKsF9vwZ8PRJ3evppdL1N90kLVQajShKPeuTxZNPAjffLJ1QEEXpv1zElcYITqzTpCQIAlJDalVSDRpkW6L/wC2bmWvBf+86H7++ZuEw793oSXQBU7lyJTfVAK16dP4ZmZlrgU6jQo/Ti5oOB57aXg2vX8QZUzMwIyf6pw/kCp/QifWqQA1MaaA3X56EP9wQZ2K9X13KQIuXdvVJwXqGWa905stVM+8dbcHCH7+FP35wMu59DJcOuxu2vuCJgf7PbSB1/RZinchT6y09zoTWHyCiseXGG29ETk4OrFZr1F85OTlcuHQMmHtuEWYujz5I4PP48cGzxybt5HqqIyvqQq+ANLFeai0d0f0hIqIh0NcBuLqlhUVObgVevQN49bvAS98CKt4Gysqk4FilAtTq8P9u2jR5Fi6tqJBCdb8f8PnC/7t+PXCcdWgU209/+lOkpKTE/fXBBx+c0mNwYp0mLatRg7ZeeVrdAiHWx6xCTPRJ3BS9Gm29gD0wtVzT7sAnVR1Yu6AgrAM91sKlI0mrVmFOngX762z4uLIDf/tY6qW7+dxpMW8zJUPa39AFTGsCE+vy4qZKxUy9NAkf7XVhT7YKJjCxnmbSojjDiJoOB2o7HFg+NQPP7qqFKAI7TrTjayunx72f4XCiNby7NtlgXT7Jkm81oNHmxNbyVtxwRsmQ7d9Y8drBRnzjr3tw95rZ+Ooo/DkR0eA9+eSTo70LlKAL/3ce9KZylH/cBLcj/PuRzwNs/dsxNBzvwtI1U5GeN3ILyY+mziY7ZlWeBxGPSeF6v7clIkSsXzyJphaJiCaKzBlA5fuA6Ac8DumXUwB6moAPHpYm19etA845RwrSq6qk+pf16ydPqA4AmzdDFGIUosmLuD744EjvFYmi9OYsWe3HpTUF0kqkvwPJUmtjVyRF8bWvfQ1XX3113G0KCwuT348QDNZp0rKGTKyXDdCvPln0n1j/4UuH8P6xVrzzaTMeuX4RNIHpdGWR0FHqV5fNK7Rif50Nv3yzHN1OL0ozTbhgduzaHHkB09AFN6sDIXtJYJp9Zl4KtGoBXQ4P6jr7UBxloVr5xINaJcDnF9GTYMd6mlELjUoA0I7aTgfcXj8+qGgDADTZnAk+66F1orU37OtkFy+Vq2CuWz4Fv3r7GLYfb4PL64NeM3LrEIyEo43dAIAPKtqGJFj/9dvH8ObhJvzjK2cizaQ75fsjIpoozrtmFuavLMKhbXU4sLU+fFJbBI593IKORgfOXDsNJfOyRm0/h1Nnkx3d7U7UH+vEpx82QG/PxA3G7+Kv1ochiCH5ugrYtHYTZmRMooCFiGiiWHA9UPMR0HRAWsjU7wH8ghQcunql8DGrTArRJ3Fw3FN+HCa/iKg/XXIR19Hj80gngJLhaAdqP5FOImlNQPFyaa2BZJz7XUCT+M/PGRkZyMjISO4xksQqGJq0woL1nPj96pOFHKzLE9lymPjG4SZ895/74fOL8PtFlDf1ABj9CX55urwl0JO//pypcXvK5SqY0In16kAVjDyxrteolQVMD8VYwNThksLnnEB90EBVMLawiXW5jqYPu6o6lJMYTd2jFKy3hAfrSU+sBz69cNHcXGSl6GF3+7CrqnPI9m+s6Ass6nq0qfuU76u2w4Hf/6cCR5t68NHJjlO+PyKiiSY9z4xzr5mF0vnRf9hqr+3Fxy+dRGeTPer141Fnkx3Vh9pQfagN2/5Wjne3HMbeN2vgskvvE87suwQ/at2CC+zXYLFzJa7LXI/yDeVYt3Dd6O44ERENTs4sYOH10tRu3umANiXQIe6TFjT9+E9SNUzF26O9pyPuRGsvXj3QgFcPNGCXmBqrDW1yLuI6njltUqhuzg58QiN2/e5QYRUM0TAKDdZncmIdAJASEqz3OD1KYK1RCXhpXwPae92oarcrU8pyL/lomRcI1gHpz/PKJfEXNZND7brOPvj9IlQqQVm8NPS5zC9Mw6H6buyvs2HN/MgFTOUwPCdVqj9JtArGatIh1SAd49pOB/5zNNhHbuvzoM/tg1E3spPe/SfWHUksXtrj9Cj97EXpJqycmY3n9tRha3kLzp4xsaYI5WC9rdeN1h7XgGsyxPN/H5yEP/DusNPhHordIyKakM66Yga6WhzoauoLu1wUgdbaXrz5fwcxf2URRD8AlYDCsrRxUxEjT6U3nbChucqGnnYn/D4RPq8ffT0e+H2RMUK2rxCf67kZqdkGXHbVAqRnjI/nSkREMZScBdTvBuxtAFRA0z7A5wJs1dIvQS0F65c+DJRdONp7G+ZEa6+ydtne6k7YnB6smpWDVbNif4J8oPsqzjChpduJX7xZji6HB0adGmWLLsZ5Lz0ZrQ1t8i3iOpaotdL0eDLajwM7HgMcbUDGdGDFN5Kvg1FrB94mBKtgiIZRaP3CzFxOrAOhVTA+VLVJ3ySzUvTYuPY03Pr3vfjwuFRbYjFocOXiIlx6emToPJJm5lqgU6vg9vlxwxlTYNLF/yct32qAWiXA7fWjpccFq1GrnDwoyQxWviwstuLvnwD7aqNPXstT3XmpeuyHFDDHI4enaUatUp9T1+FAe6DjX9bU7cTUrJH9IVnuWE83adHp8MDpSXxiXZ5WTzdpkaLXYNUsOVhvxQ8uHZbdHTV9br/y+/KmnkEH6+29Ljyzq1b5usPOYJ2IKJb0PDM++7XT0XC8Cx31vaj+tAO25mDI3l7nwNa/HYNKJUClFpCSacDMpbmYsSRnTAfsnU12vLPlU3TU98LrCQboWr0KXo9fOlEQg86oxuKLpozp50dERAnKKgPO+pZU+1L+hhSsC2ppah2Q/murBw7+a1SD9dDge1qWGY++dxz/2l0HW58H3X0eyOeCX9nfgIevXphUuH6itRe/eqscB+ps8Pn9MGo1cHn9KEw3oNflQ96y+Xjqph9i3eYH4BcEqBBYB00UJ9cirmONICRVyQIAyD0NOOe2YMd6Vtnw7FuIkaiCYbBOk1ZqYGI91aA5penTiSRFL01L211enGyTJpmnZZlx2ekFytT6RXNzsWZePgza0e/Q1mlUuHJJIT4+2YF1Z5cOuL1GrUJhmrR46PGWXuXPPdWgCTvRsrA4HQBwsM4Gn1+Eul+9jDyhnptqAAD0DFQF0xdSBRPoeW8IdKqrVQKyUnRo7nah0dY3osG60+NDXaBvfl6hFR9UtCVVBVPXEd61f15ZNgQBqGjpRVuvC1kp0f9eHaq3oa6zD5fMyzvFZzByQk84HG3qxjllg5vIf2pHNZyeYGLSyWCdiCiu9DyzEiJPOdSGN//vMDzOkO9VIuD3ifD7RHQ1OrD7jWpU7mtF3gwrMgtSUDAGp9jLP2lGa01PRIDu84rQ6FTwuPxSG4AfUGkAlUoFtUZAVpEFiy6aMmG75YmIJqWsMumXKAJHXwV6GsKvF73AkX8Du7cAS9aN+O6daO3FT189gtpOB6xGDbw+UQrBo/SztNs9+O07x1CcYcL07MSGF2s7HNhfZ0OjrQ8+P6ASXEjRa1AEA+YXWnHV0mJg6Z3Yec2lmPnvZ5He0jA5F3GdKOTX+wTCYJ0mLbkKZmauRTrjScrEt93tRWWbNMksB72XzMvHJfNGd0I9mgevOD2p7RcUp6Gmw4EfvngQX18lLUJZ2i/MnpGTApNODbvbhxOtvRFVQXJdihysJ1oFk2bUIStFB6NWrVSLLC1Jh0YtoLnbNeILmFa3O+AXpRMLcv98/2Dd6fFBrRKgVUcuySGH8kVp0m2tJi0yTDq026W6lGjB+gcVrVi/ZRfcPj/e+s5546aGqS8sWO8Z1H043F48vaMKAHB6kRUH6mycWCciSkLJvCwsurAYe96qgdcVfazb5/GjtbYXrbW9ENSAyaJF4ax0FJSlo2DG8IXscrVLaqYh7mN0NNpxcm9LRKguqAFrjhE6gwZ2mwsarRpGixazzsiFJcMIywD3S0RE41zZhcDa3wHbfw9U/VcK1GWeXuCNu4HKD4FV3x/RYLK2w4GWHif0GhX21XYh1gecPUI9etVv4+2mFnzuz6X47eXfwQVlCwe8/+d21ypVs4BU92I1anBOWTbWzM9XAvrpF54BXHjGEDwjoqHFYJ0mrfPKslCSacLVS4tHe1fGjNDFS+WQd2r2xPoh7keXnYY91Z2oanfgRy8dBhBc1FSmVgmYX2jFx5Ud2FfTFRH+2l1yFUyCwXpfoArGpIUgCChKN6IisGjo+bNzUN4sBbUjvYCp3K8+LVs6kQCEB8hurx8XPLwNFoMGr992bsQJKLkKRp5YB4B0sxSsR+sO/+hkO255WgrVAeBAnS3pYL263Y5PKjtwxeKiiE8SDKc+d/jE+mD89aMadDk8KMk04brlU3Cg7iA6TrFj/d8HGvDLN8vxxJeWKovuEhFNZMsunYacklQcer8OHY0OqAQBvTZX1KBd9AH2Lg+OfdyCk3takVlswbLPlg75xPeJfS3473PH4XX5YLbqMe+8AqRkGMNC9s4mO+rKO3HgP7Xo6Qj/fi+ogJK5GTjrijL0tDshitLH3BmmExFNMmUXAumlwEsbgNpdAELDdQdw6J9A00Hg4p+MWDVMcYYJM3JS8F55a8xQvVf9Ntq1v4MUi4s43P0hLvzbX7D5c5uiLrJ9orUX/97fgBf31qMysOaZTAAwNSslLFQnGssYrNOkVZZrwbbvrR7t3RhTglUwvoiJ9Yki26LHk/+7DFc+th09gUA8tF9dtnBKmhSs13Xh6mXhJ1/s/SfWnV7lh+D+nB6fUv1hNUmfkijOMCnB+urZOegOdLSP9MT6icA+TM9OgTHwaYXQxUtbepxKeN7r8sJiCF8oRJ4sKAoN1gPPsdMe3ju/p6YT67fshNPjV3rxjzUnP/n9o5cOY9uxVuSkGrByZnZSt/33gQb89NUjePSGxVg0JT2p24aecDjW3Auvzw9NlCn+aI639OLht8rx+qEmAMAt505DdmCa/1SqYERRxK/fPoaqdgf+faABs/JmDfq+iIjGk5J5WSiZl4XOJjt62p3o6ehD+cfN6O10oa/HBa878vPpXo+ItpoefPjccZzY2wK/T0TeNCsElQCIQEFZGjqa7Di+swXWHCNmnZGXUKj90csnsO+tavgC3z77uj344NkKmKx6WLOMOGPtVDjtXux+vQrd7U64HV7pMRHcx5R0PeadVxRWe0NERJNUVhnwuUeAwy9IE+r1u6WJdVnbUVT89X+wWeVDlTkTpQuux02LbkJZ5vBMsU/PTsFFc/Pw3tGWqNd7hHopVBdEBL+3iRABrH95Pc6Zcg5mZAQrW0609uLGTZ+grqsv2t0hy6LHfWvnMlSncYPBOhEpgouXenEysKjl9Ak2sQ5I9T+P3LAYN23ZCZ9fRElm5HNcWJQGANhf2xVxnUOeWLdK4ajXL8Ll9UftnZf71dUqAZbA8S0OBNGFaUaU5aQgzyp9farB+u7qTpRmmpAZo9u8P3lifXqOGarASYHQKhh5Mh8A2nvdEcG6HLoXpQdPTKQHuur7T2J/75/7YXf7cPaMTHxmTi7uf+XTQVWqyPUzzYM4Vq8fakKDzYltx1qTDtad/Sb5q9odmJEz8Ju9x7Yex8NvHYPPL0IQgGuXFeOaZcU4UGcDEHmcklHR0qssPlvVb9KDiGgyCA2iC8rSlZD98PsNaK3vBfoNsas0AroaHehqlP7NLP+oGQCg0amgN2tgt7mV2xz5bwOmL8mBMUWHjgY7tEY1NFoVXA4v9CYNvB4fmk50o7PJEZqRAwB8HhF93W64ej3Y8eJJ2LtcsNtcUGmk77WiX4SgAnRGDXQGNU47q4C96UREFJRVBqy8U/q17efA+w8DPhcA4Em4cTOcEPyA2GOH8N+f46HtD2HT2ujT4afqRGsvntpeBW+0UnVI0+rypHp/oihg055NePAzDyqX/XlHVcxQHQAyzDqG6jSuMFgnIkVKIPitarOj1+WFSpCmqyeilTOz8ch1i/D6oSasibKI5oLiNABSn7bT41NCc7fXr1SZZKXoIS9I3uP0Rg3W5X51q1GrTLQvLc3AUzuq8YVFhRAEQamUOZUqmEP1Nlz5h+04Z0YW/nJzYt1zJ5STJyloDjx2aOVJrys4dd5ud0V00csT64VpwYn1DLMUrHeFTGL7/aLyCYhf/M8CNAZC8WODCNblTvKeAep3omnvld6Myic7kiGfcNCqBXh8Io42dScUrD+9vRo+v4hVs7Jx95o5Sl2LfJz6T/aH6rS7cbDehmWlGTDqIl9brx5oVH5f3W5P6vkQEU00/UP2Q9vqcOSjJvi8fqhVAlIyDBEVLDKv2w+vO/xEp6Pbg4Pv1Se/I4JU7aLVq+H3i/B5fPD7/NLXXj+ypqQge4oFrbW9UKsFWLONmL4kJ/nHISKiyWHl94GUXOCT/0NF8wHcDCf8YR+UFgFRjDodPhRqO6ST0QVpBhxrifyZwyu0IFqoDkifsN128jBOtPYqYfmu6o64j3dJlJ/NicYyButEpDAH6kDkSeaidBP0mshAb6JYMz8fa+ZHX5A132pAjkWPlh4XDtXbsLQ0A0B4VUqKXoMUnQY9Li96nB5kWyInxbsCE8lpxuC092Wn52NmrkX5NEC+NRCsn8LEulyrsq+2K2YtTShRFIMT69kp6A6EzaET6z3O4HNt6+0XOLi9Ssgd2rGeFmVivavPA3/gvVa2RQ+LQXqdNXU7YXN4lIqcgfj8IroC+9njTD4cbw88B5sj+dvKVTCn5adif50N5U09uGyAdXNFUUS7XQrzH/jC/PATEIHj1OvywuX1Rf17tvGVw3hpXwMyzDp8eUUJvryiVAnkAeC1g6HBOifWiYhk6XlmnHvNLEyZm4nWmh5kT7EgNcuIl36zF17X8CwaLaiB7CkW5JamoqvZAXefDynpesxakY+KT5rQ2+mCVq/G6auLwmps2KNOREQDWrIOKDkbmzedB6Ev+nCSgMjp8KFQnGFCaaYZFoMWTo8fNZ3h0+YaMQexJtYBoKrJjD+9fxK3nDcNAHCiuTfqdgDwmTk5uPWCmUO160QjgsE6ESnkKhg5BJ1o/erJEAQBC4rT8PanzdhX26UE6/JCpXqNChq1CikGKViPtYCpHASHhseCIIQtNCl3tbf2uuDx+aFNsLs7VHO3S9m/lh6Xcp+xvHOkBQ63DxqVgJJME8oD0+PhE+vB59TeL1ivD7yhshg0sIacNMgwS7/vCgmv5UnxNJMWWrUKWrUKhWlG1Hf14WhTN86YlpnQc+x0uCEGXpuhoX+i2gMnAgYzse4MHJdFU9Kxv86GI40DT9t3O73wBD4ymRkSiAPScVOrBPj8IjrtHuRZI4P1fYEaog67G795pwJ/fP8knly3DGdMy0RFcw8qWnqVCXpbnwddDrdyYoOIiIJd7LLCWWk49nH0jljI33oj10CNTwCyCs2Yt7IQc88tAoCI0Dwt2xgRorNPnYiIkpJVhqqMEogNTVGvFiGiylY15A87PTsFt5w3DXWdfRBFEY++dxyfNtjgF0W4vSJSfBeiW/OclKuHznaJ0v+p+s7HseYe1HX24b0jzejzRgbwc/JS8OWzSnHd8pIh33+i4cZgnYgUchWMbDIH6wCwMBCs7w/0YQPBiW75JITFoEGjTVrANBp5Ojp0Yr2/TLNOCUhbe1woCJlsTlRzSI3MiZbemMG6KIp4bOsJ/PKtcgDAxXPzoFWrYApUjTg8wedhd4VOrLvC7ie4cGl4VZAysR5SBSNPu4dOW8/Os6C+qw/HmnsSD9ZD7jPZiXWfX0SnY/DBujyxvjBQEVTe3D3gbeRjkKLXRNQEqVQC0k1atPW60WF3I88a/ufl9vqVj13ev3Yu/rGzFkcau3HbP/bh9dvOxauBafVzy7JxuMGG5m4XqtodWMhgnYgopqVrpqKj0YHutj5o9WpkF6fA4/Ijs8CMjAIzOhrtEEWg7mgnetqdEEU//H5In7JHYB6vX/CenmfCRTfPCwvJ+4fmDNGJiGgolOYtgNDwCaJNhwsQUGotHZbHnZ6dolS5FGeYsLNKqnN559NmvHMEyPTchnbtbwExPFnP9NwGjViAPTVduHHzJ9HvO8uE17+9clj2m4aWKEb/VMJElejzZbBORAqTPjz8mzYBFy5Nhhyi7qvtVC6Tp7jNgWMln4yI1fnd1ReogokTeKpUAnIsBtR39aHR5hxUsN7SExKst9lx1ozIRdB8fhG3/WMv/h3o5r7+jCnYePlcAFA6vGNVwbT3D9a7IvvVgWDFSWdIFYwcMGeZg1U5M/MsePdoS1ILmLaHBOuxPiEQS+i0e1eSwbrH54c38DEO+TVR29GHHqcnYkHXsP0NHLPMlOh/9hlmHdp63WHHSlbT4YBfBEw6Nb68ogRXLS3CZb//ECdb7bjzuQNKp/pn5+ej1+VFc7cL1e12Zf+IiChSep4ZF900d8AKls4mOxqOd0lBuiiir8cDo0WLvm4PjuxoRE+HU+pR12lQtjSXoTkREY2Im866Aw/t/T8gSuAnQsT6xeuHfR9CQ/ZlpRmw9blR3nQxLL658Oj/Azea4HJmIsV3EbRiQdz7UgvAvYGfR2ns0mqln3kdDgeMxuSzivHK4ZAG3eTnHwuDdSJScGI93PwiKwApRG3vdSEzRQ+HKzCxHuijTwkEq7Em1kMXL40n3yoF682DXMBUroIBpIn1aN441IR/H2iEVi1g49q5uOGM4Eft5In1WFUwbfbw8LeuU/omU5Qe/o013RwZrMs946EB8+xAFU55EsF6R9jEeuxgvaXbicMN3ThvZjbUKmlqIrTKpv/EuiiKaLA5UWA1RO2ml6fVASA/zYC8VAOaup041tyDJSUZMfdDntTvXwMjS48y3S+TF3udmmWGIAgw6TT43bWLcMVj2/H2p80ApIVULzwtF59UtuOTyg5UtbFnnYhoIIlMj8fbJrvEgl1vVMPr9MGaY8QMLjxKREQjpCyzDJvWbsL6l9dDgAARovLfTWs3DfnCpQOZnp2Cn125IFATsxiC8Dk0dDnwp/crUd1uh2+A269dWIBVs/h9dKxTq9VIS0tDS4tUp2cymQZc0208E0URDocDLS0tSEtLg1odf91BButEpDD3C9anBc5ET1apBi2mZ5txotWOA3U2rJ6dA3tg8VI5iLYEjtlAHetpAyzQmRuoAmmMsYDpkcZulGSaYNJF/2c7rAqmNXqw/tSOKgDA11ZODwvVgeDzCZ1Y740zsV6vVMH0C9YDz7PTHgyvlYA5JFiXO+bLm3sSWmwVCJ9Y744SrNv6PHh82wk8+d9KOD1+/O66RVi7oCBi/20OT9hjPrW9Chtf+RQPXjEf1y2fEnG/cr+6SgB0ahVm51vQ1O3E0ab4wXrwhELkorZAsBonWrBeFRKsy+YVWnHXmtn4f//+FABwzowsWI1alGRK28hT7ERENHxK5mUhNSuyM52IiGgkrFu4DudMOQeb9mxCla0KpdZSrF+8fsRDdVnoBDsg/Sy6v9YGg1aFI409MZY0lRYq/fU1i0ZmJ+mU5eXlAYASrk8GaWlpyvOOh8E6ESlMIT3Qeo0K+QMsgDkZzCu04kSrHeXNPVKwrlTBBCbW5SqYGJ3fiXSsA1COdbSJ9Y9PtuOaP36Ezy0swG+vjXzzIYoiWkIm1k+2RgasRxq78UllB9QqISJUBwBjILAPnViXTyIAkYuX1sUI1uWwuNflhdvrh06jClaihFTBTMtKgUYloMfpTbj+pqM3dsf6u0eacfuz+8Om0Y+HTO6HTty7fX44PX6l/uZgvdSX/vanzVGDdXli3ahVKwvPbi1vxacN8XvW5WOWFaMKJj1OsH4ySrAOAP97dim2n2jHO0eacdXSYgBAqRysd3BinYhoJLAznYiIRtOMjBl48DMPjvZuRBW62Ol7R5uxZXt12PVGjYAfrZ3LhUrHGUEQkJ+fj5ycHHg8ya9ZNt5otdoBJ9VlDNaJSKFSCTDr1LC7fZiaZYZKNXE/3pMouUO8MdApbneHV8FYDOEd6zaHB//aU4erlxbBYtAqHevpMepAZHlxJtYPBBZPff1QEx5weSMqe7ocHrh9wdXU6rv64HB7w6bbn94hvaG5ZG5exEKZQPCkitvnh9fnh0atCu9Y7xf+1ndFX7w01aCFSgD8ItDlcCMn1RA1YNZpVJiWbcax5l6UN/UkFKyH1sv0r955akc1bH0ezMhJQWmmCe8caUGTrS+4//0m7m19HiVY7whMlu+u7oTfL0a87pVgPbD9okCPubxoTyzRTiiEitZHL6tsk04K9A/WBUHA419cjJNtdszMlab+SzKlPwNOrBMRERER0WiTp9hXzsxGhlmH3/+nAj6ftE7Z769fzPqXcUytViccOE8WqtHeASIaW+RJ7Mnery6TA9/6LinwjphYDwTrctD76Nbj+PG/P8XDbx0DkHjHuhx2N0cJ1uWw3e314/1jrRHXNwcWLs0w65SJ8dCpdZvDgxf31gMAvrwi+mSAHBoDwSA5tN6m0+GGNxDeOz0+tPZIoXH/xUtVKkFZqLUjEBjHqkSZlZcKQKqDSUR7nI71rsBj3b1mNi6eK31cK/QkRf+Je/mEBxCcGLf1eXA8So2OPMVvCJx8OGNqJgQBONbcqxyHaOQp+XiLl4Y+fqjKGBPrAKBRq5RQHQgG62297pifnCAiIiIiIhppt14wE3/68jLcftFMhuo0ITFYJ6IwKQzWwxSkyZPk0vSzQwnWpZA1pV/H+v7aLgBSrYgoikqwLofNseQFqmAau/sirmsKueytw00R18sLl+ZY9JgW+HML7Vn/5+5a9Hl8mJ1nwfKp0TvB9RoV5EFtOUgOnQoXxWBQLi9cmqLXRO2O79+z3h5jEc9ZuVIXX6ILmMqT5YAU/ntCpvSDx1mLfKsU9ofW6rTb+02sOzwh1wWD7WhT6KFVMID06YM5gZMCO062x9xfeWI9I8anFTKiLPQKSCdv5D/TRP4eWgxa5dMA1e2sgyEiIiIiorFj1awcbDi/jKE6TUgM1okoDCfWw8khrTz93OsKVMHow6tgep1eiKKII41S73Z9Vx+ONfcqnd8DdawHJ9ZdEMXwJV5CJ6/fPdoSFigDwQA5N9WgLBwjT6z7/aJSA3PjWaUxFwkVBEGpjpEXMO2/IKsckNd2SEF/cUb01cDT+1WctMmVKP0mt+WJ9aMJBuv9p85Dg395Yt1q1EWt1WmLmFgPBuuhE+O7qjojHtfZrwoGAM6angkA2HEiXrAuV+BEr4KR64H6P6+qQKVLukk74AkZ2ZQMuQ6GwToRERERERHRSGCwTkRhrlxciLkFqTybHCBXwXTY3ehz++AILOhp1skT61Jg3uPyosHmRHdI2PvW4SYlnI422R0qxyKFwW6fP6IapCkQEAuCVIHy8cnwqeoWJVjXY3pO+MT6+xWtqOlwINWgwecWFsTdBzk4HjBYD0ysF6dH70UPXZTT7fUrx6R/1/jsPKnO5ERLr1IzE0//4yLvn88vKo+RZtIqwXqP06ts0/+28gkPp8enPF8A2FUdZWLdLe2bIWRx3xVKsN4Wc3/bB6qCidGxHq8GJhZ5AdMq9qwTERERERERjQgG60QUZt3ZU/Hqreci2xJ9ynaySTVolBC90danLF4qT3fLHes9Ti+ONHSH3faFQK+5IEh1HfHoNCplsrkppMLE6/OjJdDjvWpmNgDgrU/D62Dk2pDQifUTgYn1v39SAwC4cklR2GKm0ZgCz7PPI4XRcigtvxbkOpWawFR0cYap/10ACFbBdDncSmisVgkRPfOFaUaYdGq4ff6o3eahRFFU7kuurOkO9Il3h0yfW41apOg1yicJ5JMSci2L3AkvV8HI4bdGJUAlSNP4Tf167vtXwQDA8qkZUKsEVLU7lIVcQ3l9fmV/Yy1emm4OVuaEfkqhslUO1lNiHY4IJYFgvYYT60REREREREQjgsE6EVEcgiAgPxDGNnQ5lcVLU/pXwbg8Sg3M8lKpx/xkYPI41aCFWhW9giVUnjUQrPerMPH5RahVAq4/Q1p49K3DzWFBbEtg8dKcsCqYXjTZnHjnSAsA4PrlUwZ8fDk4drh9EEVRqVopDVkcE0hmYt2j1MBkmHVQ9TsGKpWgdL6/tK8h7r71uLzw+KTnLNfzyAuYyrUuKXoNtGrp25rcWS/X5MjT9tOypQBanljv6A1Olc/Jl6pp+k+tRwvWLQYt5hdaAUSvg+l0eCCK0kmV9BifVpADd7fPr5ywAYDKwNS5vK+JKM2S/ow4sU5EREREREQ0MhisExENID9QLdJg61OCdVNg8VKLPtixfqRJCtYvmJOj1JwAA9fAyPJSpcA4dGJd/n2uRY9zy7Jg0qnR1O3EwXqbsk3o4qVF6Ubo1Cq4vH789t1j8PlFLCtNR1muBQMxhVTBuLx+eP1SkC3XjMhT33LH+pTM6BPrcsVJl8Mdc+FS2bXLigEA/9xVF9EdH0oOwE06NbICE/RysN6p9KsHj3Noz7rT40NP4M9NPvEgB+vyFH6GWY9lgRMi/XvWne7IjnUg2LO+PUodjFw9k27SQaOO/q3WqFPDoJWu6wypqpGrYOTjngh5Yj20Y73H6Ym1ORERERERERGdIgbrREQDkOtDGrucsMsd6/rwKphelxdHGqVFOOfkp+L82cGO+oEWLpVFm1hvsvUFrjPAoFVj1axAHczhZmWblpDFSzVqlTK9/MzOWgDAdQlMqwPBeps+ty+sX11eGLOtV1pYtbZDnliPVQUTmFh3uJXgOtYCnhfMyUVWih5tvS68e6Q56jZAsLIlw6xDasinBIBgrYtcrQIET4Y02fqUkFurFlAUmLKXp9yDC4zqsLQ0HUDsifXQjnUg2LP+0Yn2iAVn5ZMQsU4oyOSTEO1RgvXkOtalP4umbid6nB5899n9mL/xLbx2sDHh+yAiIiIiIiKixDFYJyIagFw90tDVB4dLClnNcsd6IGD3+EQlEO0frFtN8cPV/o/TGBKsy7+Xr7vwtFwAwNZjUsWL3y8qHey5qVJ4LU9l+0WpI/6z8/MTenxDSBWMXANj1qmDHeu9btj6PMr0d1GsYD0QJnfaQybWYyzgqVWrcPXSIgDA3z6pjblvcjieadYp9TvBKhjpujRj8DHyQo6lvA8ZZh3SAn8WShVMSGC/tESaWP+0oTvsxEK0KhgAWFqSAa1aQIPNGTYpDgBtAyxcKgs9VvJ/uwInCuQTJIlIM+mUif3r//QxnttTBwD46GRkTQ0RERERjQ3vvPMO/vCHP+D5559HW1vkpyCJiGhsY7BORDSA/LRgFYwcuMq1KeZ+C4JmpeiRbdFj0ZR0pQIm0Yl1eTHQqrZgT7Y8vZ4b6Aw/c5o0JX2ksQd2lxcdDje8fhGCEJwKD+3mvmJxUcSkdSzBKhiv8jxTDBpkBu63ze5GTWBaPduij6hGkcmd4p0Oj9LLnhFncvvaZdJE/QcVrco0fH9y8Jxu1sGil+5fCdYDQbQ1pHJH7lhvsjnRZpenx/VK+GwL1MeETsLnWQ0oSjfCLwJ7a4J1MH1KFUz4t0yjTo1FU6Qp9+39etaVifUYk/qyDKWPXtoPuV89L9Uw4GKz/clT66E1QfWdkQurEhEREdHo+9e//oUPP/wQzc3NOHDgAB555BE89thj2L1792jvGhERJYjBOhHRAJQqGJsTjkDIKk+qq1SC8nsAmJMvdZmrVQJWzZRqW+KFyqFmBXrQy5t7lGqR4MS6IfBfIwrTjPD5Reyr7VIW58w065WFO+WJdSDxGhggGKyHVsGk6DXK1HV7r0vpV4+1cCnQf2I9fhUMIHW1n1uWBVEM1tf0FxqAy/U73YEOcTlYDz2BoVTBdDvDFiiVT3YEJ9bDK1vknvU91V3KfTljTKwDwIrAiY6dVeH1MUrFzEBVMPKxCgT9la3J18DISgO3sRg02LB6BgCgvovBOhEREdFY0dbWhpdffhmPPvooDh06FHF9S0sLXnnlFYbrRETjBIN1IqIBKIuXdvUpHevy4qUAlGoSQKqBkX3nwpm47PR8fPHMxMLtqVlmaFQCepxeJVCXJ9blxTgBYElJoAu8qhMt3eE1MACwfGoG9BoVLpidg1l5Ay9aKpMn0B2eYBVMil6DLHOwCqa2M9CvnhG7pkTuDe9xeZXFVwfqGpen1p/dVQtvlEVMQwNw+XjL+yiH5KGLxOZZgxProT3vysR6RBWM9BxLAlPfLT3BOp5YHesAlEVqK0M+ZQAEF0UdaGJd6aOXJ9blfvXs5IP1W86dhisWFeLZr67A5xYWADj1iXVRFHG0qRsury/scr9fxHvlLWGLrhIRERFRbG1tbXj22WexZ88etLa2xt32jTfeGKG9IiKiU8FgnYhoAHK/ucPtg7xGZeiUerSJdQAoyTTjkesXY0ZOYuG2TqNSalzKm6SFUBu7+wL7EAzWQxfZbO4Or4oBpO7zXT/8DB774uLEnmBA1Il1gwZZFin87fP4lP2aEidYTzVqIQjS708GJrAHCpgvPC0XmWYdWnpc2BGlF7w9JAC3GPpXwUR2rMvHq93uRkNXMNwPDdb9fjFsEh4AUgP33e0M6VhXqmAig/UpgSC+pl+FTdsA3fKyWFUw0wYxsT6v0IpfXbMQc/JTURj4REGPy6ucRBiMtz5txiW/+QA/e/1o2OVvH2nG/z65ExtfOTzo+yYiIiKaTA4fPozOzs6BNwTg8Qz+/RsREY0cButERAMw6tRhdS6CEF4LkhJjYn0wZobUwfj9Ippt0uRztIn1vTVdaFA62MODa4tBC70msW51mdzp7XB7lQVKU/QamHQa5fnK3ePFMRYuBaQaHLmWRa4iGShg1mlUWDVLWvC1f185EOxYD1+8NFAF0xfZsW41aqHXSN/iPm3oBgBkpASDdb8I9Lq9wUVRA/uXGri+OySMjrV4KRA8wdBhdyv7A4R0rA8wqZ8eEqx7fH7sCDz32Xmn9joy6TRK1/2pTK0fC5xI+aQyvOpmb00XAKCqPXonPhEREREFVVRU4L///S88Hg8y2ttxwTvv4MrnnsMF77yDjPbI974pKSlR7oWIiMaa5FZGIyKapPKtBiWENes0EOSRbAQn1nVqVVi/+WDMzrPg3wcacaypBx0ON9w+PwQByLEYQrZJRYpeg16XFx9USB8jDb1+sOTg2OH2wa4E61I4m5miQ11nnxKkFmXE7lgHpIqTTkcwaJbrZOI5a3omnttTFzVY7whZvFSuium/eGlox7ogCMi3GlDV7sCnjd3KPhi0aug1Kri8ftgcHqV/PTixHt7fDsTvWLcYtMgw69ARWNh1boEVQHDCfsDFS03BjvVt5a3osLuRlaLHmdMy4t4uEYXpRnQ6PKjv6sNpBYML6jsCnwaoaOmF1+eHJtDjf6xZCtzlTwsQERERkaSivQKb925Gla0KpdZS3LToJuzcuRNutxsL9+7F2ldeCdv+7O3b8fLatdi3cKFy2bp160Z2p4mIaFA4sU5ElAC5DgYIVqbI5AnqGTkpygKigyVPrB9t6lH61bNS9NBpgverVglYNCUNQHByOLQKZrDCqmCUjnXpsv4BcbwqGCA4iS0baGIdAFZMlxYCPVjXFRZsA+GLl8pVMHJdjVIFYwp/DHnKX95O3ge5i72lx6VM5suT5fEm1g1RqmCA4LGoDamDkRcvHWhiPbQK5oW99QCAzy8sUALsUyEvulvfOfipcvmkhdvrR3XI85MrgTrYsU5EREQEAHjzzTdx0+9uwqxHZuGh/z6EZw89i19s/wVmPzobL1W/hIz2dqx95RWoRDHslyCKWPvyy8jokD4hePnllyMrK2uUnw0RESWCwToRUQIK0oLBtVkf/mEfeWL9VGtgACiLjR5v7UVdIBAN7VeXyXUwsv5VMIMhd4j3ecI71gEgKyQg1qiEsBMN0aSHhNwGrSriZEQ0BWlGlGaa4BeBT06GV490RK2CCQTrgRA8PaQKBkDEPsonB+Q6mKrAQqFqlaB0q8ftWI8ysQ4Eg/XqwDS/M+T4DTixHjiuTTYn3j7SDAD4wuLCuLdJVGGatF9yXdBghAbncpje4/QoFT89Ti88URabJSIiIppM3nrrLfx7x7+xpWMLRIjwB/7nE33wi3780/VPZB/dHvW28udgV588iRtuuAFLliwZuR0nIqJTwmCdiCgBBWnBkNasDw9Yl5ZmQCUAn5mTc8qPU5xuglGrhtvrx0eBcDkvyjT60pLwqpChmViXO9Z9SmgtV8FkhQTEBWlGqFVC5B2ECA25M836sOqceFZMl6ZzQhcwdXp8cATC7YwUnRL2dzulBUhtUTrWgchjIk+Py8H6ybZe6T7NOqgCzyfVGLjvvtAqGCk4jhWsl/RbwFSerteqBaVaJpZ0s7QvdrcPbq8fs/MsOG0ITtAAwZNBp9Kx3umIDNaPNfeGbdPl4OJaRERENLlVVlZiL/bG3ebdrJqY1wmCgPkWC8rKyoZ614iIaBgxWCciSkDo1LgcQMuuXlqMT//fJVgzP/+UH0elEjAzV+ppf/9Ya8RjyxZOSUNotp0zBBProVUwwY51uQomOIE+UA0MgLDFXhOpgZGdFaiDCe1Z7wgJqi16jTKx3uvywtbngShK21mN/SfW+wXrKXKwLv33ZKs0sR5a1yJXwbi8fqVbXVm8NMbUfXFGv2BdWbh04BMK6f3qa65YXJjwSYiBFKVLJ4PqugYfrEebWJf71WWd7FknIiKiSS47Oxs22OJuU5UW+zpBEIDS0iHdJyIiGn4M1omIEhA6sZ6ij5xCNsSYZh4MuWf9ZKCqJC9K7UqKXqNUz6hVAjITWBx0IHJw7PB4I6pgQitNigdYuBQI7zsfqGc81JnTpGD9SGO3Eup2hPSrC0KwtkUUgQabFBqbdGroNeF/BnkhwbpRq1ZOiMgBfGXg+IaeBEjRaSDn2vLU/kBVMCX9g3Vl4dKBn7dWrVJOFKgE4HMLh6YGBghWwZzSxHpIsC4H6nLAHm0bIiIiosnovPPOQ64hN+42QuoUAIDY73IRkN7Yrl8/LPtGRETDh8E6EVECQoP1RPrCT4Xcsy6LNrEOAEsDPevZKfoBq1kSETqx3uPqXwUTDImL0hOZWA+pghmgZzxUtkWvTOx/FKiDkYNqebpbr1FBq5aeb22HFBqn9ZtWB8KPW2jILS9eGi1YV6mkqXhAqpoRRTG4eGmsjvXMYIDt9fmDC5cm+LzlEw9nz8gakkofWWFgYr2t16VM3yfD5fXB7g7erqrdDqfHFxmsc2KdiIiIJrmsrCw88D8PSIXpUZNzYI7pbLxx1VUQBQF+lQp+lQqiWg1BpQI2bQJmzBjp3SYiolPEYJ2IKAG5Fr1SvWLWxe/NPlX9g/W8GMH68qnSdLccoJ4qkzbYsd7rlHqz5en80In4RKpgQitOkqmCAYCz5J71QB1Mh90Vdj+CICj7JS/wajVFPkZeWLAe3H9rSN0LEDlRL9fBdPd5lG2A2FUwuRYDdBoVvH4RRxp7lCqYrAQn9eUqmf9ZUpTQ9olKN2mVKfuGQdTByN3papWAdJMWfhE43tKrTK7nWKRj2tmvY10URYhi/58oiYiIiCa2M2acgd+e/1sIgoCw/wkCvpL3Fdx42Y1Y/uijqH37bTg3bIDq6qshfO97QHk5sG7daO8+ERENwvCmQ0REE4RGrUKOxYCmbifMUapghtKs3MQm1i+em4vvXTwL55ZlDcnjysFxn8cXrIIJPNcsSzAkLk4kWA8JlbOSrKlZMT0TW7ZXYfuJNgBQJsAzQu7HYtCi0+FBbaB+JdrEepZZD41KgNcvhoXc/bvYM/rtn1Q104dup1epgQEAgyb6uWiVSsD5s3LwxuEm3PfyISyaIn2SINETCj/+3DwcrLfhstNPvaM/lCAIKEw34nhLL+q7+jAtOyWp23conxTQYkZOCj462YH/Hm9Du90NQQCWTc3Aqwcaw3rY6zod+OxvP8C1y6fgns/OGdLnQ0RERDTWfevcb2GOeQ5++8Fv0eppRVFKEe78zJ1YPmO5sk3WBRcAF1wwintJRERDhcE6EVGCCtLkYH14q2CyLXqkm7TKJHCsehCNWoVvrh66j4zKVTCiGAyzlY71kPC5OIEJ+VOZWD9zaiYEATjRakdVm12pGgmdLJd7yesC/eFyvUsolUpAbqoB9V19UatgZBkp/SfWA1UwfR6lBkanVkGjjv0hrx9dfho+PN6GPTVdON7SK+1vglUwpVlmlGaZE9o2WYVpgWB9ED3rnSEVPLPzUvHRyQ68cqABgNQrXxA44dMVUgWz40Q7up1ePL2jCt/+TFnEQr9EREREE91nFn8GC6csRFdXF9LS0pCVNTRDMERENPawCoaIKEFyt7i8eOZwEQRBWcA0w6wb0oVR4wldnNPrl6o8lIn1FB0+v7AAVy8tCuskjyXdNLiOdQCwmrRYEpj6vvqJHfiksgNAeBe6HKzXBqpgogXrQLAOJnQqPbXfxHpEFUzgz7fb6QnpV4//7bIgzYjvXzIrcDtvxP6OFrkmqH4QVTAdjmCwLr8eD9V3A5AW2JU/ldBhD1bBtPRINThOjx/vHW0d/I4TERERjWNZWVmYMWMGQ3UiogmOwToRUYK+ct40XLusGGsXFgz7Y8k960O5mOVAVCohIkCWA2xBEPCbaxfhof9ZAEEYeKFUq1ELebP+wXUifnX1QpTlpKClx4WdVZ0Awutl5EVVlcVLo3SsA8Hp+tA6nf61Mf0D8GDHerAKJla/eqgbzijBstJ05eusJCf1h0Nh2uCDdWVi3ayN6P2flWdBRuCYh06sN9mcyu9fO9SY9GMSERERERERjRcM1omIEjSv0IqfXXn6iITd8wqsAKTKjZEUWt2hVgnQx+gVH4hGrcK8AitSDRqUZCb/HKZkmvD8N87CZ+bkKJeF9qSnBgJ/eaI8Wsc6ANx6QRluu6AMn19UqFzWv2M93sS6M3D/xgQ+NaBSCfjZladDFzhm+dahWVT2VBTJE+uDqIKRJ9EzzDrMzA3vZ5+VZ1FOZnSEBOvN3cFg/b2jLWEd9UREREREREQTCctPiYjGoLULC9Dt9OAzc3JH9HFDA+QUvSah6fRY/vm1FXB5/bAMsjrHYtDij19aise2HsfOqk6cHbJIqzxJL4tVBTMtOwXfuXBm2GWRi5cO3LGeaB3P9OwUbL5xGU629WJOfmpCtxlOpzSxHlIFYzFoUZhmVO5nVq5FWQOgyxGsgmkOVMEAgMPtw7ZjrbhkXh4A4ERrL3JTDUq9EBEREREREdF4xol1IqIxyKBV4+Zzpw3bopaxmHThwfqpMGjVESF2slQqARvOL8NTNy0P67bvH9ZbjYnXroTuk0qIrJEJTqwnVwUjO6csC19eUZrw9sNJ7lhvsjnhC/TmJ0oO1uUTD3IdjFYtoDTLrPTod9hDJtYDVTDLp2YAAF4P1MH845MaXPDwNmz4257BPhUiIiIiIiKiMYXBOhERKUKD9f5T4WNJSoIT69Fo1CrlpEG6SQe1KnwqP9ixHpxYT6QKZizKsRigUQnw+sWwmpb+DjfYcPuz+3C4waZcJgfm6abwYH16dgq0apXSeW/r88Dr88PnF9HaK02s33R2KQDg3SMteP1gI37w4iEAwMlW+9A+QaJx4IEHHsBZZ50Fk8mEtLS0hG4jiiI2btyIgoICGI1GrFq1CocPHx7eHSUiIiIioqQwWCciIkVo5Yl5DFd2JFoFE4s8td6/BgYI9rcn27E+FqlVAvICC7fGqoN572gLrnp8B57fU4//+6BSuVypgjFLx2r1LKnvfvVs6b+hvfa2Pg/ae13w+UWoBOCCObkosBrQ6/LiG3/bo0zL213eIX6GRGOf2+3GVVddha9//esJ3+ahhx7Cr371KzzyyCPYuXMn8vLycOGFF6Knp2cY95SIiIiIiJLBYJ2IiBRDWQUznPpXwaQlUQUDDBCsh06sB6pgDElUwYw1Ss96lAVM/7yjCuuf2glH4HlWtgUnyjsDi5fKE+vLp2Zg1w8/g+8GOus1apVyEqLT4UZztzStnm3RQ6tW4ZJ5+QAAUQTmFkh983Y3g3WafO6//3585zvfwfz58xPaXhRF/OY3v8EPfvADXHHFFZg3bx6eeuopOBwO/O1vfxvmvSUiIiIiokQxWCciIoVJFwzT+9etjCVDNbGemRJtYj2kY93jBzB+J9aBYM96/4n11w424t6XDsMvAmfPyAQAVLcHg3W5Cib05ENWih4adfCtg1wH0+nwKFUzuanShPyVSwqhVgk4vciKx7+4BADg9Pjh9fmH9PkRTTSVlZVoamrCRRddpFym1+uxcuVKbN++fRT3jIiIiIiIQo3d1ISIiEZc6CKdlrE8sR6yb3qNKqzCJhFyEB99Yj1QBTMBOtYBYGqmtADuiZbesMvfPdICALhmaTF+dPlpmHvfm+h0eGBzeKDXqpTnnh7lGMnSTTpUtzvQYXejtUeaWJeD9bkFVvz3++cjM0UHvxhcONXh8SFVzfP6RLE0NTUBAHJzc8Muz83NRXV1dczbuVwuuFwu5evu7u7h2UEiIiIiIgLAiXUiIgoRWgUztjvWgxPqyU6rA9LkNQDkWgwR18lVMC6vH7ZAz7hxHFfBzM6XaliONIV3Mx9tkkK31bNzYNZrkGORjkl1h13pV9eohLgnWNIDx77L4UaLMrGuV67PsxqgVaug16ihVUuLxLJnnSaCjRs3QhCEuL927dp1So8hCOELK4uiGHFZqAcffBBWq1X5VVxcfEqPT0RERERE8Y3d1ISIiEaccdx0rAf3Te4AT8b6c6bCoFXhmmWRwVOKTgNBkLrBWwJT2MlOxI8ls/MsAIDjLT1we/3QaVTw+vyoaJYm2E8LBO+lmWa09LhQ1e6AWiWFd+lmXdwgT55m77B70CQH61FOVgDSiZouh4fBOk0IGzZswLXXXht3m9LS0kHdd15eHgBpcj0/P1+5vKWlJWKKPdTdd9+N22+/Xfm6u7ub4ToRERER0TAau6kJERGNOJM2+G2hf4/5WBK6b3JfejJKs8z4waWnRb1OFZjS7nZ6ld7w8VwFU5RuhEWvQY/Li5NtvZidl4rKNjvcPj/MOjWKAh3sJZkmfFLVgeo2OzICJyvSB/g0gLxdV8jipbnWGMG6Tg7WfUP11IhGTVZWFrKysoblvqdOnYq8vDy8/fbbWLRoEQDA7XZj27Zt+PnPfx7zdnq9Hnq9Pub1REREREQ0tFgFQ0RECtM4mVg3B6bKgcFVwQxEroORw2Kjdvx+uxQEAbPzpan1o41SHYxcCzMrzwJVYDq9NEvqYq9qd6AjUAUz0KcBghPr7ojFS/sz66XXFifWabKpqanBvn37UFNTA5/Ph3379mHfvn3o7Q2uezB79my88MILAKS/s9/+9rfx05/+FC+88AIOHTqEdevWwWQy4frrrx+tp0FERERERP2M3dSEiIhGnHGcdKyrVAJSdNIUdpox+SqYgaQatAD60NITmFgfxx3rADA7LxU7qzpxpKkbn0chjjZK/epy/zogTawDQHW7HZ12K4Doi7uGkoP3TkcwWM+LGaxLr6deBus0yfzoRz/CU089pXwtT6G/9957WLVqFQCgvLwcNptN2ebOO+9EX18fvvGNb6CzsxNnnHEG3nrrLVgslhHddyIiIiIiim3spiZERDTiwibWx3AVDCDVwfS4vMM0sS49d49PBDC+O9YBREysHw1MrM/JC4Z0pZnBiXV58dL0AYP14GR/p8MDIHzx0lBmnXRMHW5WwdDksmXLFmzZsiXuNqIohn0tCAI2btyIjRs3Dt+OERERERHRKRm/n20nIqIhFxqsW8bwxDoAWAxSqGsdjmDdEH6f47ljHZAm1gHgaJM0qR5tYn1KYGK9rdeF2o4+AMEO9Vjk4P1YsxTU6zSqmJ33chUMJ9aJiIiIiIhoImCwTkRECqMuGKaP5SoYIDhRPyxVMP3C4fFeBTMrMJne3O1CVZsdDTZn2OWAdDIhMxCU76vtBJDIxLp0vcvrByDVwAhy+X0/8sQ6O9aJiIiIiIhoImCwTkREivGyeCkALJ6SBo1KwOlF1iG/74k2sZ6i1ygd6i/uqwcAFKYZI56nvM2JVjuAYNVLLOnm8Otj1cAAwRM1dlbBEBERERER0QTAYJ2IiBShAbJljHes3/PZOdj7owsxr3AYgnVj+HMf7x3rADA7MJ3+wl4pWJ+TH7kIotyzLhtoYr3/pwVyYyxcCoQE65xYJyIiIiIiogmAwToRESlCJ9bHehWMIAhKz/pQi5hYH+dVMECwZ7263RH2daiSfsH6QB3rOo0qrIs/brAeOIYON4N1IiIiIiIiGv8YrBMRkSLboodeo0JhmhFa9eT9FhHRsT4BJtb7T6jPjjaxnmUK+zpjgIl1IHyqPS+BifVeF6tgiIiIiIiIaPwb2+OIREQ0oiwGLf79rXMmxIT2qUjtV4MzEYL1/hPqiUysD1QFA0g97DUd0u9z4nSsp7AKhoiIiIiIiCYQButERBSmLDdyknmyiZhYnwAnGqZkmGDSqeFw+6DXqDA1yxyxTWlmcGJdp1Yp9S3xhIbv8apgTHrpvhisExERERER0UQweT/nT0REFEP/hVv1mvH/7VKlEjArsIDprDwL1CohYps0kw7WwEmFdLMWghC5TX/ppuSqYOzsWCciIiIiIqIJYPwnBUREREMsdPFSo1adUMA8Hsj1L7PifCpBnlpPH2DhUlnodvEm1oNVMOxYJyIiIiIiovGPwToREVE/oVUwE6EGRnbzuVPxmTk5+Mp502JuI/esJx6sS8cq1aCJe6xMOlbBEBERERER0cTBjnUiIqJ+LHoNBAEQxYmxcKlsenYK/u/GZXG3kSfWMxJYuBQIdqzHm1YHuHgpERERERERTSycWCciIupHpRKUINignVzfKi9fUIAFxWm4cklhQttPCyyCOjMv/qK3wY51H/x+8dR2koiIiIiIiGiUcWKdiIgoilSDFj1O74SqgklEWa4FL33z7IS3XzE9E8985Uylvz0Wsy74lqPP41OCdiIiIiIiIqLxaFTH8N5//31cfvnlKCgogCAIePHFFwe8zbZt27BkyRIYDAZMmzYNjz/++PDvKBERTTpyz/pEqoIZDoIg4IxpmbCatHG3M2hVUAXWgGUdDBEREREREY13oxqs2+12LFiwAI888khC21dWVuKzn/0szj33XOzduxf33HMPbr31Vjz33HPDvKdERDTZpBrkKhgG60NBEARlat3u9o3y3hARERERERGdmlH9HPaaNWuwZs2ahLd//PHHMWXKFPzmN78BAMyZMwe7du3CL3/5S1x55ZXDtJdERDQZcWJ96Jn1GvS4vJxYJyIiIiIionFvXK3ItmPHDlx00UVhl1188cXYtWsXPB7PKO0VERFNRKmGQLA+yTrWh5NZLx3LXgbrRERERERENM6Nq5XDmpqakJubG3ZZbm4uvF4v2trakJ+fH3Ebl8sFl8ulfN3d3T3s+0lERONfqlH6FsmJ9aEjL1jqcDNYJyIioiFSUQFs3gxUVQGlpcBNNwFlZaO9V0RENAmMq2AdkDpaQ4miGPVy2YMPPoj7779/2PeLiIgmlunZKQCAKZmmUd6TiUPuWO91sWOdiIiIhsCTTwI33wwIAiCK0n8fegjYtAlYt260946IiCa4cVUFk5eXh6amprDLWlpaoNFokJmZGfU2d999N2w2m/KrtrZ2JHaViIjGueuWT8HLG87GV86dNtq7MmHIE+vsWCciIqJTVlEhhep+P+Dzhf93/Xrg+PHR3kMiIprgxlWwvmLFCrz99tthl7311ltYunQptFpt1Nvo9XqkpqaG/SIiIhqIWiXg9KI0aNTj6lvlmCZ3rDNYJyIiolO2ebM0oR6NIEhT60RERMNoVNOC3t5e7Nu3D/v27QMAVFZWYt++faipqQEgTZt/+ctfVrb/2te+hurqatx+++04cuQINm/ejE2bNuGOO+4Yjd0nIiKiJAQn1lkFQ0RERKeoqkqqf4lGFKXriYiIhtGodqzv2rULq1evVr6+/fbbAQA33ngjtmzZgsbGRiVkB4CpU6fitddew3e+8x08+uijKCgowO9+9ztceeWVI77vRERElJwUOVjn4qVERER0Cuz2k1DlqmAQBESdWRcEaSFTIiKiYTSqwfqqVauUxUej2bJlS8RlK1euxJ49e4Zxr4iIiGg4mHSsgiEiIqJT02s/gfLyjRDPPIolv/dBBMLCdRGAIIpSzzoREdEwYnEsERERjYgULl5KREREp6i15S10de2GLacLR76bDagAvxoQVQJEtQCoVFK/+owZo72rREQ0wY3qxDoRERFNHkrHupsd60RERDQ4LlcDABcAoPESC7rmG1HytgqmVjV8RTkwfesnMJ1+/ujuJBERTQoM1omIiGhEsArm1PS5ffjXnjpcfno+0ky60d4dIiKiUeHze8K+7ivUo/cHX4IhayWMhiKYzNNGac/Gnor2CmzeuxlVtiqUWktx06KbUJZZNtq7RUQ0YTBYJyIiohHBKphT85t3j+GJbSfRbHPijotnjfbuEBERjTi7/STa2t4Nu0ylMiAz8zxkZp43Sns1Nj2590nc/MrNECBAhAgBAh7a/hA2rd2EdQvXjfbuERFNCOxYJyIiohFh0o1MFczfPq7BU9urhvUxRsPWo60AgLpOxyjvCRER0eg4WfkIvN6OsMvUagMEQYhxi8mpor0CN79yM/yiHz7RF/bf9S+tx/GO46O9i0REEwKDdSIiIhoRQz2xvru6A/tru8Iuq2yz454XDuK+lw+jvdc1JI8zFjR3O1He3AMA6HR4BtiaiIho4rHbT6Kl5ZWIy1UqPQyGolHYo7Fr897NEBD9ZIMA4Il3HhnZHSIimqAYrBMREdGIMOuljvXeIQjW23pduO5PH+OqJ3agudupXP6v3bXK75u7J06w/kFFm/L7Lod7FPeEiIhodJQf+38A/BGXF+RfDTN71cNU2aogQox6nSgCx6vK4WnlJ+CIiE4Vg3UiIiIaEebAxLrD7YMoRv9hL1HbT7TD7fXD7fUrtS8+v4jndtcr27T0OGPcGnhudx1+/faxU96PkfJBRavye06sExHRZGO3n4TNtjvi8oyM8zFt2rdGYY/GtlJradyJ9cLuTHS+dILhOhHRKWKwTkRERCNCDtZ9fhEub+TEWTK2Hw9OcP/14xo43F58UNGKppDp9dae6BPrfW4f7n7+IH77bgUO1ttOaT9Ggt8v4sOQifVOTqwTEdEk09X1Cfz+8O9/KSmnY9HCP43SHo1tNy26KfrEugiIAK7xXQp3TTdcVd0jvm9ERBMJg3UiIiIaESatWvm9XAdzsM6GJlvsyfJYPgwE6zq1CrY+D/65qw7/3F0Xtk1LjGB9V3UH3D4p2D9UP/Z/oPy0sRvtdjc0KmnyrMfphdd3aicmiIiIxhOXuw1AeJVcdvYFo7Mz40BZZhk2rd0ElaCCGmqoRBXUogoqqPALz/cxVSwCvH4gRl0MERElhsE6ERERjQiVSoBJJ4XrDpcPJ1p78fnH/osr/7AdTo8v4fupaXegrrMPGpWA2y+aCQD44/sn8fbhZgDAeTOzAcSeWN9xol35/eGGxCfWR6s2Ru5XP3tGlnJZVx/rYIiIaPJw9jX0u0QFj6dzVPZlvFi3cB3KN5Tj27O+ictVF+Br3uuw1fUXXO1bI20gCNCXWkd3J4mIxjnNaO8AERERTR5mvQYOtw+9Li/21XbB5xdR39WHZ3bW4sazShO6D3laffGUdHx5RQn+sPUE6rv6AACz8yxYNTMb7x9rjR2snwwN1hObWH/wtSN4ekc1pueYMa/AitMKUjEtKwWlWSYUWI1QqaL3mA6FD49L/eqrZ2Vjb00nup1edDncyErRD9tjEhERjSUOx4l+l2iRmXHeqOzLeDIjYwYevOBB9Gjr4DzeCX9nSJ2OT4Sr0gZttmn0dpCIaJxjsE5EREQjJkWvQWuPCw63F/tru5TLH9t6HNcsK4YhpC4mlv+ekIL1s2ZkwqTT4ItnTsGj70k/cF+1tBg5qVLgHC1Y73V5caAuOKV+tKkbPr8I9QDB+L8PNKLP48Oh+u6I+pisFB2e//rZmJI59D+Y9rl92FkpTeSdOzMbT26vCgTrnFgnIqLJobbub7B1Hwi7zGKZg6yslaO0R+OLNtsEy3lFgEYFx47GsOvcVd3A8vxR2jMiovGPVTBEREQ0YuQqmF6XF/vrugAAKgFo7nbh75/UDHh7v19UqlzkapQbV5TCoFXBqFXj8wsLkB2Y5G7piexu31nVAZ9fRGGaESadGk6PHydbewd8zObAoqg//cJ8fHP1dFwwOwfTss3QqAS09brxn6PNiR2AJH1c2Q63z48CqwHTssxIM+kAAJ0M1omIaAKz20+ivv4Z7NmzDseObQQQunCpBllZ54/Sno1P2mwTtFlGoP/8gp6REBHRqeDEOhEREY0Ys15669Ha48Kx5h4AwLfOL8Nv363AY1tP4LrlU+JOrR9p6kaH3Q2zTo2FxWkAgJxUA1765jkAgMwUPbqdXuUx+vsoEMqfNT0TJ9vs2F3dicMN3SjLtcR8zDa7C16/CJUAXL20CBp18IfQX799DL99twIHh2kR1P8Gam/OKcuCIAhIN2kBAJ0Od7ybERERjVt2+0kcPPgN2B0VUa83GAqRm7NmhPdq/DPMTIftTRUQsgC6p64XnlYH62CIiAaJpyeJiIhoxKQEgvWPKzvgF4G8VAO+uXoGCtOMaO1x4S8fVce9/fbjUjC+fGoGtCEB96w8C2blSeF4tkWaWLe7fbC7vGG3l/vVz5qRibkFqQAGXsC02SYF9Fkp+rBQHQDmFVoTuo9kFmcNtbNKqoE5c1omACA9MLHexWCdiIgmqNq6P8cM1VUqE/Lzr4TZPG2E92r8c1XaAHcwVIcAiF4/fJ3R16QhIqKBMVgnIiKiESNXwWwPTGIvKLZCp1HhW+fPAABs/rASoijGvL28cKlcAxONWaeGMTD1Hjq13u304FC9FICvmJYVEqzHnzZvCtTA5FkNEdfNDwTrFS29McPz375TgdM3voXd1Z1xH6e/PrdP2d9lpRkAgDRlYp1VMERENDF1dX0U9XKtNhdW6xLodVkoP/ZTbHt/Cd79zyy8//4KnKz8Pez2kyO8p+OLfV9L+AUioLbooE7nYuhERIPFYJ2IiIhGjDyx3mCTwuoFgTqXzy0shEYloMHmRH1XX9TbNtmc+KSyA0D8YF0QhOACpr3BYP2Tk9KU/NQsM/KsBswtkKfNu+OG+XKwnpsaGaznpuqRlaKDzy/iSGP0gP61g41w+/zYWdUR8zGi2V/XBa9fRI5Fj6J0IwBOrBMR0WQQPabIybkEbncrjpbfh7q6TfB6uwB44fG2oLLyNzh27McM1+Pw2yNPyutKrayBISI6BQzWiYiIaMSYdOHLuywsSgMAGHVqZYI82mR3XacDVz+xA30eH6ZlmzErTic6gOACpt3BYH17oF9drlUpy02BRiXA1udRwvyfvnYE1zyxA33u4PR5c+AkQH6UiXVBEJQ6GHm6PFSvy4tjLT0R+5II+TgsLU2HIAgAEOxYj/LDMRER0USQlnZG1Ms/Pv5/+O2h7XjgaB3+r7IDdX3h3ws7O3fC6awbiV0cdzytDvid4Z+sE/QqqC3aUdojIqKJgcE6ERERjZgUfXBhUkEA5hVZla8Xl6QDAPb0C9ar2uy45omPUNPhwJQME5763+VQqYS4j6NMrPc4lcvkfvUV06VgXa9RK4uWHm7oxtbyFvzx/ZP4uLIjbLo83sQ6AMwrkIP1yIn1Q/U2yMPwLSH7kgh5H5aWZCiXpQUm1rl4KRERTVTFRV+ESpUSdtkbTT24aVctnq3rwrZWO56t68JNu2rxZmAhdAAQ0Rf3E2iTmavSBjH0pLwAaPLN0JdaY9+IiIgGxGCdiIiIRoxZH5xYn56dglRDcFJqSSBY310TDNYdbi+u/9NHqO/qw7QsM5796goUZwz8kWVlYj3Qsd7n9uFokxR8nzE1GFTLU/J7a7qw8eXDyuXV7Xbl902BifW8WMF6YGL9YJSJ9f21XcrvW3oSn1j3+0XlBMPS0nTlcrljvYsd60RENEGZzdMwf97vAEgn4+v6PPhVRSv8QMSvh4+1oj4wuS4IeuUTXhTO2+0CQk866NQwzExnDQwR0SlisE5EREQjxhQSrC8I1MDI5GD9SGMP7C4vAOCdIy1osDmRbzXgH189M+oCotHkBEJwefHSY809EEUg06xDjiW4SJccrG/+byWq2h3K5aG/j7d4KQDMK0xVHsPlDf+Y9f66LuX3rUkE6xUtveh2emHSqXFafqpyeTon1omIaBLIylqJqVNvBSDgjaaeuNu+HrjeYpkHg6FoBPZufPG0OuA60e/kv9cHV6UNnlZH9BsREVFCGKwTERHRiAmtgllYHP7x43yrEQVWA3x+UQmkXz3QAAC4YnEhciyJhepA5MS6PK0+O98SNs0mL2Dq9voBAGdOk6bZQyfW5Y71WFUwhWlGpJu08PpFlPf74X9/bfAH2ZbuxKtgdlVLNTALi9OgUQffroVOrPPj7kRENJHl5nwW6ennoDlwsj2WZpcHZvMcnDbnZzCbp43Q3o0fvg4nVIIAlVUPCJB+iYCn0QFXVeSn7YiIKHEM1omIiGjEmEMWLz2938Q6EN6z3uvy4r3yVgDApfMLknqcbKVjXQrWjzRKgfecvNSw7ebkBxdBPXNaBr65egaA4MS63eVFT+AH+lgT6+ELmAZ71lt6nMqiqABgd/uUSfyB7KoK1MCUpIddLk+su31+ONy+iNsNRlWbHU7P0NwXERHRUDGbp2HWzB+hxDo17na5ei1SzLMZqsegzjBAnWmA2moAtCpABOAHxF4Pej9q5NQ6EdEpYLBOREREI0buWNepVZgdEmrLlJ716k68e6QZbq8f07LMYQF4ImJPrIcH6xaDFsunZiBFr8H/+9w8lGaaAQA17Q74/KJSA5Oi1yAlpMamv2g96wcC0+ozc1Ng0qnD9mcg8sT60tKMsMtNOjV0gQn2oaiD2VfbhVW/3Iq7njtwyvdFREQ01MzmafjaGd+Pu82aPAu0Oi7CGYs22wTLeUWwri6GrjT8fZDf7oWvM/GqOiIiCsdgnYiIiEbMzFwLLAYNLjwtF3qNOuJ6OVjfU9OFV/Y3AgAuPT0/6cXIcgIT6x12F7w+P44GKlpm50UG9H9evxwffn81ZuZaUJBmhFYtwO3zo6nbGVy4dIBu93mBSpnDDcFgXa6zWVCUpvS6J1IH09ztRG1HH1QCsGhKWth1giAM6QKmhwInAj6p7Djl+yIiIhoOZ8y4AXfNnQMVEPHruzOzUWg0wmwqG9V9HBdEEZpMo1QFE6Aya6BO18e+DRERxRV79IqIiIhoiGVb9Nj5g89Ar4l+bn9OfioMWhVsfR68e7QZAPDZ+flJP06mWQ+VAPhF4NPGbnQ5PFCrBMzISYnYVq9RKyG/WiWgOMOEk612VLXZg8F6jH512fzAxPrRxh64vX7oNCrsq+0CAJxenIbqdgeq2h0JTazLNTCz8lJhMWgjrk836dDS4xqSiXV5fxpsTvQ4PVEfj4iIaLR9/cwfYZbxB3i9qQPNLg9y9QasyUtBsdkKo7EIRmNylXGTiafVgc4Xj8Nd1wu4QqrfTBqknJEPbbZp9HaOiGicY7BOREREI8qgjZxUl2nVKiwoSsPHlR0QRWBatjnqlPlA1CoBGWY92npd+KCiDQAwLcsc97FlpZlmKVhvtytT4bEWLpUVZxiRatCg2+lFeVMP5hWm4kCdNA2+sCgNH51sB5BYFcy+2uj96jJ5Yr1zCCbWQyfoT7TasbA47ZTvk4iIaKgVFV2L8wEsKd0Nq3UJDIZ81NZtgd/vgck4BQZD0Wjv4pjlqrTBXWUDIpZTEaFJS3xheCIiisRgnYiIiMaUJSXp+DhQTXLZ/ORrYGQ5FilY33ZMWgC1f796LCWZ0uRWdbtDWdQzzxr/Y9KCIGBxSTq2lrfijn/uxwNfmAdbnwc6jQqz8izBKpiegatgajqkRcTKciOn64HgAqa2JCbWazsc+Mmrn+K65VOwalaOcnlzSLBe0dwTM1j3+PzQqtkgSEREo6eo6FoUFV2rfG00FsPprIPBUMSFS+Pw9bijhOoA3H7WwBARnSL+hERERERjypKQSe1LTx/8R7uzA2H2nmppAjzRyfepWdICpslUwQDAvZedhhyLHuXNPfjipo8BAHMLUqHTqJBjkW7f2h2cWO+0u/HK/gYlvJc1dEmPWWA1Rn2cdHNyE+s+v4jvPLMPbx5uxh/fPxl2XegE/fGW3qi3r2yzY/kD7+COf+5P6PGIiIhGgtk8DZmZ5zFUH4DfHuv9gghXpS3GdURElAgG60RERDSmnDEtE6WZJqycmY2ZMaa2EyFPiXv9IgBgTn5iwXpJphSsV7c70BSY6B6oCgYApmen4NmvrkCB1QCnxw9AWrg0dF9Cg+xfvlWOb/19L/61uy7sfhq6+gAABWnRg/W0wMR6oh3rT/63ErsCJxfk+5Y1hwT9FTGC9Se2nUCnw4Ot5a0JPR4RERGNHf4+b/QrvEDXi8fR+0njyO4QEdEEwmCdiIiIxpQUvQZbv7caT920fNA1MEBwYl02Oy+xKphSuQqmw45GeWLdmlgHaWmWGc98dQWmZEj3sWJ6JgAgJzWyCkZe3LS8qUe5rM/tQ7tdCswLYwTr6YGO9a4EJtZPtPbiF2+WK1832JzwB040eH1+tNtDg/WeiNu39Djx/J56AEBbrwtur3/AxyQiIqKxQ2WM0wDsBxz7eeKciGiwGKwTERHRhJQTEqynGjTITzAcL0wzQqMS4PT40RqYME80WAeA4gwTXtlwDv568xm46LTcwL5It5cn1n1+UZkQlzvVAaDBJk2Um3VqpMb4QTjRiXWfX8T3/rkfLq8fZ03PhCAAbq9fCe7bet0QRUA+d1HX2QeHO3yq7c87quH2BcP00E52IiIiGvu0eWYgzpyCOHK7QkQ04TBYJyIiogkp2xIMw2fnpyY8/a5Rq1CUHpwW16gEZJmTW9zLatLi7BlZymPKIX+XwwOX14eqdrsy/V0bGqwHqloK040x9zfNGN6xLooitp9oQ1dI0O72+vHdZ/dhT00XLHoNfnnVAuQGjof8GHJInmsxINOsgygCJ1vtyn043F78+aNqAMHwXZ7gp8Q98MADOOuss2AymZCWlpbQbdatWwdBEMJ+nXnmmcO7o0RENCHpp1phmJsZM1w3TE8b0f0hIppIGKwTERHRhCTXrwDAnAQXLpXJPeuAFIqrVIOvpAGANJMWOrX0tqu1x4VjIfUvdZ198AXqWQbqVweAdLM0sS4H6U/vqMb1f/oYK3+xFVv+W4kOuxs3bv4EL+5rgEYl4GdXno6CNCMK0mIE66l6TM+RuuxD62D+tbsOXQ4PSjJNWFaSAQBotIV3tNPA3G43rrrqKnz9619P6naXXHIJGhsblV+vvfbaMO0hERFNZNpsE6wXl8J8Vn7klSrAND9r5HeKiGiCiFO2RURERDR+ZaeEBOv5ifWry6ZmmbHtmNQ5mptEDUwsgiAg26JHfVcfWnpcOBoSrLt9fjR3O1GQZkR9lxR2xw3WAx3rnYFKl5f2SR3otj4PNr7yKR547Qg8PhFmnRp/+OISnDczW7nPPTVdqA8E63ItTU6qATkWPT6p7EBFs1RP4/OL+L8PKgEAN58zFXtquoAqTqwPxv333w8A2LJlS1K30+v1yMvLG4Y9IiKiyUabbYIq8P4hjIazlkREp4L/ihIREdGEFLp46ewkg/WSwAKmAJCXeurBeuj+tHS7whYsBYI960oVTJxgXe5Y73Z60WRzYm9gEdQ7L5mFDLMOHp+IHIsez35thRKqh96nEqwHJtZzLHqUBSbWjwd639883ISaDgfSTVr8z5JipWO+icH6iNm6dStycnIwc+ZM3HLLLWhpaRntXSIionHM2xblU2duP1xVtpHfGSKiCYIT60RERDQhmfUaLClJR1uvC7OTrIIpDamCyR2iYF3uWW/tceJYsxSsG7Vq9Hl8qOlw4MxpmajvlKtgYj+m3LEOAM/tqYMoAqcXWfGNVTNwwxklePNwE1bNzEZOv/2Wp+CDVTAu5fmV5UrH53hLL0RRxBPvnwQAfOnMEhh1ahRYw2tkaHitWbMGV111FUpKSlBZWYl7770X559/Pnbv3g29Pnrfv8vlgsvlUr7u7u4eqd0lIqJxQJMV/aS9fW8LUpZFqYkhIqIBcWKdiIiIJqxnv7oC796+EgatOqnbhU6s5w9BFQwQ7Hyv6XCgql1aJPS8mVKvqbyAaYNNnlg3RbkHiUatgsUgzUb8c1ctAOCi03IBAFajFlcvLY4I1YHQYF2aOm/pCXasyxPrVe12bD/Rjv21XdBpVPjSilIAQJ5Vum1TNyfWAWDjxo0Ri4v2/7Vr165B3/8111yDSy+9FPPmzcPll1+O119/HceOHcOrr74a8zYPPvggrFar8qu4uHjQj09ERBOP6fRsqNIjT856WxxRtiYiokRwYp2IiIgmLLVKAJD8wqNF6SaoBMAvQqlBOVU5Ful+tp9oh1+UutIXT0nHm4ebUdPhgN8volHpWI//mOkmHXqcXlS1Sz8MX3jawF3ckYuXBjvWsy16pBo06HZ68aOXDgEArlxcqNTXyCcX2LEu2bBhA6699tq425SWlg7Z4+Xn56OkpAQVFRUxt7n77rtx++23K193d3czXCciIoU224TU1cXoev542OWixz9Ke0RENP4xWCciIiLqR6dRoTTTjJNtdhSlx54eT4ZcBXO4QaromJVnUSbjq9sdaLO74Pb5oRIGrp9JN2lR0yH9fkqGCTNzUwZ8fLljvd3uhtPjUybWcyx6CIKAslwLdld34kSrNE2//pxpym3lYL2t1wW31w/dJF/sLCsrC1lZWSP2eO3t7aitrUV+fuyP6uv1+pg1MURERDF5/fC0OqDNHpr3O0REk8nk/qmIiIiIKIafXXk67vnsbCyekjYk9ydXwchm56WiOEP6Iba2w6FUtOSmGqBVx3+LJi9gCgAXnpYLQRh4Kt9q1MKskypxajocaLe7lccDoNTBAMBn5uRgRsjXGWYddBoVRBFoZh1MUmpqarBv3z7U1NTA5/Nh37592LdvH3p7e5VtZs+ejRdeeAEA0NvbizvuuAM7duxAVVUVtm7dissvvxxZWVn4whe+MFpPg4iIJgD73igLYfsAX6cr8nIiIhoQJ9aJiIiIolg+NQPLp2YM2f3JVTCymbkWJVhvt7uVBU3lLvR40k3BBUzlfvWBCIKAgjQjKlp6sb+2C6IIaFQCMgIhfWiQfsu50yJum281oLrdgaZup7LfNLAf/ehHeOqpp5SvFy1aBAB47733sGrVKgBAeXk5bDYbAECtVuPgwYN4+umn0dXVhfz8fKxevRrPPPMMLJbkFuElIiKSeVod8NREWdhaLUAdpXudiIgGxmCdiIiIaATIVTCyWXkWpBq0SDdp0enw4KOT7QASC9blifV0kxZLStIT3gc5WN9b2wUAyLbooVJJ0+7LSjMC/02PekIhL1UK1uWOdkrMli1bsGXLlrjbiKKo/N5oNOLNN98c5r0iIqLJpue/9YAv8nLj6VmsgSEiGiQG60REREQjIDNFryyICkDpRZ+SYUKnw4aPT0ql6YUJBOtTAhPjF8/Ng2aA2phQcmi/r6YLgLRwqWxBcRr+/a1zMCXTFLVaRu5Zb+ICpkREROOKp9UBx+7miMu101KRec3sUdgjIqKJgcE6ERER0QhQqwRkpujR2uNCYZoRFoNU51KcYcL+OhvqA5PghWnxFy4FgOuWT0GqUYtL5uUltQ/yfR9tkj4Knttvin5eoTXmbfMDoXwjg3UiIqIxzdPqgLetD87yDjiOtEO0eSK20RSZkfuVBaOwd0REEweDdSIiIqIRkmORgvXZecGu7Cn9+soTqYIx6tT4nyVFST++fN/y1Hz/BVXjkSfWG22sgiEiIhqrPK0OdPzzGDwNPYA39nbWC0tHbJ+IiCaqxD87TERERESnRO5Zn3WKwfpg9b/vXMvA0/GyvFRWwRAREY113e/VwlMTP1SHUQ3jrKFboJ2IaLLixDoRERHRCFkzLx8H67vDKlymZI5csN6/vz03NfFgvYBVMERERGOOp9UBX4cT6gwD/HYP+g63DXgb86KcEdgzIqKJj8E6ERER0Qi5elkxrl5WHHZZ6MS6Ra+B1agdtsfPTTVAEAAxUAWTnUQVTF6gCqa11wW31w+dhh98JCIiGk2eVge636uFr60PoloAfP5g31s0KsC4IBvpa2eM3E4SEU1gDNaJiIiIRlG+1QiNSoDXLw7rtDoA6DQq5Fj0aO52AUiuCibDpINOrYLb50dLyZhktQAAHtdJREFUjxNF6aaBb0RERETDxtfhhK+9D36fH95mJwSNClCrAK8PkPN1kwbafDMM09Ngmp8FbTa/fxMRDRUG60RERESjSK0SUJRuRFW7AwVpiQfdg1WYZgwG60lMrKtUAvKsBtR0ONBoY7BOREQ02tQZBggmLfy1PYDfD02OGYIgQG3VAxChyTYxTCciGkYM1omIiIhGWXGGKRCsD+/EOiB1pe+p6YJWLSDdpEvqtqHBOhEREY0uURShMqil4XSVCr5OF3TFKUg9v5hhOhHRCGCwTkRERDTKTstPxQcVbZiVZxn2x5IXMM1O0UOlEpK6bX6gZ73J1jfk+0VERESJ87Q60LtpK3RvPAtjewPE4inoO2MtDDPPYKhORDRCGKwTERERjbJvXVCGZaUZOHdm1rA/ljwVn5OafO1MvlW6bUMXJ9aJiIhGk/inTUj/4behrEp+RIDpzS3wZT4GLPvqaO8eEdGkoBrtHSAiIiKa7FL0GnzmtFzoNephf6yzZ2TCatTiwtNyk75tcGKdwToREdGoqaiA9t5vQxD9EPw+5b8Q/dB8+xvA8eOjvYdERJMCg3UiIiKiSWRGjgV7770Q31w9I+nb5gWC9cZuButERESjZvNmCEJknZsASBPsmzaN+C4REU1GDNaJiIiIJplku9VlBYEqmMYudqwTERGNmqoqqf4lGlGUriciomHHjnUiIiIiSsjUbDMevX4x8tOS72cnIiKiIVJaKk2mRyMI0vVERDTsOLFORERERAlJ0Wtw6en5WDwlfbR3hYiIaPK66ab4E+vr14/s/hARTVIM1omIiIiIiIiIxouyMqlHXaUC1Orw/27aBMxIfh0VIiJKHqtgiIiIiIiIiIjGk3XrgHPOkYL0qiqp/mX9eobqREQjiME6EREREREREdF4M2MG8OCDo70XRESTFqtgiIiIiIiIiIiIiIiSwGCdiIiIiIiIiIiIiCgJDNaJiIiIiIiIiIiIiJLAYJ2IiIiIiIiIiIiIKAkM1omIiIiIiIiIiIiIksBgnYiIiIiIiIiIiIgoCQzWiYiIiIiIiIiIiIiSwGCdiIiIiIiIiIiIiCgJDNaJiIiIiIiIiIiIiJLAYJ2IiIiIiIiIiIiIKAkM1omIiIiIiIiIiIiIksBgnYiIiIiIiIiIiIgoCZrR3oGRJooiAKC7u3uU94SIiIiIBiK/Z5Pfw1Fi+J6XiIiIaPzge97xadIF6z09PQCA4uLiUd4TIiIiIkpUT08PrFbraO/GuMH3vERERETjD9/zji+COMlOhfj9fjQ0NMBisUAQhBF5zO7ubhQXF6O2thapqakj8pjjFY9Vcni8ksPjlTgeq+TweCWHxytxPFbS1E5PTw8KCgqgUrHFMFGj8Z43WXx9x8fjMzAeo/h4fOLj8YmPxyc+Hp/4eHzii3Z8+J53fJp0E+sqlQpFRUWj8tipqan8ByVBPFbJ4fFKDo9X4nisksPjlRwer8RN9mPFqZ3kjeZ73mRN9tf3QHh8BsZjFB+PT3w8PvHx+MTH4xMfj098/Y8P3/OOPzwFQkRERERERERERESUBAbrRERERERERERERERJYLA+AvR6Pe677z7o9frR3pUxj8cqOTxeyeHxShyPVXJ4vJLD45U4HiuayPj6jo/HZ2A8RvHx+MTH4xMfj098PD7x8fjEx+MzcUy6xUuJiIiIiIiIiIiIiE4FJ9aJiIiIiIiIiIiIiJLAYJ2IiIiIiIiIiIiIKAkM1omIiIiIiIiIiIiIksBgfZg99thjmDp1KgwGA5YsWYIPPvhgtHdp2D344INYtmwZLBYLcnJy8PnPfx7l5eVh26xbtw6CIIT9OvPMM8O2cblc+Na3voWsrCyYzWasXbsWdXV1Ydt0dnbiS1/6EqxWK6xWK770pS+hq6truJ/ikNm4cWPEccjLy1OuF0URGzduREFBAYxGI1atWoXDhw+H3cdkOE6y0tLSiOMlCAK++c1vAuDr6v3338fll1+OgoICCIKAF198Mez6kXw91dTU4PLLL4fZbEZWVhZuvfVWuN3u4XjagxbveHk8Hnz/+9/H/PnzYTabUVBQgC9/+ctoaGgIu49Vq1ZFvOauvfbasG0mwvEa6LU1kn/3xvqxAgY+XtH+HRMEAb/4xS+UbSbLa4sml6qqKqxfvx5Tp06F0WjE9OnTcd999w34mkzk35iJYLDHJ5Hv7xPFAw88gLPOOgsmkwlpaWkJ3WayvH6AwR2fyfT6Gcx7/In++kk2r9i2bRuWLFkCg8GAadOm4fHHHx+hPR0dyRyfrVu3Rn1/d/To0RHc45Ez0PvdaCbT6yfZ4zPZXj8TCYP1YfTMM8/g29/+Nn7wgx9g7969OPfcc7FmzRrU1NSM9q4Nq23btuGb3/wmPvroI7z99tvwer246KKLYLfbw7a75JJL0NjYqPx67bXXwq7/9re/jRdeeAH/+Mc/8OGHH6K3txeXXXYZfD6fss3111+Pffv24Y033sAbb7yBffv24Utf+tKIPM+hMnfu3LDjcPDgQeW6hx56CL/61a/wyCOPYOfOncjLy8OFF16Inp4eZZvJcpwAYOfOnWHH6u233wYAXHXVVco2k/l1ZbfbsWDBAjzyyCNRrx+p15PP58Oll14Ku92ODz/8EP/4xz/w3HPP4bvf/e7wPflBiHe8HA4H9uzZg3vvvRd79uzB888/j2PHjmHt2rUR295yyy1hr7knnngi7PqJcLwGem0BI/N3bzwcK2Dg4xV6nBobG7F582YIgoArr7wybLvJ8NqiyeXo0aPw+/144okncPjwYfz617/G448/jnvuuWfA2w70b8xEMNjjk8j394nC7Xbjqquuwte//vWkbjcZXj/A4I7PZHr9DPY9/kR9/SSbV1RWVuKzn/0szj33XOzduxf33HMPbr31Vjz33HMjvOcjY7B5Tnl5edjrpaysbIT2eGQl8vNBqMn2+kn2+Mgmy+tnQhFp2Cxfvlz82te+FnbZ7NmzxbvuumuU9mh0tLS0iADEbdu2KZfdeOON4uc+97mYt+nq6hK1Wq34j3/8Q7msvr5eVKlU4htvvCGKoih++umnIgDxo48+UrbZsWOHCEA8evTo0D+RYXDfffeJCxYsiHqd3+8X8/LyxJ/97GfKZU6nU7RareLjjz8uiuLkOU6x3HbbbeL06dNFv98viiJfV6EAiC+88ILy9Ui+nl577TVRpVKJ9fX1yjZ///vfRb1eL9pstmF5vqeq//GK5pNPPhEBiNXV1cplK1euFG+77baYt5mIxyvasRqpv3vj7ViJYmKvrc997nPi+eefH3bZZHxt0eT00EMPiVOnTo27zUD/xkxkAx2fRL6/T0RPPvmkaLVaE9p2Mr5+Ej0+k+n1M9j3+BP59ZNsXnHnnXeKs2fPDrvsq1/9qnjmmWcO2z6OpmSPz3vvvScCEDs7O0dg78aWRN7vTrbXT6hEjs9kfv2Md5xYHyZutxu7d+/GRRddFHb5RRddhO3bt4/SXo0Om80GAMjIyAi7fOvWrcjJycHMmTNxyy23oKWlRblu9+7d8Hg8YcevoKAA8+bNU47fjh07YLVaccYZZyjbnHnmmbBarePqGFdUVKCgoABTp07Ftddei5MnTwKQzug2NTWFHQO9Xo+VK1cqz28yHaf+3G43/vKXv+Cmm26CIAjK5XxdRTeSr6cdO3Zg3rx5KCgoULa5+OKL4XK5sHv37mF9nsPJZrNBEISIj1b/9a9/RVZWFubOnYs77rgjbMJrMh2vkfi7N1GOVajm5ma8+uqrWL9+fcR1fG3RZGCz2SLeI0YT79+YiWyg45PI93eavK+fgUym18+pvMefiK+fweQVO3bsiNj+4osvxq5du+DxeIZtX0fDqeQ5ixYtQn5+Pi644AK89957w7mb48pkev2cCr5+xh/NaO/ARNXW1gafz4fc3Nywy3Nzc9HU1DRKezXyRFHE7bffjnPOOQfz5s1TLl+zZg2uuuoqlJSUoLKyEvfeey/OP/987N69G3q9Hk1NTdDpdEhPTw+7v9Dj19TUhJycnIjHzMnJGTfH+IwzzsDTTz+NmTNnorm5GT/5yU9w1lln4fDhw8pziPYaqq6uBoBJc5yiefHFF9HV1YV169Ypl/F1FdtIvp6ampoiHic9PR06nW7cHkOn04m77roL119/PVJTU5XLb7jhBkydOhV5eXk4dOgQ7r77buzfv1+pKZosx2uk/u5NhGPV31NPPQWLxYIrrrgi7HK+tmgyOHHiBH7/+9/j4YcfjrvdQP/GTFSJHJ9Evr9PdpP19ZOIyfT6Gex7/In6+hlMXhHtfUVubi68Xi/a2tqQn58/bPs70gZzfPLz8/HHP/4RS5Ysgcvlwp///GdccMEF2Lp1K84777yR2O0xbTK9fgaDr5/xi8H6MAudpAWkoLn/ZRPZhg0bcODAAXz44Ydhl19zzTXK7+fNm4elS5eipKQEr776akS4EKr/8Yt2LMfTMV6zZo3y+/nz52PFihWYPn06nnrqKWVRnMG8hibacYpm06ZNWLNmTdgkJl9XAxup19NEOoYejwfXXnst/H4/HnvssbDrbrnlFuX38+bNQ1lZGZYuXYo9e/Zg8eLFACbH8RrJv3vj/Vj1t3nzZtxwww0wGAxhl/O1RePJxo0bcf/998fdZufOnVi6dKnydUNDAy655BJcddVVuPnmm+PedrD/xowVw318gPH9M8dgjk8yJuPrJ1mT4fUDDO574nh//Qwk2T/7aNtHu3yiSOb4zJo1C7NmzVK+XrFiBWpra/HLX/6SwWjAZHv9JIOvn/GLwfowycrKglqtjjib2dLSEnGWbqL61re+hZdffhnvv/8+ioqK4m6bn5+PkpISVFRUAADy8vLgdrvR2dkZNuHY0tKCs846S9mmubk54r5aW1vH7TE2m82YP38+Kioq8PnPfx6AdGY39Oxt6Gtosh6n6upqvPPOO3j++efjbsfXVVBeXh6AkXk95eXl4eOPPw67vrOzEx6PZ9wdQ4/Hg6uvvhqVlZX4z3/+EzatHs3ixYuh1WpRUVGBxYsXT7rjJRuuv3sT7Vh98MEHKC8vxzPPPDPgtnxt0Vi2YcMGXHvttXG3KS0tVX7f0NCA1atXY8WKFfjjH/+Y9OP1/zdmrBvO45PI9/exLtnjc6om+usnGZPp9XPgwIEheY8/3l4/sQwmr8jLy4u6vUajQWZm5rDt62gYqjznzDPPxF/+8peh3r1xaTK9foYKXz/jAzvWh4lOp8OSJUuUj2zL3n77bSVEmKhEUcSGDRvw/PPP4z//+Q+mTp064G3a29tRW1urvKFbsmQJtFpt2PFrbGzEoUOHlOO3YsUK2Gw2fPLJJ8o2H3/8MWw227g9xi6XC0eOHEF+fr5SARB6DNxuN7Zt26Y8v8l6nJ588knk5OTg0ksvjbsdX1dBI/l6WrFiBQ4dOoTGxkZlm7feegt6vR5LliwZ1uc5lORQvaKiAu+8805Cb/gOHz4Mj8ejvOYm0/EKNVx/9ybasdq0aROWLFmCBQsWDLgtX1s0lmVlZWH27Nlxf8mfyqivr8eqVauwePFiPPnkk1Cpkv9xpP+/MWPdcB6fRL6/j3XJHJ+hMJFfP8maTK+foXqPP95eP7EMJq9YsWJFxPZvvfUWli5dCq1WO2z7OhqGKs/Zu3fvuH+tDJXJ9PoZKnz9jBMjs0bq5PSPf/xD1Gq14qZNm8RPP/1U/Pa3vy2azWaxqqpqtHdtWH39618XrVaruHXrVrGxsVH55XA4RFEUxZ6eHvG73/2uuH37drGyslJ87733xBUrVoiFhYVid3e3cj9f+9rXxKKiIvGdd94R9+zZI55//vniggULRK/Xq2xzySWXiKeffrq4Y8cOcceOHeL8+fPFyy67bMSf82B997vfFbdu3SqePHlS/Oijj8TLLrtMtFgsymvkZz/7mWi1WsXnn39ePHjwoHjdddeJ+fn5k+44hfL5fOKUKVPE73//+2GX83UlHYO9e/eKe/fuFQGIv/rVr8S9e/eK1dXVoiiO3OvJ6/WK8+bNEy+44AJxz5494jvvvCMWFRWJGzZsGLmDkYB4x8vj8Yhr164Vi4qKxH379oX9W+ZyuURRFMXjx4+L999/v7hz506xsrJSfPXVV8XZs2eLixYtmnDHK96xGsm/e+PhWIniwH8XRVEUbTabaDKZxD/84Q8Rt59Mry2aXOrr68UZM2aI559/vlhXVxf2b2uoWbNmic8//7woiol/f58IBnN8RDGx7+8TRXV1tbh3717x/vvvF1NSUpR/a3t6epRtJuvrRxSTPz6iOLleP4m8x59Mr5+B8oq77rpL/NKXvqRsf/LkSdFkMonf+c53xE8//VTctGmTqNVqxX/961+j9RSGVbLH59e//rX4wgsviMeOHRMPHTok3nXXXSIA8bnnnhutpzCsBnq/O9lfP8ken8n2+plIGKwPs0cffVQsKSkRdTqduHjxYnHbtm2jvUvDDkDUX08++aQoiqLocDjEiy66SMzOzha1Wq04ZcoU8cYbbxRramrC7qevr0/csGGDmJGRIRqNRvGyyy6L2Ka9vV284YYbRIvFIlosFvGGG24QOzs7R+iZnrprrrlGzM/PF7VarVhQUCBeccUV4uHDh5Xr/X6/eN9994l5eXmiXq8XzzvvPPHgwYNh9zEZjlOoN998UwQglpeXh13O15Uovvfee1H/7t14442iKI7s66m6ulq89NJLRaPRKGZkZIgbNmwQnU7ncD79pMU7XpWVlTH/LXvvvfdEURTFmpoa8bzzzhMzMjJEnU4nTp8+Xbz11lvF9vb2sMeZCMcr3rEa6b97Y/1YieLAfxdFURSfeOIJ0Wg0il1dXRG3n0yvLZpcnnzyyZj/toYazPvGiWAwx0cUE/v+PlHceOONcb83i+Lkff2IYvLHRxQn1+snke+bk+31Ey+vuPHGG8WVK1eGbb9161Zx0aJFok6nE0tLS6MOCEwkyRyfn//85+L06dNFg8Egpqeni+ecc4746quvjsJej4yB3u9O9tdPssdnsr1+JhJBFAOrBRARERERERERERER0YDYsU5ERERERERERERElAQG60RERERERERERERESWCwTkRERERERERERESUBAbrRERERERERERERERJYLBORERERERERERERJQEButERERERERERERERElgsE5ERERERERERERElAQG60RERERERERERERESWCwTkREREREREQJEwQBL7744mjvRlxbt26FIAjo6uoa7V0hIqIJisE6EdEY0NLSgq9+9auYMmUK9Ho98vLycPHFF2PHjh0AxscPL0REREQ0fq1btw6CIEAQBGi1WuTm5uLCCy/E5s2b4ff7w7ZtbGzEmjVrRmlPE3PWWWehsbERVqt1WB/n/fffx+WXX46CggK+ZycimmQYrBMRjQFXXnkl9u/fj6eeegrHjh3Dyy+/jFWrVqGjo2O0d42IiIiIJolLLrkEjY2NqKqqwuuvv47Vq1fjtttuw2WXXQav16tsl5eXB71eP4p7OjCdToe8vDwIgjCsj2O327FgwQI88sgjw/o4REQ09jBYJyIaZV1dXfjwww/x85//HKtXr0ZJSQmWL1+Ou+++G5deeilKS0sBAF/4whcgCILyNQC88sorWLJkCQwGA6ZNm4b7778/7IceQRDwhz/8AWvWrIHRaMTUqVPxz3/+U7ne7XZjw4YNyM/Ph8FgQGlpKR588MGReupERERENIbIn5wsLCzE4sWLcc899+Cll17C66+/ji1btijbhU5mV1VVQRAEPPvsszj33HNhNBqxbNkyHDt2DDt37sTSpUuRkpKCSy65BK2trWGP9+STT2LOnDkwGAyYPXs2HnvsMeU6+X6ff/55rF69GiaTCQsWLFA+0QkA1dXVuPzyy5Geng6z2Yy5c+fitddeAxC9Cua5557D3LlzodfrUVpaiocffjhsf0pLS/HTn/4UN910EywWC6ZMmYI//vGPcY/ZmjVr8JOf/ARXXHFFMoeaiIgmAAbrRESjLCUlBSkpKXjxxRfhcrkirt+5cycA6QePxsZG5es333wTX/ziF3Hrrbfi008/xRNPPIEtW7bggQceCLv9vffeq0zEf/GLX8R1112HI0eOAAB+97vf4eWXX8azzz6L8vJy/OUvfwkL7omIiIhocjv//POxYMECPP/883G3u++++/DDH/4Qe/bsgUajwXXXXYc777wTv/3tb/HBBx/gxIkT+NGPfqRs/6c//Qk/+MEP8MADD+DIkSP46U9/invvvRdPPfVU2P3+4Ac/wB133IF9+/Zh5syZuO6665RBkm9+85twuVx4//33cfDgQfz85z9HSkpK1P3bvXs3rr76alx77bU4ePAgNm7ciHvvvTfshAEAPPzww1i6dCn27t2Lb3zjG/j617+Oo0ePDuLIERHRRKcZ7R0gIprsNBoNtmzZgltuuQWPP/44Fi9ejJUrV+Laa6/F6aefjuzsbABAWloa8vLylNs98MADuOuuu3DjjTcCAKZNm4Yf//jHuPPOO3Hfffcp21111VW4+eabAQA//vGP8fbbb+P3v/89HnvsMdTU1KCsrAznnHMOBEFASUnJCD5zIiIiIhoPZs+ejQMHDsTd5o477sDFF18MALjttttw3XXX4d1338XZZ58NAFi/fn1YiP3jH/8YDz/8sDLpPXXqVGVYRH5/K9/vpZdeCgC4//77MXfuXBw/fhyzZ89GTU0NrrzySsyfPx+A9H44ll/96le44IILcO+99wIAZs6ciU8//f/t3V9I010cx/HPZpKkjezGDZkYhNkgi+EIsRsvxBShwMyrcpRCGAxRKOhi5TaIFBlYdDO8FCqpICKkC/EiTGLBaPFILDUo+kvtpj+IzD0Xsd/jbI+1Mvz3fsHY9uPsnN/ZxTj77Lvz+0d9fX1yu91Gu4aGBnV0dEiSzp49q2AwqLGxMZWXl//KWwUA2ECoWAeAVaCpqUmvX7/WnTt3VFdXp7GxMTmdzh8qaBZ6/PixfD6fUfFeUFCg9vZ2vXnzRl+/fjXaVVVVpb2uqqrKqFh3u92KRCLatWuXPB6P7t+//1fmBwAAgLUrmUz+dK/yiooK43FRUZEkGYF36tj79+8lSR8+fNDLly918uTJtLVsIBDQ1NTU//Zrs9kkyejH4/EoEAiourpa58+fXzL8n5ycNEL+lOrqasViMSUSiYzjmUwmWa1WYzwAABYiWAeAVSIvL0+1tbXyer0aHx+X2+1OqzxfbH5+Xj09PYpEIsYtGo0qFospLy9vybFSX4ycTqdmZmbk9/v17ds3HT16VEeOHFnWeQEAAGBtm5yc1I4dO5Zsk5ubazxOrTUXH5ufn5ck4z4UCqWtZZ8+faqJiYmf9pt6fVtbm6anp3Xs2DFFo1FVVlbq8uXLGc8v048DyWRyyXksPm8AABYiWAeAVcrhcOjLly+Svi/wF1bSSN9D8WfPnmnnzp0/3Mzm/z7eF385mZiYSPsrq8ViUUtLi0KhkK5fv66bN2/q06dPf3FmAAAAWCtGR0cVjUbV1NS0bH0WFRWpuLhY09PTP6xjfxbgL2a323Xq1CndunVL3d3dCoVCGds5HA49ePAg7dj4+LjKysqUk5Pz23MBAGxc7LEOACvs48ePam5u1okTJ1RRUaGtW7cqHA6rt7dXhw4dkiSVlpYae1Ru3rxZhYWF8nq9amxslN1uV3Nzs8xms548eaJoNKpAIGD0Pzw8rMrKSh04cEBDQ0N69OiRBgcHJUnBYFA2m0379u2T2WzW8PCwrFartm3bthJvBQAAAFbQ7Oys3r59q0QioXfv3mlkZEQXL15UY2Ojjh8/vqxjXbhwQR6PRxaLRfX19ZqdnVU4HFY8HldXV9cv9dHZ2an6+nqVlZUpHo9rdHRUu3fvzti2u7tbLpdLfr9fLS0tevjwoa5cuaKrV6/+0Tw+f/6s58+fG89nZmYUiUS0fft2lZSU/FHfAIDVjWAdAFZYQUGB9u/fr2AwqKmpKc3Nzclut6u9vV3nzp2TJPX396urq0uhUEjFxcV68eKF6urqdPfuXfl8PvX29io3N1fl5eXGhUpTenp6dO3aNXV0dMhqtWpoaEgOh8MY+9KlS4rFYsrJyZHL5dK9e/fSKt4BAACwMYyMjMhms2nTpk0qLCzU3r17NTAwoNbW1mVfH7a1tWnLli3q6+vTmTNnlJ+frz179qizs/OX+0gkEjp9+rRevXoli8WigwcPKhgMZmzrdDp148YNeb1e+f1+2Ww2+Xy+tAuX/o5wOKyamhrjeepHgdbW1iWvlwQAWPtMyUybigEA1gWTyaTbt2/r8OHDK30qAAAAAAAA6wYliQAAAAAAAAAAZIFgHQAAAAAAAACALLDHOgCsY+z2BQAAAAAAsPyoWAcAAAAAAAAAIAsE6wAAAAAAAAAAZIFgHQAAAAAAAACALBCsAwAAAAAAAACQBYJ1AAAAAAAAAACyQLAOAAAAAAAAAEAWCNYBAAAAAAAAAMgCwToAAAAAAAAAAFkgWAcAAAAAAAAAIAv/Agl1O8vTI+99AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization function for embedding evolution\n",
    "def visualize_embeddings(embedding_history, loss_history, global_steps, chars_to_track):\n",
    "    \"\"\"Visualize the evolution of embeddings and loss.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(121)\n",
    "    plt.plot(global_steps, loss_history)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # Plot embedding trajectories\n",
    "    plt.subplot(122)\n",
    "    for i, char in enumerate(chars_to_track):\n",
    "        plt.plot(embedding_history[:, i, 0], \n",
    "                embedding_history[:, i, 1], \n",
    "                'o-', label=char, alpha=0.5,\n",
    "                markersize=2)\n",
    "        # Mark start and end positions\n",
    "        plt.plot(embedding_history[0, i, 0],\n",
    "                embedding_history[0, i, 1],\n",
    "                'o', color='red', markersize=5)\n",
    "        plt.plot(embedding_history[-1, i, 0],\n",
    "                embedding_history[-1, i, 1],\n",
    "                'o', color='green', markersize=5)\n",
    "    \n",
    "    plt.title('Embedding Evolution')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Visualize the embedding evolution\n",
    "visualize_embeddings(loaded_embedding_history, loaded_loss_history, loaded_global_steps, loaded_chars_to_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
